{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23326b81-bc35-4147-ae75-377d2e75d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from json import load\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from os import listdir\n",
    "from os.path import getmtime, exists, isdir, isfile\n",
    "from pathlib import Path\n",
    "\n",
    "from urlextract import URLExtract\n",
    "import re\n",
    "\n",
    "#IP2024119   Excel's stuff\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45bf9af4-a979-47e4-bf44-b2ec108cb0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel(s) to analyze: All\n",
      "The folder 'JSONs_converted' already exists in '/home/agds/Downloads/' and it will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "## AG20241119: Introduced one extra notation to identify a bit more easily the different comments.\n",
    "## If a comment is part of the description of a given step on the code, it starts with ##--\n",
    "## And if the comment is for suggesting/implementing changes in the code, it starts with #\n",
    "\n",
    "rows_to_show = 1   # uses for debug with Jupiter's-cells-system\n",
    "\n",
    "#AG20241120: replaced every explicit reference to 'n/a', None, ... to the global variable 'missing_value'\n",
    "##-- Syntax to use for missing values:   \n",
    "missing_value = 'n/d'\n",
    "\n",
    "# IP20241125 \n",
    "##-- set adjust for shift from UTC(Slack export timestamp) to ProjectManager's preferred TimeZone \n",
    "timmeshift = 'US/Central'  #IP20241125  chose proper value (! string !)  for TimeZone \n",
    "\n",
    "\n",
    "# IP20241125 inserted to the next block  to minimize data input (from 2 to 1 entry) and end-user misfits\n",
    "'''\n",
    "##-- Do you wish to convert all the Slack channels?:\n",
    "analyze_all_channels = False  #True   \n",
    "\n",
    "##-- If not, insert name of Slack channel to convert:\n",
    "'''\n",
    "##-- Do you wish to convert certain only the Slack channel? then type n it's name:\n",
    "#                             f.e. - 'general'   #  '' - should be preserved for var  initiation  \n",
    "chosen_channel_name = ''  \n",
    "if len(chosen_channel_name) < 1:\n",
    "    analyze_all_channels = True \n",
    "    print('Channel(s) to analyze: All')\n",
    "else:\n",
    "    analyze_all_channels = False\n",
    "    print('Channel(s) to analyze: ', chosen_channel_name)\n",
    "\n",
    " \n",
    "##-- Generate file with the information of all the Slack channels?:\n",
    "write_all_channels_info = True\n",
    "##-- Generate file with the information of all the Slack users?:\n",
    "write_all_users_info = True\n",
    "\n",
    "\n",
    "##-- Insert path where the LOCAL copy of the GoogleDrive folder is:\n",
    "slackexport_folder_path = \"/home/agds/Documents/RebeccaEverleneTrust/RebeccaEverlene_Slack_export\" #AG\n",
    "#slackexport_folder_path = 'E:\\_RET_slack_export\\RebeccaEverlene Slack export Apr 30 2021 - Oct 3 2024-2short' #IP\n",
    "#slackexport_folder_path = 'E:\\_RET_slack_export\\RebeccaEverlene Slack export Oct 3 2024 - Nov 9 2024'\n",
    "\n",
    "##-- Check that slackexport_folder_path exists:  #IP20241123\n",
    "if exists(slackexport_folder_path)==False:\n",
    "    print('Please enter a valid path to the source directory')\n",
    "    continue_analysis = False        #  IP20241124  may be add here abort of entire code? like \"sys.exit()\" ?\n",
    "\n",
    "##-- Insert path where the converted files will be saved:\n",
    "converted_directory = \"/home/agds/Downloads\" #AG\n",
    "#converted_directory = 'E:\\_RET_slack_export\\RebeccaEverlene Slack export Apr 30 2021 - Oct 3 2024-2short' #IP\n",
    "#converted_directory = 'E:\\_RET_slack_export\\RebeccaEverlene Slack export Oct 3 2024 - Nov 9 2024'\n",
    "#\n",
    "converted_directory = f\"{converted_directory}/_JSONs_converted\"\n",
    "\n",
    "##-- Check that     exprt_folder_path   exists:  #IP20241118\n",
    "if exists(converted_directory)==True:\n",
    "    exprt_folder_path = Path(converted_directory)\n",
    "    if exprt_folder_path.is_dir():\n",
    "        print(f\"The folder 'JSONs_converted' already exists in '{converted_directory.split('JSONs')[0][:-1]}' and it will be overwritten.\") #AG20241120\n",
    "        shutil.rmtree(exprt_folder_path)\n",
    "        \n",
    "Path(f\"{converted_directory}\").mkdir(parents=True, exist_ok=True) #IP20241119\n",
    "\n",
    "#\n",
    "continue_analysis = True      # IP20241123 moved here,to var's initiating section\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "910a5f89-bf2e-46a2-a0da-021fb024e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##--AG: Added a routine that checks the existence/format of files/directories of the channel(s) requested by the user.\n",
    "\n",
    "def check_format_of_json_names(list_names):\n",
    "    \"\"\" Iterates over all the json files in a channel's directory, and returns a list with the names of the json files \n",
    "    that have the correct format 'yyyy-mm-dd.json' \"\"\"\n",
    "    list_names_dates = []\n",
    "    #list_names_others = []\n",
    "    for i in range(len(list_names)):\n",
    "        match = re.match(r'(\\d{4})(-)(\\d{2})(-)(\\d{2})(.)(json)',list_names[i])\n",
    "        if match!=None:\n",
    "            list_names_dates.append(list_names[i])\n",
    "        #else:\n",
    "            #list_names_others.append(list_names[i])    # list_names_others could be deleted : it have not sense (un-unified structures of \"other\".json's).\n",
    "    return list_names_dates            #, list_names_others\n",
    "\n",
    "\n",
    "def get_channels_names(slackexport_folder_path, analyze_all_channels, chosen_channel_name, continue_analysis):     # AG20241120\n",
    "    \"\"\" Returns a list with the name(s) of the Slack channels to be converted.\n",
    "    If analysing one channel, check that its directory exists, and default to the 0-th element of channels_names:\n",
    "    channels_names = [ chosen_channel_name ] for one channel\n",
    "    channels_names = [channel0, channel1, ...] for all the channels \"\"\"\n",
    "    if analyze_all_channels == False:\n",
    "        if exists(f\"{slackexport_folder_path}/{chosen_channel_name}\")==False:\n",
    "            channels_names = []\n",
    "            print(f\"The source directory for the channel '{chosen_channel_name}' was not found in {slackexport_folder_path}\")\n",
    "            continue_analysis = False\n",
    "        else:\n",
    "            channels_names = [chosen_channel_name]\n",
    "    else:\n",
    "        all_in_sourceDir = listdir(slackexport_folder_path)\n",
    "        channels_names = [all_in_sourceDir[i] for i in range(len(all_in_sourceDir)) if isdir(f\"{slackexport_folder_path}/{all_in_sourceDir[i]}\")==True]\n",
    "        \n",
    "    #AG20241120: Pending to check the format of each channel's name. Having empty spaces in the name can cause problems later. \n",
    "    return channels_names\n",
    "        \n",
    "\n",
    "def get_all_channels_json_names(channels_names):     # AG20241120\n",
    "    \"\"\" \n",
    "    Check the names of json files in all the channels to be converted and stores them in a list:\n",
    "    all_channels_jsonFiles_dates = [ [chosen_channel_name_json0, chosen_channel_name_json1, ...] ] for one exportchannel\n",
    "    all_channels_jsonFiles_dates = [ [channel0_json0, channel0_json1, ...], [channel1_json0, channel1_json1, ...], ... ] for all the channels\n",
    "    \"\"\"\n",
    "    all_channels_jsonFiles_dates = []\n",
    "    #all_channels_jsonFiles_others = []\n",
    "    for channel in channels_names:\n",
    "        channel_jsonFiles_dates = check_format_of_json_names( listdir(f\"{slackexport_folder_path}/{channel}\") )\n",
    "        all_channels_jsonFiles_dates.append(channel_jsonFiles_dates)\n",
    "        #all_channels_jsonFiles_others.append(channel_jsonFiles_others)  \n",
    "        #   IP20241118: \"all_channels_jsonFiles_others.append\"  is senseless, because \"other\" files could have dofferent inner JSON-structure\n",
    "        #   AG20241119: Agree. The two commented lines were added to keep track of all the files in every directory, it was used for checks but it can be deleted.    \n",
    "    return all_channels_jsonFiles_dates\n",
    "\n",
    "\n",
    "\n",
    "def check_missing_channels(present_channel_names):   #AG20241127\n",
    "    ##-- Get name of channels in channels.json:\n",
    "    expected_channel_names = pd.read_json(f\"{slackexport_folder_path}/channels.json\")['name'].values\n",
    "    ##-- Check that all the expected channels are in present channels:\n",
    "    missing_channels = []\n",
    "    for channel in expected_channel_names:\n",
    "        if channel not in present_channel_names:\n",
    "            missing_channels.append(channel)\n",
    "    if len(missing_channels) > 0:\n",
    "        return missing_channels\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "\n",
    "##-- Check that slackexport_folder_path exists:\n",
    "if exists(slackexport_folder_path)==False:\n",
    "    print('Please enter a valid path to the source directory')\n",
    "    continue_analysis = False\n",
    "else:\n",
    "    #  !!! IP2024118  need to check if exist File \"channels.json\"\n",
    "    ##-- Check that the channels.json files exists:     # AG20241119:\n",
    "    if exists(f\"{slackexport_folder_path}/channels.json\")==False:\n",
    "        print('File \"channels.json\" was not found in the source directory')\n",
    "        continue_analysis = False\n",
    "     \n",
    "    ##-- Check that the users.json files exists:\n",
    "    if exists(f\"{slackexport_folder_path}/users.json\")==False:\n",
    "        print('File \"users.json\" was not found in the source directory')\n",
    "        continue_analysis = False\n",
    "\n",
    "    ##-- Get a list with the name of the channels to be converted:\n",
    "    channels_names = get_channels_names(slackexport_folder_path, analyze_all_channels, chosen_channel_name, continue_analysis) #AG20241120: Defined routine in function\n",
    "\n",
    "    ##-- Get the name of all the json files of the form \"yyyy-mm-dd.json\" in each channel directory:\n",
    "    all_channels_jsonFiles_dates = get_all_channels_json_names(channels_names) # AG20241120: Defined routine in function\n",
    "    \n",
    "    ##-- Check for missing channels in the source directory:       #AG20241127\n",
    "    if analyze_all_channels == True:\n",
    "        missing_channels = check_missing_channels(channels_names)\n",
    "        if missing_channels != None:\n",
    "            print('The following channels are missing in the source directory:', missing_channels)\n",
    "            continue_analysis = False    ##AG: pending to prompt the user if continuing with the analysis? (Relevant for the GUI)\n",
    "\n",
    "\n",
    "#print(continue_analysis) \n",
    "#print(channels_names)\n",
    "#print(all_channels_jsonFiles_others)\n",
    "#print(all_channels_jsonFiles_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d1aa82b-554d-484c-8824-7a52858b2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definition of functions used later in the analysis to replace \"none\" or \"NaN\" entrances:\n",
    "\n",
    "def replace_empty_space(df, column):\n",
    "    \"\"\"Function to replace empty spaces \"\" with the string missing_value for a given column\"\"\"\n",
    "    for i in range(len(df)):\n",
    "        if df.at[i,column] == \"\":\n",
    "            df.at[i,column] = missing_value  \n",
    "            \n",
    "def replace_NaN(df, column):\n",
    "    \"\"\"Function to replace missing values with the string 'n/a' for a given column \"\"\"\n",
    "    df[column] = df[column].fillna(missing_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_channels_df = pd.read_json(f\"{slackexport_folder_path}/channels.json\")\n",
    "#      for visualization, when code run in \"Jupiter-mode\"\n",
    "all_channels_df[0:rows_to_show]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a38f2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_channels_info(slackexport_folder_path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function exports the file channels.json into the dataframe all_channels_df and filters/format relevant features.\n",
    "    The primary features of all_channels_df are: \n",
    "        id, name, created, creator, is_archived, is_general, members, pins, topic, purpose.\n",
    "    The secondary features of 'pins' are:\n",
    "        id, type, created, user, owner.\n",
    "        Generally a list of dictionaries.\n",
    "    The secondary features of 'topic' are:\n",
    "        value, creator, last_set.\n",
    "    \"\"\"\n",
    "    ##-- Export channels.json to dataframe    \n",
    "    all_channels_df = pd.read_json(f\"{slackexport_folder_path}/channels.json\")\n",
    "\n",
    "    # ! IP20241118 code below not take in count - which JSONs _supposed-to-present_ in the export folder\n",
    "    #  code below store only JSONs which physically presented in the time of iterating folder\n",
    "    #  think, all_channels_df should preserv initial list of JSON's, which stored in \"channels.json\" originally\n",
    "    #  to provide manual checking of folder/jsons consistence\n",
    "\n",
    "    ##-- Format relevant features on all_channels_df:\n",
    "    all_json_files = []\n",
    "    for i in range(len(all_channels_df)):\n",
    "        ##-- Adds df['members']. Writes the list of members into a string separated by commnas:\n",
    "        tmp_list = all_channels_df.at[i, 'members']\n",
    "        members_str = \"\".join(f\"{tmp_list[j]}, \" for j in range(len(tmp_list)))\n",
    "        all_channels_df.at[i,'members'] = members_str[:-2]\n",
    "        ##-- Adds df['purpose']:\n",
    "        all_channels_df.at[i,'purpose'] = all_channels_df.at[i,'purpose']['value']\n",
    "        ##-- Adds a list with the channel's json_files with the correct format (yyyy-mm-dd.json):\n",
    "        channel_path = f\"{slackexport_folder_path}/{all_channels_df.at[i,'name']}\"\n",
    "        \n",
    "        #print(\"in the  def'get_all_channels_info' channel_path =>> \"+channel_path )\n",
    "\n",
    "        ##-- Check that the channel_path exists:   #IP20241118\n",
    "        if exists(channel_path)==True:\n",
    "            list_names_dates = check_format_of_json_names(listdir(channel_path)) #AG20241120: list_names_others not part of the output anymore\n",
    "            all_json_files.append(list_names_dates)\n",
    "        else:\n",
    "            all_json_files.append(missing_value)\n",
    "\n",
    "        \n",
    "    all_channels_df['json_files'] = all_json_files\n",
    "    \n",
    "    ##-- Keep the relevant features:\n",
    "    all_channels_df = all_channels_df[['id', 'name', 'created', 'creator', 'is_archived', 'is_general', 'members', 'purpose', 'json_files']]\n",
    "\n",
    "    ##-- Handle missing values or empty strings:\n",
    "    replace_empty_space(all_channels_df, 'members')\n",
    "    replace_empty_space(all_channels_df, 'purpose')\n",
    "    \n",
    "    return all_channels_df\n",
    "\n",
    "\n",
    "def get_all_users_info(slackexport_folder_path):\n",
    "    \"\"\"\n",
    "    This function exports the file users.json into the dataframe all_users_df and filters/format relevant features.\n",
    "    The primary features of all_users_df are: \n",
    "        id, team_id, name, deleted, color, real_name, tz, tz_label, tz_offset, profile, is_admin, is_owner,\n",
    "        is_primary_owner, is_restricted,is_ultra_restricted, is_bot, is_app_user, updated, is_email_confirmed,\n",
    "        who_can_share_contact_card, is_invited_user, is_workflow_bot, is_connector_bot.\n",
    "    Among the secondary features of 'profile', there are:\n",
    "        title, phone, skype, real_name, real_name_normalized, display_name, display_name_normalized, fields, \n",
    "        status_text, status_emoji, status_emoji_display_info, status_expiration, \n",
    "        avatar_hash, image_original, is_custom_image, email, huddle_state, huddle_state_expiration_ts, \n",
    "        first_name, last_name, image_24, image_32, image_48, image_72, image_192, image_512, image_1024, \n",
    "        status_text_canonical, team.\n",
    "    \"\"\"\n",
    "    ##-- Read users.json as a dataframe:\n",
    "    all_users_df = pd.read_json(f\"{slackexport_folder_path}/users.json\")\n",
    "    \n",
    "    ##-- Keep relevant features on all_users_df:\n",
    "    for i in range(len(all_users_df)):\n",
    "        all_users_df.at[i, 'display_name'] = all_users_df.at[i, 'profile']['display_name']\n",
    "        #IP20241120 :: 'profile_title', 'profile_real_name' should stay, cause support to figure out user, when slack-account had deactivated \n",
    "        #all_users_df.at[i, 'profile_title'] = all_users_df.at[i, 'profile']['title']  ## AG: Contain a lot of missing values. Display_name seems more representative.\n",
    "        #all_users_df.at[i, 'profile_real_name'] = all_users_df.at[i, 'profile']['real_name']  ## AG:  Contain a lot of missing values. Display_name seems more representative.\n",
    "        #IP20241126    to provide additional analytics potential for PMs\n",
    "        #all_users_df.at[i, 'profile_status_text'] = all_users_df.at[i, 'profile']['status_text']\n",
    "        #all_users_df.at[i, 'profile_status_emoji'] = all_users_df.at[i, 'profile']['status_emoji']\n",
    "        # AG20241127: Replaced commented lines above to:\n",
    "        for feature in ['title', 'real_name', 'status_text', 'status_emoji']:\n",
    "            all_users_df.at[i, f\"profile_{feature}\"] = all_users_df.at[i, 'profile'][feature]\n",
    "        #\n",
    "    all_users_df = all_users_df[['id', 'team_id', 'name', 'deleted', 'display_name', 'is_bot', 'profile_title', 'profile_real_name', \n",
    "                                 'profile_status_text', 'profile_status_emoji']]\n",
    "    \n",
    "    ##-- Handling missing values in all_users_df:\n",
    "    #replace_empty_space(all_users_df, 'display_name')\n",
    "    #replace_empty_space(all_users_df, 'name')\n",
    "    #replace_empty_space(all_users_df, 'team_id')\n",
    "    #replace_empty_space(all_users_df, 'id')\n",
    "    #replace_empty_space(all_users_df, 'profile_title')  #IP20241120 \n",
    "    #replace_empty_space(all_users_df, 'profile_real_name')  #IP20241120 \n",
    "    # AG20241127: replaced commented lines above to:\n",
    "    for feature in ['display_name', 'name', 'team_id', 'id', 'profile_title', 'profile_real_name']:#, 'profile_status_text', 'profile_status_emoji']:\n",
    "        replace_empty_space(all_users_df, feature) \n",
    "        \n",
    "    return all_users_df\n",
    "\n",
    "\n",
    "def slack_json_to_dataframe(slack_json):\n",
    "    \"\"\" Function to extract channel's messages from a JSON file \"\"\"\n",
    "    \n",
    "    messages_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\", \n",
    "                                        \"reply_count\", \"reply_users_count\", \n",
    "                                        \"ts_latest_reply\", \"ts_thread\", \"parent_user_id\"])\n",
    "    \n",
    "    for message in range(len(slack_json)):\n",
    "        #if 'files' in slack_json[message] and slack_json[message]['files']:            #AG:commented out\n",
    "        #    messages_df.at[message, \"msg_id\"] = slack_json[message]['files'][0]['id']  #AG:commented out\n",
    "        if 'client_msg_id' in slack_json[message]:\n",
    "            messages_df.at[message, \"msg_id\"] = slack_json[message]['client_msg_id']\n",
    "        elif 'subtype' in slack_json[message]:                                       #AG:added\n",
    "            messages_df.at[message, \"msg_id\"] = slack_json[message]['subtype']       #AG:added\n",
    "        else:\n",
    "            messages_df.at[message, \"msg_id\"] = missing_value #'n/a'\n",
    "            \n",
    "        #if 'ts' in slack_json[message]:\n",
    "        #    messages_df.at[message, \"ts\"] = slack_json[message]['ts']\n",
    "        #else:\n",
    "        #    messages_df.at[message, \"ts\"] = missing_value  \n",
    "        \n",
    "        #messages_df.at[message, \"user\"] = slack_json[message].get('user', missing_value)  \n",
    "        \n",
    "        #if 'text' in slack_json[message]:\n",
    "        #    messages_df.at[message, \"text\"] = slack_json[message]['text']\n",
    "        #else:\n",
    "        #    messages_df.at[message, \"text\"] = missing_value  \n",
    "\n",
    "        \n",
    "        # IP20241124 restored (otherwise missed to store timestamps)\n",
    "        if 'type' in slack_json[message]:\n",
    "            messages_df.at[message, \"type\"] = slack_json[message]['type']\n",
    "        else:\n",
    "            messages_df.at[message, \"type\"] = missing_value  \n",
    "\n",
    "\n",
    "        # IP20241124 restored (otherwise missed to store timestamps)\n",
    "        if 'reply_count' in slack_json[message]:\n",
    "            #messages_df.at[message, \"reply_count\"] = slack_json[message]['reply_count']   #AG20241127: line could be deleted if using for loop at the end\n",
    "            #messages_df.at[message, \"reply_users_count\"] = slack_json[message]['reply_users_count']  #AG20241127: line could be deleted if using for loop at the end\n",
    "            messages_df.at[message, \"ts_latest_reply\"] = slack_json[message]['latest_reply']\n",
    "        else:\n",
    "            #messages_df.at[message, \"reply_count\"] = missing_value   #AG20241127: line could be deleted if using for loop at the end\n",
    "            #messages_df.at[message, \"reply_users_count\"] = missing_value  #AG20241127: line could be deleted if using for loop at the end\n",
    "            messages_df.at[message, \"ts_latest_reply\"] = missing_value   \n",
    "        \n",
    "        # IP20241124 restored (otherwise missed to store timestamps)\n",
    "        if 'parent_user_id' in slack_json[message]:\n",
    "            messages_df.at[message, \"ts_thread\"] = slack_json[message]['thread_ts']\n",
    "            #messages_df.at[message, \"parent_user_id\"] = slack_json[message]['parent_user_id']  #AG20241127: line could be deleted if using for loop at the end\n",
    "            messages_df.at[message, \"type\"] = \"thread\"    #IP20241124 to distinguish messages and threads\n",
    "        else:\n",
    "            messages_df.at[message, \"ts_thread\"] = missing_value \n",
    "            #messages_df.at[message, \"parent_user_id\"] = missing_value  #AG20241127: line could be deleted if using for loop at the end\n",
    "\n",
    "        messages_df[\"text\"] = messages_df[\"text\"].astype(str)  #IP20241125  this fixed \"FutureWarning: Setting an item of incompatible dtype is deprecated\" \n",
    "\n",
    "\n",
    "        #IP20241125 Replace CR and LF in only the 'text' column  \n",
    "        #messages_df[\"text\"] = messages_df[\"text\"].apply(lambda x: str(x).replace('\\r\\n\\r\\n', '\\r\\n `rn` ').replace('\\r\\r', '\\r `r` ').replace('\\n\\n', '\\n `n` ') if isinstance(x, str) else x)\n",
    "        #IP20241125 Replace  CR \n",
    "        #messages_df[\"text\"] = messages_df[\"text\"].apply(lambda x: str(x).replace('\\n', ' ') if isinstance(x, str) else x)\n",
    "        #IP20241125 Replace  LF        this chosen as optimal variance\n",
    "        #messages_df[\"text\"] = messages_df[\"text\"].apply(lambda x: str(x).replace('\\r', ' ') if isinstance(x, str) else x)\n",
    "            \n",
    "\n",
    "        #AG20241122 simplified commented lines shown above to:\n",
    "        features = ['ts', 'user',  'text', 'reply_count', 'reply_users_count',  'parent_user_id']  # IP20241124 :: 'type', 'ts_latest_reply', 'ts_thread' - are removed (otherwise missed to store timestamps) \n",
    "        for feature in features:\n",
    "           messages_df.at[message, feature] = slack_json[message].get(feature, missing_value)    \n",
    "           \n",
    "            \n",
    "    return messages_df\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_channel_messages_df(export_path, curr_channel_name, json_list):\n",
    "    \"\"\" Extracts all the messages of a given channel from all its JSON files, and stores them on a data frame \"\"\"\n",
    "    channel_messages_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\",\n",
    "                                                \"reply_count\", \"reply_users_count\",\n",
    "                                                \"ts_latest_reply\", \"ts_thread\", \"parent_user_id\"])\n",
    "                                                # ,\"channel_folder\", \"json_name\", \"json_mod_date\"])          #_IP\n",
    "    \n",
    "    ##-- Iterate over JSONs inside the current channel's folder:\n",
    "    for file_day in range(len(json_list)):\n",
    "        filejson_path = f\"{export_path}/{curr_channel_name}/{json_list[file_day]}\" #AG\n",
    "        \n",
    "        with open(filejson_path, encoding='utf-8') as f:\n",
    "            import_file_json = load(f)\n",
    "        import_file_df = slack_json_to_dataframe(import_file_json)\n",
    "        import_file_df['json_name'] = json_list[file_day]\n",
    "        import_file_df['json_mod_ts'] = getmtime(filejson_path)  #  un-ZIP of download from Ggl-Drive change ts to the non-sense :: \"1980-01-01 00:00:00\" \n",
    "        \n",
    "        channel_messages_df = pd.concat([channel_messages_df, import_file_df], axis=0, ignore_index=True) \n",
    "    \n",
    "    channel_messages_df['channel_folder'] = curr_channel_name   #IP\n",
    "    return channel_messages_df\n",
    "\n",
    "\n",
    "def get_channel_users_df(channel_messages_df, users_df ):\n",
    "    \"\"\"Returns a data frame with the information of the users in current channel\"\"\"\n",
    "    ##-- Initialize channel_users_df as a copy of users_df:\n",
    "    channel_users_df = users_df.copy()\n",
    "    ##-- Find the unique set of users in channel:\n",
    "    channel_users_list = channel_messages_df['user'].unique()\n",
    "    ##-- Collect the indices of the users that are NOT in the channel:\n",
    "    indices_to_drop = [i for i in range(len(users_df)) if users_df.at[i,'id'] not in channel_users_list ]\n",
    "    ##-- Drop the rows on indices_to_drop:\n",
    "    channel_users_df.drop(channel_users_df.index[indices_to_drop], inplace=True)\n",
    "    return channel_users_df\n",
    "\n",
    "def add_users_info_to_messages(df_messages, df_users):\n",
    "    \"\"\"Uses the user's id in the format U1234567789 from the df_messages to find the \n",
    "    name, display name and if the user is a bot from df_users. \n",
    "    The 'name', 'display_name' and 'is_bot' are then added as columns to df_messages\"\"\"\n",
    "    for index in df_messages.index.values:\n",
    "        i_df = df_users[df_users['id']==df_messages.at[index,'user']]\n",
    "        if i_df['display_name'].shape[0]==0:        ##AG: 'USLACKBOT' is a special case\n",
    "            df_messages.at[index, 'name'] =  df_messages.at[index, 'user']\n",
    "            df_messages.at[index, 'display_name'] =  df_messages.at[index, 'user']\n",
    "            df_messages.at[index, 'is_bot'] =  True\n",
    "            df_messages.at[index, 'deactivated'] =  False    #IP20241121\n",
    "        else:\n",
    "            df_messages.at[index, 'name'] = i_df['name'].values\n",
    "            df_messages.at[index, 'display_name'] = i_df['display_name'].values\n",
    "            df_messages.at[index, 'is_bot'] = i_df['is_bot'].values\n",
    "            df_messages.at[index, 'deactivated'] =  i_df['deleted'].values  #IP20241121\n",
    "        del i_df\n",
    "\n",
    "\n",
    "def ts_to_tz(df, original_column_name, new_column_name):\n",
    "    \"\"\"Transforms timestamps in a dataframe's column to dates on the \"US/Central\" timezone\"\"\"\n",
    "    df[original_column_name] = pd.to_numeric(df[original_column_name], errors='coerce')   #_IP\n",
    "    tzs = []\n",
    "    for i in range(len(df)):\n",
    "        i_is_null = pd.Series(df.at[i,original_column_name]).isnull().values[0]    #AG20241120\n",
    "        if i_is_null == True:\n",
    "            #i_date = '0000-00-00 00:00:00'\n",
    "            i_date = missing_value\n",
    "        else:\n",
    "            # IP20241119    #IP20241125 introduce a var \"timmeshift\" to adjast timezone from the 1st pfrt of code (easy tocontrol)\n",
    "            i_date = pd.to_datetime(df.at[i,original_column_name], unit='s').tz_localize('UTC').tz_convert(timmeshift) #('US/Central')\n",
    "            i_date = datetime.strftime(i_date,\"%Y-%m-%d %H:%M:%S\")\n",
    "        tzs.append(i_date)\n",
    "    df[[original_column_name]].astype('datetime64[s]')\n",
    "    df[original_column_name] = tzs\n",
    "    df.rename(columns={original_column_name: new_column_name}, inplace=True)\n",
    "    \n",
    "\n",
    "def extract_urls(df):\n",
    "    \"\"\"Extracts all the url links in df['text'] and stores them as a list in df['URL']\"\"\"\n",
    "    extractor = URLExtract()\n",
    "    #print('len(df) = ',len(df))  #IP20241125\n",
    "    for i in range(len(df)):\n",
    "        urls = []\n",
    "        urls = extractor.find_urls(df.at[i,'text'])\n",
    "        #print('i = ', i , 'len(urls)= ', len(urls), 'urls= ', urls)  #IP20241125\n",
    "        if len(urls)>0:\n",
    "            urls_string = ' ;  '.join(urls)  #IP20241125  to fix  error_\"ValueError: Must have equal len keys and value when setting with an iterable\"\n",
    "            df.at[i,'URL(s)'] = urls_string  #IP20241125 \n",
    "            #print('i = ', i , 'urls= ', urls)  #IP20241125\n",
    "        else:\n",
    "            df.at[i,'URL(s)'] = \"\" # None   IP2024118\n",
    "\n",
    "\n",
    "#IP20241121 :: AG!  it should be \"Add cases where the user_id is not found in users_df.\" >> like preserve original user_ID and added note \"user_not_found\"\n",
    "#IP20241121 :: AG!  in cases  user's \"display_name\"==\"\", then replace \"user_ID\" with \"user_name\"\n",
    "#IP20241121  ::  AG! :: should Add cases where the user_id is \"USLACKBOT\" or \"SLACKBOT\".\n",
    "def user_id_to_name(df_messages, df_users):\n",
    "    \"\"\"Replaces the user_id in the format <@U12345678> to the user's display_name in df_messages['text'], which happens\n",
    "    when the user is mentioned in an Slack message through the option @user_name. \n",
    "     If there is no display_name, then 'user_id' is replaced with 'profile_real_name'.\n",
    "     All the bots in df_users have an 'id' and 'profile_real_name' (not necessarily 'name' and 'display_id'). Their profile_real_name are:\n",
    "    Zoom, Google Drive, monday.com, monday.com notifications, GitHub, Google Calendar, Loom, Simple Poll, Figma, \n",
    "    OneDrive and SharePoint, Calendly, Outlook Calendar, Rebecca Everlene Trust Company, Slack Team Emoji, New hire onboarding, \n",
    "    Welcome, Clockify - Clocking in/out, Zapier, Update Your Slack Team Icon, Jira, Google Sheets, Time Off, Trailhead, \n",
    "    Slack Team Emoji Copy, Guru, Guru, Google Calendar, Polly.\n",
    "     Notice that 'USLACKBOT' and 'B043CSZ0FL7' are the only bot messages if df_messages, but they are not in df_users!\n",
    "     In the replacements, the \"<<>>\" are used for clarity on the text, since names can generally have more than one word and many names\n",
    "    can be referenced one after the other, which can lead to confusion when reading.\n",
    "    \"\"\"\n",
    "    for i in range(len(df_messages)):\n",
    "        text = df_messages.at[i,'text']\n",
    "        matches = re.findall(r'<+@[A-Za-z0-9]+>',text)\n",
    "        if len(matches)>0:\n",
    "            for match in matches:\n",
    "                user = match[2:-1]\n",
    "                # AG20241122: begin\n",
    "                if user in df_users['id'].values:\n",
    "                    name = df_users[df_users['id']==user]['display_name'].values[0]\n",
    "                    is_bot = df_users[df_users['id']==user]['is_bot'].values[0]   \n",
    "                    if is_bot==True:\n",
    "                        name = df_users[df_users['id']==user]['profile_real_name'].values[0] + ' (bot)'\n",
    "                    elif name == missing_value:\n",
    "                        name = df_users[df_users['id']==user]['profile_real_name'].values[0]\n",
    "                else: \n",
    "                    name = f\"{user} (user not found)\"  ## Case for USLACKBOT and B043CSZ0FL7, since they are technically not in df_users!\n",
    "                # AG20241122: end\n",
    "                text = re.sub(f\"<@{user}>\", f\"@{name}@\", text)  #AG20241122: Added \"<>\" (see function's documentation) \n",
    "                \n",
    "                #IP20241121: AG :: should Add cases where the user_id is not found in users_df.\n",
    "                #IP20241124:  issue above not solved\n",
    "\n",
    "                #IP20241121: AG :: should Add cases where the user_id is \"USLACKBOT\" or \"SLACKBOT\".\n",
    "                #IP20241124:  issue above not solved (or explane - how solved, if solved). Show cell with examples \n",
    "            df_messages.at[i,'text'] = text\n",
    "\n",
    "\n",
    "#AG20241122: defined routine that was inside user_id_to_name_test to its own function:\n",
    "def parent_user_id_to_name(df_messages, df_users):\n",
    "    # IP20241121   \"parent_user_id\"  substitution\n",
    "    '''Replaces the user_id in the format \"UA5748HE\" to the user's display_name in df_messages['parent_user_id']'''\n",
    "    for i in range(len(df_messages)):\n",
    "        #text1 = df_messages.at[i,'parent_user_id']\n",
    "        #matches = re.findall(r'\\bU[A-Za-z0-9]+\\b',text1)\n",
    "        #if len(matches)>0:\n",
    "        #    for match in matches:\n",
    "        #        user1 = match   \n",
    "                #print(\"i= \", i, \"user1=\", user1)   #IP20241121:\n",
    "        #        if user1 == \"SLACKBOT\" or user1 == \"USLACKBOT\":\n",
    "        #            continue\n",
    "        #        name1 = df_users[df_users['id']==user1]['display_name'].values[0]\n",
    "        #        text1 = re.sub(f\"{user1}\", f\"{name1}\", text1)\n",
    "                #IP20241121: should Add cases where the user_id is not found in users_df.\n",
    "        #    df_messages.at[i,'parent_user_id'] = text1\n",
    "\n",
    "        #AG20241122: Propose simplifying a bit (since 'matches' will always have the one element in df_messages['parent_user_id'])\n",
    "        user = df_messages.at[i,'parent_user_id']\n",
    "        if user!=missing_value:\n",
    "            name = df_users[df_users['id']==user]['display_name'].values\n",
    "            if user in df_users['id'].values:\n",
    "                is_bot = df_users[df_users['id']==user]['is_bot'].values\n",
    "                if is_bot==True:\n",
    "                    name = df_users[df_users['id']==user]['profile_real_name'].values + ' (bot)'\n",
    "                elif name == missing_value:\n",
    "                    name = df_users[df_users['id']==user]['profile_real_name'].values\n",
    "            else:\n",
    "                name = user+' (user not found)'\n",
    "            df_messages.at[i,'parent_user_id'] = name\n",
    "        \n",
    "\n",
    "def channel_id_to_name(df_messages, df_users):\n",
    "    \"\"\"Replaces <#channel_id|channel_name> to channel_name in df_messages['text'], which happens\n",
    "    when the channel is mentioned in an Slack message through the option #channel_name\"\"\"\n",
    "    for i in range(len(df_messages)):\n",
    "        text = df_messages.at[i,'text']\n",
    "        matches = re.findall(r'#+[A-Za-z0-9]+\\|',text)\n",
    "        if len(matches)>0:\n",
    "            for match in matches:\n",
    "                text = re.sub(match, \"\", text)\n",
    "                text = re.sub(r\"<+\\|\", \"<\", text)\n",
    "            df_messages.at[i,'text'] = text\n",
    "\n",
    "\n",
    "\n",
    "def apply_excel_adjustments(file_path, curr_channel_name):\n",
    "    \"\"\" Excel file formatting/adjustments with  openpyxl (IP) \"\"\"\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb.active\n",
    "    #\n",
    "    ##-- Set the column width\n",
    "    column_widths = {\n",
    "        'A': 12, 'B': 19, 'C': 15,'D': 8, 'E': 35, 'F': 5, 'G': 5, 'H': 17, 'I': 17, 'J': 15, \n",
    "        'K': 19, 'L': 19, 'M': 19, 'N': 13, 'O': 25 , 'P': 7 , 'Q': 6  , 'R': 37      \n",
    "    }\n",
    "    ##-- Apply the column widths\n",
    "    for col, width in column_widths.items():\n",
    "        ws.column_dimensions[col].width = width\n",
    "\n",
    "\n",
    "    ##--  Apply font color to all cells in column \n",
    "    font_color = \"0707C5\"  \n",
    "    for cell in ws['E']: \n",
    "        cell.font = Font(color=font_color)\n",
    "    # \n",
    "    font_color = \"c10105\"  \n",
    "    for cell in ws['J']: \n",
    "        cell.font = Font(color=font_color)\n",
    "\n",
    "\n",
    "    ##-- Loop through each cell in the column_\"E\" >> 'text'  and replace CR+LF    #IP20241125\n",
    "    #    also, set alignments\n",
    "    for row in ws.iter_rows(min_col=5, max_col=5, min_row=2, max_row=ws.max_row):\n",
    "        for cell in row:\n",
    "            if isinstance(cell.value, str):  # Check if the cell contains text\n",
    "                # Replace CR (carriage return) and LF (line feed) with a space\n",
    "                cell.value = cell.value.replace('\\r\\n', ' ').replace('\\r', ' ').replace('\\n\\n', '\\n')\n",
    "                cell.alignment = Alignment(wrap_text=False, vertical=\"top\", horizontal=\"left\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #IP20241120  re-order columns  \n",
    "    #   \n",
    "    # Specify the column to move  \n",
    "    col_to_move_indx = 13    # N-of-clmn==(index)+1\n",
    "    col_to_insert_indx = 4\n",
    "    # Get all columns\n",
    "    columns = list(ws.columns)\n",
    "    col_to_move = columns[col_to_move_indx]\n",
    "    col_to_insert = columns[col_to_insert_indx]  \n",
    "    # Get the data in the column to move\n",
    "    col_data = [cell.value for cell in col_to_move]\n",
    "    # Remove the column from its current position \n",
    "    ws.delete_cols(col_to_move_indx+1)\n",
    "    # Insert the column at the destination position\n",
    "    ws.insert_cols(col_to_insert_indx)  \n",
    "    for row_idx, value in enumerate(col_data, start=1):\n",
    "        ws.cell(row=row_idx, column=col_to_insert_indx, value=value)\n",
    "\n",
    "    col_to_move_indx = 14    # N-of-clmn==(index)+1\n",
    "    col_to_insert_indx = 5\n",
    "    # Get all columns\n",
    "    columns = list(ws.columns)\n",
    "    col_to_move = columns[col_to_move_indx]\n",
    "    col_to_insert = columns[col_to_insert_indx]  \n",
    "    # Get the data in the column to move\n",
    "    col_data = [cell.value for cell in col_to_move]\n",
    "    # Remove the column from its current position \n",
    "    ws.delete_cols(col_to_move_indx+1)\n",
    "    # Insert the column at the destination position\n",
    "    ws.insert_cols(col_to_insert_indx)   \n",
    "    for row_idx, value in enumerate(col_data, start=1):\n",
    "        ws.cell(row=row_idx, column=col_to_insert_indx, value=value)\n",
    "\n",
    "    ##-- re-Set the column width AFTER moving columns  IP20241124 (preserve in code, if further column-moving will be changed)\n",
    "    column_widths = {\n",
    "        'A': 12, 'B': 19, 'C': 15,'D': 19, 'E': 19, 'F': 8, 'G': 35, 'H': 5, 'I': 5, 'J': 17, \n",
    "        'K': 17, 'L': 15, 'M': 19, 'N': 19, 'O': 25 , 'P': 7 , 'Q': 6, 'R': 37    \n",
    "    }\n",
    "    ##-- Apply the column widths\n",
    "    for col, width in column_widths.items():\n",
    "        ws.column_dimensions[col].width = width\n",
    "    \n",
    "    # IP20241124 move \"deactivated\" column\n",
    "    col_to_move_indx = 16    # N-of-clmn==(index)+1\n",
    "    col_to_insert_indx = 6\n",
    "    # Get all columns\n",
    "    columns = list(ws.columns)\n",
    "    col_to_move = columns[col_to_move_indx]\n",
    "    col_to_insert = columns[col_to_insert_indx]  \n",
    "    # Get the data in the column to move\n",
    "    col_data = [cell.value for cell in col_to_move]\n",
    "    # Remove the column from its current position \n",
    "    ws.delete_cols(col_to_move_indx+1)\n",
    "    # Insert the column at the destination position\n",
    "    ws.insert_cols(col_to_insert_indx)   \n",
    "    for row_idx, value in enumerate(col_data, start=1):\n",
    "        ws.cell(row=row_idx, column=col_to_insert_indx, value=value)\n",
    "    \n",
    "    \n",
    "    # IP20241124 move \"is_bot\" column\n",
    "    col_to_move_indx = 16    # N-of-clmn==(index)+1\n",
    "    col_to_insert_indx = 7\n",
    "    # Get all columns\n",
    "    columns = list(ws.columns)\n",
    "    col_to_move = columns[col_to_move_indx]\n",
    "    col_to_insert = columns[col_to_insert_indx]  \n",
    "    # Get the data in the column to move\n",
    "    col_data = [cell.value for cell in col_to_move]\n",
    "    # Remove the column from its current position \n",
    "    ws.delete_cols(col_to_move_indx+1)\n",
    "    # Insert the column at the destination position\n",
    "    ws.insert_cols(col_to_insert_indx)   \n",
    "    for row_idx, value in enumerate(col_data, start=1):\n",
    "        ws.cell(row=row_idx, column=col_to_insert_indx, value=value)\n",
    "\n",
    "    ##-- re-Set the column width AFTER moving columns\n",
    "    column_widths = {\n",
    "        'A': 12, 'B': 19, 'C': 15,'D': 19, 'E': 19, 'F': 7, 'G': 7, 'H':8, 'I':35, 'J': 5,   \n",
    "        'K': 5, 'L': 17, 'M': 17, 'N': 15, 'O': 19, 'P': 19, 'Q': 25, 'R': 37      \n",
    "    }\n",
    "    ##-- Apply the column widths\n",
    "    for col, width in column_widths.items():\n",
    "        ws.column_dimensions[col].width = width\n",
    "\n",
    "    ##-- Data align-to-left  IP2024124  (excluding 1st row)\n",
    "    for row in ws.iter_rows(min_col=10, max_col=11, min_row=2, max_row=ws.max_row):\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(horizontal='center')   # 'left'\n",
    "            if isinstance(cell.value, (int, float)):\n",
    "                cell.font = Font(size=12, bold=True)\n",
    "    \n",
    "    #\n",
    "    #  first row (Row 1) formattings\n",
    "    ##-- Freeze the first row (Row 1)\n",
    "    ws.freeze_panes = 'A2'\n",
    "    ##-- Set font size and bold for the first row\n",
    "    font = Font(size=9, bold=True)\n",
    "    ##-- Set the height of the first row\n",
    "    ws.row_dimensions[1].height = 43 \n",
    "    ##-- Define the RGB color\n",
    "    fill = PatternFill(start_color=\"e7c9fb\", end_color=\"e7c9fb\", fill_type=\"solid\")\n",
    "    ##-- Apply the color, font formatting to the 1st row (Header row)\n",
    "    for cell in ws[1]:\n",
    "        cell.font = font\n",
    "        cell.fill = fill\n",
    "        #cell.alignment = Alignment(wrap_text=True) # Set wrap text for the cells in the first row \n",
    "        cell.alignment = Alignment(wrap_text=True, vertical=\"top\", horizontal=\"left\")\n",
    " \n",
    "    font_color = \"c10105\"  #IP font_color User_name\n",
    "    for cell in ws['E']: \n",
    "        cell.font = Font(color=font_color)\n",
    "\n",
    "    #IP20241121  fill_color when  -> \"is_bot\"==True  -> message's \"type\"==\"thread\"\n",
    "    fill_bot = PatternFill(start_color=\"FBBF8F\", end_color=\"FBBF8F\", fill_type=\"solid\")\n",
    "    fill_thread = PatternFill(start_color=\"FBFB99\", end_color=\"FBFB99\", fill_type=\"solid\")\n",
    "    last_row = ws.max_row\n",
    "    for i in range(2, last_row + 1):\n",
    "        if ws[f'g{i}'].value == \"True\" or ws[f'g{i}'].value == True:\n",
    "            for col in ['C', 'D', 'E', 'F', 'G']:\n",
    "                ws[f'{col}{i}'].fill = fill_bot\n",
    "        if ws[f'H{i}'].value == \"thread\":\n",
    "            for col in ['H', 'I']:\n",
    "                ws[f'{col}{i}'].fill = fill_thread\n",
    "\n",
    "\n",
    "    ##-- Delete columns  ::   json_name \tjson_mod_date\tchannel_folder    #IP20241125\n",
    "    #    this columns is tech only, for development and debug, not for PMs\n",
    "    ws.delete_cols(15)  # Delete column 'O' (now 'P' has shifted to 'O')\n",
    "    ws.delete_cols(15)  # Delete column former 'P'  \n",
    "    ws.delete_cols(15)  # Delete column former 'Q' \n",
    "\n",
    "\n",
    "    #\n",
    "    ##-- Rename the sheet\n",
    "    ws_title = curr_channel_name \n",
    "    ws_title = ws_title[:31]\n",
    "    ws.title = ws_title \n",
    "    #\n",
    "    ##-- Save the changes to the Excel file\n",
    "    wb.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ae148b4-3f0b-4f44-9d6b-abe0df76ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:43:29.108885 Started analysis after sanity checks\n",
      "slackexport_folder_path =>> /home/agds/Documents/RebeccaEverleneTrust/RebeccaEverlene_Slack_export\n",
      "13:43:29.144529 Obtained channels_df\n",
      "13:43:29.413033 Obtained users_df\n",
      "13:43:29.436812 Wrote channels_df to xlsx file\n",
      "13:43:29.582739 Wrote users_df to xlsx file\n",
      "13:43:29.582757 Starting loop over channels \n",
      "\n",
      "landmarks-sprint 13:43:29.582768  Set-up channel name and path to directory\n",
      "landmarks-sprint 13:43:29.587127  Collected channel messages from the json files\n",
      "landmarks-sprint 13:43:29.599973  Collected users in current channel\n",
      "landmarks-sprint 13:43:29.601898  Included the users information on channel_messages_df\n",
      "landmarks-sprint 13:43:29.603117  User's id replaced by their names in messages\n",
      "landmarks-sprint 13:43:29.614327  URLs extracted from messages\n",
      "main_analysys ->> landmarks-sprint    13:43:29.619455  Formated the dates and times in the dataframe\n",
      "landmarks-sprint 13:43:29.637795  Wrote curated messages to xlsx files \n",
      "\n",
      "unequivocally-big-ux-ui 13:43:29.637868  Set-up channel name and path to directory\n",
      "unequivocally-big-ux-ui 13:43:29.930980  Collected channel messages from the json files\n",
      "unequivocally-big-ux-ui 13:43:29.946339  Collected users in current channel\n",
      "unequivocally-big-ux-ui 13:43:30.081270  Included the users information on channel_messages_df\n",
      "unequivocally-big-ux-ui 13:43:30.252307  User's id replaced by their names in messages\n",
      "unequivocally-big-ux-ui 13:43:30.633176  URLs extracted from messages\n",
      "main_analysys ->> unequivocally-big-ux-ui    13:43:30.896541  Formated the dates and times in the dataframe\n",
      "unequivocally-big-ux-ui 13:43:31.407666  Wrote curated messages to xlsx files \n",
      "\n",
      "made-ux-ui 13:43:31.407712  Set-up channel name and path to directory\n",
      "made-ux-ui 13:43:31.570883  Collected channel messages from the json files\n",
      "made-ux-ui 13:43:31.583827  Collected users in current channel\n",
      "made-ux-ui 13:43:31.662006  Included the users information on channel_messages_df\n",
      "made-ux-ui 13:43:31.781961  User's id replaced by their names in messages\n",
      "made-ux-ui 13:43:32.072212  URLs extracted from messages\n",
      "main_analysys ->> made-ux-ui    13:43:32.238770  Formated the dates and times in the dataframe\n",
      "made-ux-ui 13:43:32.455301  Wrote curated messages to xlsx files \n",
      "\n",
      "outreach-fundraising-communications 13:43:32.455342  Set-up channel name and path to directory\n",
      "outreach-fundraising-communications 13:43:32.488631  Collected channel messages from the json files\n",
      "outreach-fundraising-communications 13:43:32.501900  Collected users in current channel\n",
      "outreach-fundraising-communications 13:43:32.515020  Included the users information on channel_messages_df\n",
      "outreach-fundraising-communications 13:43:32.540231  User's id replaced by their names in messages\n",
      "outreach-fundraising-communications 13:43:32.594720  URLs extracted from messages\n",
      "main_analysys ->> outreach-fundraising-communications    13:43:32.621080  Formated the dates and times in the dataframe\n",
      "outreach-fundraising-communications 13:43:32.671576  Wrote curated messages to xlsx files \n",
      "\n",
      "team-azure 13:43:32.671626  Set-up channel name and path to directory\n",
      "team-azure 13:43:32.706031  Collected channel messages from the json files\n",
      "team-azure 13:43:32.719158  Collected users in current channel\n",
      "team-azure 13:43:32.732650  Included the users information on channel_messages_df\n",
      "team-azure 13:43:32.762385  User's id replaced by their names in messages\n",
      "team-azure 13:43:32.811688  URLs extracted from messages\n",
      "main_analysys ->> team-azure    13:43:32.839380  Formated the dates and times in the dataframe\n",
      "team-azure 13:43:32.907804  Wrote curated messages to xlsx files \n",
      "\n",
      "sae-performing-arts-medkids 13:43:32.907851  Set-up channel name and path to directory\n",
      "sae-performing-arts-medkids 13:43:32.925688  Collected channel messages from the json files\n",
      "sae-performing-arts-medkids 13:43:32.938608  Collected users in current channel\n",
      "sae-performing-arts-medkids 13:43:32.945706  Included the users information on channel_messages_df\n",
      "sae-performing-arts-medkids 13:43:32.956984  User's id replaced by their names in messages\n",
      "sae-performing-arts-medkids 13:43:32.995882  URLs extracted from messages\n",
      "main_analysys ->> sae-performing-arts-medkids    13:43:33.010367  Formated the dates and times in the dataframe\n",
      "sae-performing-arts-medkids 13:43:33.039174  Wrote curated messages to xlsx files \n",
      "\n",
      "team-tech-order-up 13:43:33.039194  Set-up channel name and path to directory\n",
      "team-tech-order-up 13:43:33.718930  Collected channel messages from the json files\n",
      "team-tech-order-up 13:43:33.732670  Collected users in current channel\n",
      "team-tech-order-up 13:43:34.078740  Included the users information on channel_messages_df\n",
      "team-tech-order-up 13:43:34.917249  User's id replaced by their names in messages\n",
      "team-tech-order-up 13:43:36.226543  URLs extracted from messages\n",
      "main_analysys ->> team-tech-order-up    13:43:36.961810  Formated the dates and times in the dataframe\n",
      "team-tech-order-up 13:43:38.027499  Wrote curated messages to xlsx files \n",
      "\n",
      "team-game-designers-medkids 13:43:38.027548  Set-up channel name and path to directory\n",
      "team-game-designers-medkids 13:43:38.390143  Collected channel messages from the json files\n",
      "team-game-designers-medkids 13:43:38.404064  Collected users in current channel\n",
      "team-game-designers-medkids 13:43:38.544615  Included the users information on channel_messages_df\n",
      "team-game-designers-medkids 13:43:38.748428  User's id replaced by their names in messages\n",
      "team-game-designers-medkids 13:43:39.106165  URLs extracted from messages\n",
      "main_analysys ->> team-game-designers-medkids    13:43:39.393800  Formated the dates and times in the dataframe\n",
      "team-game-designers-medkids 13:43:39.786641  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-automation-team 13:43:39.786688  Set-up channel name and path to directory\n",
      "aspects-automation-team 13:43:40.714325  Collected channel messages from the json files\n",
      "aspects-automation-team 13:43:40.727875  Collected users in current channel\n",
      "aspects-automation-team 13:43:41.184601  Included the users information on channel_messages_df\n",
      "aspects-automation-team 13:43:42.218615  User's id replaced by their names in messages\n",
      "aspects-automation-team 13:43:43.835879  URLs extracted from messages\n",
      "main_analysys ->> aspects-automation-team    13:43:44.749999  Formated the dates and times in the dataframe\n",
      "aspects-automation-team 13:43:46.179272  Wrote curated messages to xlsx files \n",
      "\n",
      "aws-automation-team 13:43:46.179323  Set-up channel name and path to directory\n",
      "aws-automation-team 13:43:46.284274  Collected channel messages from the json files\n",
      "aws-automation-team 13:43:46.297924  Collected users in current channel\n",
      "aws-automation-team 13:43:46.342309  Included the users information on channel_messages_df\n",
      "aws-automation-team 13:43:46.450854  User's id replaced by their names in messages\n",
      "aws-automation-team 13:43:46.610374  URLs extracted from messages\n",
      "main_analysys ->> aws-automation-team    13:43:46.703892  Formated the dates and times in the dataframe\n",
      "aws-automation-team 13:43:46.834587  Wrote curated messages to xlsx files \n",
      "\n",
      "team-nabil-medkids-games 13:43:46.834611  Set-up channel name and path to directory\n",
      "team-nabil-medkids-games 13:43:46.969535  Collected channel messages from the json files\n",
      "team-nabil-medkids-games 13:43:46.982663  Collected users in current channel\n",
      "team-nabil-medkids-games 13:43:47.036437  Included the users information on channel_messages_df\n",
      "team-nabil-medkids-games 13:43:47.131166  User's id replaced by their names in messages\n",
      "team-nabil-medkids-games 13:43:47.309614  URLs extracted from messages\n",
      "main_analysys ->> team-nabil-medkids-games    13:43:47.419006  Formated the dates and times in the dataframe\n",
      "team-nabil-medkids-games 13:43:47.668495  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-landing-page 13:43:47.668543  Set-up channel name and path to directory\n",
      "landmarks-landing-page 13:43:47.722901  Collected channel messages from the json files\n",
      "landmarks-landing-page 13:43:47.735834  Collected users in current channel\n",
      "landmarks-landing-page 13:43:47.757834  Included the users information on channel_messages_df\n",
      "landmarks-landing-page 13:43:47.798973  User's id replaced by their names in messages\n",
      "landmarks-landing-page 13:43:47.917989  URLs extracted from messages\n",
      "main_analysys ->> landmarks-landing-page    13:43:47.961602  Formated the dates and times in the dataframe\n",
      "landmarks-landing-page 13:43:48.039102  Wrote curated messages to xlsx files \n",
      "\n",
      "tutors-on-call 13:43:48.039125  Set-up channel name and path to directory\n",
      "tutors-on-call 13:43:48.071473  Collected channel messages from the json files\n",
      "tutors-on-call 13:43:48.084514  Collected users in current channel\n",
      "tutors-on-call 13:43:48.098102  Included the users information on channel_messages_df\n",
      "tutors-on-call 13:43:48.120403  User's id replaced by their names in messages\n",
      "tutors-on-call 13:43:48.167168  URLs extracted from messages\n",
      "main_analysys ->> tutors-on-call    13:43:48.195289  Formated the dates and times in the dataframe\n",
      "tutors-on-call 13:43:48.245086  Wrote curated messages to xlsx files \n",
      "\n",
      "FC_F07CWGBGK0D_Untitled 13:43:48.245109  Set-up channel name and path to directory\n",
      "FC_F07CWGBGK0D_Untitled 13:43:48.249507  Collected channel messages from the json files\n",
      "FC_F07CWGBGK0D_Untitled 13:43:48.262320  Collected users in current channel\n",
      "FC_F07CWGBGK0D_Untitled 13:43:48.264646  Included the users information on channel_messages_df\n",
      "FC_F07CWGBGK0D_Untitled 13:43:48.265656  User's id replaced by their names in messages\n",
      "FC_F07CWGBGK0D_Untitled 13:43:48.277637  URLs extracted from messages\n",
      "main_analysys ->> FC_F07CWGBGK0D_Untitled    13:43:48.281980  Formated the dates and times in the dataframe\n",
      "FC_F07CWGBGK0D_Untitled 13:43:48.296666  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-2d-art-characters 13:43:48.296684  Set-up channel name and path to directory\n",
      "landmarks-2d-art-characters 13:43:49.596485  Collected channel messages from the json files\n",
      "landmarks-2d-art-characters 13:43:49.611417  Collected users in current channel\n",
      "landmarks-2d-art-characters 13:43:50.232551  Included the users information on channel_messages_df\n",
      "landmarks-2d-art-characters 13:43:51.521392  User's id replaced by their names in messages\n",
      "landmarks-2d-art-characters 13:43:52.862268  URLs extracted from messages\n",
      "main_analysys ->> landmarks-2d-art-characters    13:43:54.242316  Formated the dates and times in the dataframe\n",
      "landmarks-2d-art-characters 13:43:56.169935  Wrote curated messages to xlsx files \n",
      "\n",
      "college-aspects 13:43:56.169988  Set-up channel name and path to directory\n",
      "college-aspects 13:43:56.223449  Collected channel messages from the json files\n",
      "college-aspects 13:43:56.236896  Collected users in current channel\n",
      "college-aspects 13:43:56.262007  Included the users information on channel_messages_df\n",
      "college-aspects 13:43:56.325425  User's id replaced by their names in messages\n",
      "college-aspects 13:43:56.401677  URLs extracted from messages\n",
      "main_analysys ->> college-aspects    13:43:56.449900  Formated the dates and times in the dataframe\n",
      "college-aspects 13:43:56.540222  Wrote curated messages to xlsx files \n",
      "\n",
      "team-avatars-medkids 13:43:56.540245  Set-up channel name and path to directory\n",
      "team-avatars-medkids 13:43:56.570427  Collected channel messages from the json files\n",
      "team-avatars-medkids 13:43:56.583323  Collected users in current channel\n",
      "team-avatars-medkids 13:43:56.594242  Included the users information on channel_messages_df\n",
      "team-avatars-medkids 13:43:56.614939  User's id replaced by their names in messages\n",
      "team-avatars-medkids 13:43:56.675062  URLs extracted from messages\n",
      "main_analysys ->> team-avatars-medkids    13:43:56.697674  Formated the dates and times in the dataframe\n",
      "team-avatars-medkids 13:43:56.748986  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-geocodes 13:43:56.749013  Set-up channel name and path to directory\n",
      "landmarks-geocodes 13:43:56.866409  Collected channel messages from the json files\n",
      "landmarks-geocodes 13:43:56.880988  Collected users in current channel\n",
      "landmarks-geocodes 13:43:56.937902  Included the users information on channel_messages_df\n",
      "landmarks-geocodes 13:43:57.018842  User's id replaced by their names in messages\n",
      "landmarks-geocodes 13:43:57.141334  URLs extracted from messages\n",
      "main_analysys ->> landmarks-geocodes    13:43:57.259995  Formated the dates and times in the dataframe\n",
      "landmarks-geocodes 13:43:57.447581  Wrote curated messages to xlsx files \n",
      "\n",
      "team-writers-for-rebecca-everlene 13:43:57.447634  Set-up channel name and path to directory\n",
      "team-writers-for-rebecca-everlene 13:43:57.649019  Collected channel messages from the json files\n",
      "team-writers-for-rebecca-everlene 13:43:57.663744  Collected users in current channel\n",
      "team-writers-for-rebecca-everlene 13:43:57.736191  Included the users information on channel_messages_df\n",
      "team-writers-for-rebecca-everlene 13:43:57.855299  User's id replaced by their names in messages\n",
      "team-writers-for-rebecca-everlene 13:43:58.086585  URLs extracted from messages\n",
      "main_analysys ->> team-writers-for-rebecca-everlene    13:43:58.233743  Formated the dates and times in the dataframe\n",
      "team-writers-for-rebecca-everlene 13:43:58.524682  Wrote curated messages to xlsx files \n",
      "\n",
      "eat-like-us-inventory-project 13:43:58.524727  Set-up channel name and path to directory\n",
      "eat-like-us-inventory-project 13:43:58.705446  Collected channel messages from the json files\n",
      "eat-like-us-inventory-project 13:43:58.720991  Collected users in current channel\n",
      "eat-like-us-inventory-project 13:43:58.800811  Included the users information on channel_messages_df\n",
      "eat-like-us-inventory-project 13:43:58.962113  User's id replaced by their names in messages\n",
      "eat-like-us-inventory-project 13:43:59.222354  URLs extracted from messages\n",
      "main_analysys ->> eat-like-us-inventory-project    13:43:59.379842  Formated the dates and times in the dataframe\n",
      "eat-like-us-inventory-project 13:43:59.614745  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-2d-art-locations 13:43:59.614797  Set-up channel name and path to directory\n",
      "landmarks-2d-art-locations 13:43:59.931568  Collected channel messages from the json files\n",
      "landmarks-2d-art-locations 13:43:59.945348  Collected users in current channel\n",
      "landmarks-2d-art-locations 13:44:00.072529  Included the users information on channel_messages_df\n",
      "landmarks-2d-art-locations 13:44:00.365084  User's id replaced by their names in messages\n",
      "landmarks-2d-art-locations 13:44:00.633482  URLs extracted from messages\n",
      "main_analysys ->> landmarks-2d-art-locations    13:44:00.903201  Formated the dates and times in the dataframe\n",
      "landmarks-2d-art-locations 13:44:01.304298  Wrote curated messages to xlsx files \n",
      "\n",
      "team-google-workspace 13:44:01.304345  Set-up channel name and path to directory\n",
      "team-google-workspace 13:44:01.384033  Collected channel messages from the json files\n",
      "team-google-workspace 13:44:01.396952  Collected users in current channel\n",
      "team-google-workspace 13:44:01.436584  Included the users information on channel_messages_df\n",
      "team-google-workspace 13:44:01.530941  User's id replaced by their names in messages\n",
      "team-google-workspace 13:44:01.764877  URLs extracted from messages\n",
      "main_analysys ->> team-google-workspace    13:44:01.852839  Formated the dates and times in the dataframe\n",
      "team-google-workspace 13:44:02.088216  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-data-cleanup 13:44:02.088266  Set-up channel name and path to directory\n",
      "aspects-data-cleanup 13:44:02.179875  Collected channel messages from the json files\n",
      "aspects-data-cleanup 13:44:02.193414  Collected users in current channel\n",
      "aspects-data-cleanup 13:44:02.228810  Included the users information on channel_messages_df\n",
      "aspects-data-cleanup 13:44:02.333101  User's id replaced by their names in messages\n",
      "aspects-data-cleanup 13:44:02.449076  URLs extracted from messages\n",
      "main_analysys ->> aspects-data-cleanup    13:44:02.520050  Formated the dates and times in the dataframe\n",
      "aspects-data-cleanup 13:44:02.633283  Wrote curated messages to xlsx files \n",
      "\n",
      "FC_F05PD7LP5C3_Important_links 13:44:02.633328  Set-up channel name and path to directory\n",
      "FC_F05PD7LP5C3_Important_links 13:44:02.636301  Collected channel messages from the json files\n",
      "FC_F05PD7LP5C3_Important_links 13:44:02.649351  Collected users in current channel\n",
      "FC_F05PD7LP5C3_Important_links 13:44:02.650666  Included the users information on channel_messages_df\n",
      "FC_F05PD7LP5C3_Important_links 13:44:02.650764  User's id replaced by their names in messages\n",
      "FC_F05PD7LP5C3_Important_links 13:44:02.661474  URLs extracted from messages\n",
      "main_analysys ->> FC_F05PD7LP5C3_Important_links    13:44:02.665181  Formated the dates and times in the dataframe\n",
      "FC_F05PD7LP5C3_Important_links 13:44:02.678588  Wrote curated messages to xlsx files \n",
      "\n",
      "dreampad-for-dreamforce 13:44:02.678615  Set-up channel name and path to directory\n",
      "dreampad-for-dreamforce 13:44:02.694468  Collected channel messages from the json files\n",
      "dreampad-for-dreamforce 13:44:02.707380  Collected users in current channel\n",
      "dreampad-for-dreamforce 13:44:02.713884  Included the users information on channel_messages_df\n",
      "dreampad-for-dreamforce 13:44:02.721208  User's id replaced by their names in messages\n",
      "dreampad-for-dreamforce 13:44:02.747490  URLs extracted from messages\n",
      "main_analysys ->> dreampad-for-dreamforce    13:44:02.761049  Formated the dates and times in the dataframe\n",
      "dreampad-for-dreamforce 13:44:02.789198  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-unity-lightship-squad 13:44:02.789219  Set-up channel name and path to directory\n",
      "landmarks-unity-lightship-squad 13:44:02.888964  Collected channel messages from the json files\n",
      "landmarks-unity-lightship-squad 13:44:02.902762  Collected users in current channel\n",
      "landmarks-unity-lightship-squad 13:44:02.941877  Included the users information on channel_messages_df\n",
      "landmarks-unity-lightship-squad 13:44:03.047881  User's id replaced by their names in messages\n",
      "landmarks-unity-lightship-squad 13:44:03.210154  URLs extracted from messages\n",
      "main_analysys ->> landmarks-unity-lightship-squad    13:44:03.291965  Formated the dates and times in the dataframe\n",
      "landmarks-unity-lightship-squad 13:44:03.405010  Wrote curated messages to xlsx files \n",
      "\n",
      "team-barbara-medkids-games 13:44:03.405032  Set-up channel name and path to directory\n",
      "team-barbara-medkids-games 13:44:03.663480  Collected channel messages from the json files\n",
      "team-barbara-medkids-games 13:44:03.677453  Collected users in current channel\n",
      "team-barbara-medkids-games 13:44:03.781655  Included the users information on channel_messages_df\n",
      "team-barbara-medkids-games 13:44:03.905595  User's id replaced by their names in messages\n",
      "team-barbara-medkids-games 13:44:04.175465  URLs extracted from messages\n",
      "main_analysys ->> team-barbara-medkids-games    13:44:04.387737  Formated the dates and times in the dataframe\n",
      "team-barbara-medkids-games 13:44:04.680345  Wrote curated messages to xlsx files \n",
      "\n",
      "mockups-for-strategy-finance-budgets 13:44:04.680402  Set-up channel name and path to directory\n",
      "mockups-for-strategy-finance-budgets 13:44:04.692974  Collected channel messages from the json files\n",
      "mockups-for-strategy-finance-budgets 13:44:04.706073  Collected users in current channel\n",
      "mockups-for-strategy-finance-budgets 13:44:04.711755  Included the users information on channel_messages_df\n",
      "mockups-for-strategy-finance-budgets 13:44:04.720974  User's id replaced by their names in messages\n",
      "mockups-for-strategy-finance-budgets 13:44:04.752235  URLs extracted from messages\n",
      "main_analysys ->> mockups-for-strategy-finance-budgets    13:44:04.763627  Formated the dates and times in the dataframe\n",
      "mockups-for-strategy-finance-budgets 13:44:04.790034  Wrote curated messages to xlsx files \n",
      "\n",
      "FC_F07A54DBKUK_Untitled 13:44:04.790067  Set-up channel name and path to directory\n",
      "FC_F07A54DBKUK_Untitled 13:44:04.794643  Collected channel messages from the json files\n",
      "FC_F07A54DBKUK_Untitled 13:44:04.808186  Collected users in current channel\n",
      "FC_F07A54DBKUK_Untitled 13:44:04.810072  Included the users information on channel_messages_df\n",
      "FC_F07A54DBKUK_Untitled 13:44:04.811339  User's id replaced by their names in messages\n",
      "FC_F07A54DBKUK_Untitled 13:44:04.824314  URLs extracted from messages\n",
      "main_analysys ->> FC_F07A54DBKUK_Untitled    13:44:04.828760  Formated the dates and times in the dataframe\n",
      "FC_F07A54DBKUK_Untitled 13:44:04.844810  Wrote curated messages to xlsx files \n",
      "\n",
      "scrum 13:44:04.844837  Set-up channel name and path to directory\n",
      "scrum 13:44:05.208834  Collected channel messages from the json files\n",
      "scrum 13:44:05.222235  Collected users in current channel\n",
      "scrum 13:44:05.398040  Included the users information on channel_messages_df\n",
      "scrum 13:44:06.061781  User's id replaced by their names in messages\n",
      "scrum 13:44:06.975285  URLs extracted from messages\n",
      "main_analysys ->> scrum    13:44:07.335133  Formated the dates and times in the dataframe\n",
      "scrum 13:44:07.888475  Wrote curated messages to xlsx files \n",
      "\n",
      "team-audio-med-kids 13:44:07.888523  Set-up channel name and path to directory\n",
      "team-audio-med-kids 13:44:08.476528  Collected channel messages from the json files\n",
      "team-audio-med-kids 13:44:08.489869  Collected users in current channel\n",
      "team-audio-med-kids 13:44:08.737143  Included the users information on channel_messages_df\n",
      "team-audio-med-kids 13:44:09.135817  User's id replaced by their names in messages\n",
      "team-audio-med-kids 13:44:09.741999  URLs extracted from messages\n",
      "main_analysys ->> team-audio-med-kids    13:44:10.277898  Formated the dates and times in the dataframe\n",
      "team-audio-med-kids 13:44:11.110485  Wrote curated messages to xlsx files \n",
      "\n",
      "smitten-hitch-coparenting-project 13:44:11.110533  Set-up channel name and path to directory\n",
      "smitten-hitch-coparenting-project 13:44:11.207158  Collected channel messages from the json files\n",
      "smitten-hitch-coparenting-project 13:44:11.220068  Collected users in current channel\n",
      "smitten-hitch-coparenting-project 13:44:11.266678  Included the users information on channel_messages_df\n",
      "smitten-hitch-coparenting-project 13:44:11.359817  User's id replaced by their names in messages\n",
      "smitten-hitch-coparenting-project 13:44:11.543325  URLs extracted from messages\n",
      "main_analysys ->> smitten-hitch-coparenting-project    13:44:11.639227  Formated the dates and times in the dataframe\n",
      "smitten-hitch-coparenting-project 13:44:11.776194  Wrote curated messages to xlsx files \n",
      "\n",
      "time-off 13:44:11.776237  Set-up channel name and path to directory\n",
      "time-off 13:44:11.866309  Collected channel messages from the json files\n",
      "time-off 13:44:11.881186  Collected users in current channel\n",
      "time-off 13:44:11.925507  Included the users information on channel_messages_df\n",
      "time-off 13:44:12.032998  User's id replaced by their names in messages\n",
      "time-off 13:44:12.108114  URLs extracted from messages\n",
      "main_analysys ->> time-off    13:44:12.195823  Formated the dates and times in the dataframe\n",
      "time-off 13:44:12.394736  Wrote curated messages to xlsx files \n",
      "\n",
      "team-yigit-medkids-games 13:44:12.394780  Set-up channel name and path to directory\n",
      "team-yigit-medkids-games 13:44:12.918877  Collected channel messages from the json files\n",
      "team-yigit-medkids-games 13:44:12.931886  Collected users in current channel\n",
      "team-yigit-medkids-games 13:44:13.170801  Included the users information on channel_messages_df\n",
      "team-yigit-medkids-games 13:44:13.713341  User's id replaced by their names in messages\n",
      "team-yigit-medkids-games 13:44:14.557916  URLs extracted from messages\n",
      "main_analysys ->> team-yigit-medkids-games    13:44:15.110109  Formated the dates and times in the dataframe\n",
      "team-yigit-medkids-games 13:44:15.892167  Wrote curated messages to xlsx files \n",
      "\n",
      "team-back-end-dev 13:44:15.892217  Set-up channel name and path to directory\n",
      "team-back-end-dev 13:44:15.912965  Collected channel messages from the json files\n",
      "team-back-end-dev 13:44:15.926238  Collected users in current channel\n",
      "team-back-end-dev 13:44:15.935633  Included the users information on channel_messages_df\n",
      "team-back-end-dev 13:44:15.944640  User's id replaced by their names in messages\n",
      "team-back-end-dev 13:44:15.974066  URLs extracted from messages\n",
      "main_analysys ->> team-back-end-dev    13:44:15.993213  Formated the dates and times in the dataframe\n",
      "team-back-end-dev 13:44:16.027953  Wrote curated messages to xlsx files \n",
      "\n",
      "team-scapegoated 13:44:16.027974  Set-up channel name and path to directory\n",
      "team-scapegoated 13:44:16.093133  Collected channel messages from the json files\n",
      "team-scapegoated 13:44:16.106948  Collected users in current channel\n",
      "team-scapegoated 13:44:16.137717  Included the users information on channel_messages_df\n",
      "team-scapegoated 13:44:16.181571  User's id replaced by their names in messages\n",
      "team-scapegoated 13:44:16.306868  URLs extracted from messages\n",
      "main_analysys ->> team-scapegoated    13:44:16.365486  Formated the dates and times in the dataframe\n",
      "team-scapegoated 13:44:16.457501  Wrote curated messages to xlsx files \n",
      "\n",
      "grants 13:44:16.457544  Set-up channel name and path to directory\n",
      "grants 13:44:16.507200  Collected channel messages from the json files\n",
      "grants 13:44:16.520225  Collected users in current channel\n",
      "grants 13:44:16.537012  Included the users information on channel_messages_df\n",
      "grants 13:44:16.572036  User's id replaced by their names in messages\n",
      "grants 13:44:16.651374  URLs extracted from messages\n",
      "main_analysys ->> grants    13:44:16.685205  Formated the dates and times in the dataframe\n",
      "grants 13:44:16.744775  Wrote curated messages to xlsx files \n",
      "\n",
      "spaulding-daniels-leadership-group 13:44:16.744818  Set-up channel name and path to directory\n",
      "spaulding-daniels-leadership-group 13:44:16.781241  Collected channel messages from the json files\n",
      "spaulding-daniels-leadership-group 13:44:16.793932  Collected users in current channel\n",
      "spaulding-daniels-leadership-group 13:44:16.808615  Included the users information on channel_messages_df\n",
      "spaulding-daniels-leadership-group 13:44:16.845038  User's id replaced by their names in messages\n",
      "spaulding-daniels-leadership-group 13:44:16.972910  URLs extracted from messages\n",
      "main_analysys ->> spaulding-daniels-leadership-group    13:44:17.002948  Formated the dates and times in the dataframe\n",
      "spaulding-daniels-leadership-group 13:44:17.057386  Wrote curated messages to xlsx files \n",
      "\n",
      "presidential-service-award 13:44:17.057407  Set-up channel name and path to directory\n",
      "presidential-service-award 13:44:17.100420  Collected channel messages from the json files\n",
      "presidential-service-award 13:44:17.113578  Collected users in current channel\n",
      "presidential-service-award 13:44:17.129556  Included the users information on channel_messages_df\n",
      "presidential-service-award 13:44:17.169703  User's id replaced by their names in messages\n",
      "presidential-service-award 13:44:17.221248  URLs extracted from messages\n",
      "main_analysys ->> presidential-service-award    13:44:17.255205  Formated the dates and times in the dataframe\n",
      "presidential-service-award 13:44:17.311690  Wrote curated messages to xlsx files \n",
      "\n",
      "team-dev-issues-board 13:44:17.311712  Set-up channel name and path to directory\n",
      "team-dev-issues-board 13:44:17.319520  Collected channel messages from the json files\n",
      "team-dev-issues-board 13:44:17.332235  Collected users in current channel\n",
      "team-dev-issues-board 13:44:17.335532  Included the users information on channel_messages_df\n",
      "team-dev-issues-board 13:44:17.341355  User's id replaced by their names in messages\n",
      "team-dev-issues-board 13:44:17.353211  URLs extracted from messages\n",
      "main_analysys ->> team-dev-issues-board    13:44:17.360542  Formated the dates and times in the dataframe\n",
      "team-dev-issues-board 13:44:17.380515  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-interactive-wall 13:44:17.380533  Set-up channel name and path to directory\n",
      "landmarks-interactive-wall 13:44:17.537753  Collected channel messages from the json files\n",
      "landmarks-interactive-wall 13:44:17.550813  Collected users in current channel\n",
      "landmarks-interactive-wall 13:44:17.606803  Included the users information on channel_messages_df\n",
      "landmarks-interactive-wall 13:44:17.675366  User's id replaced by their names in messages\n",
      "landmarks-interactive-wall 13:44:17.908869  URLs extracted from messages\n",
      "main_analysys ->> landmarks-interactive-wall    13:44:18.027798  Formated the dates and times in the dataframe\n",
      "landmarks-interactive-wall 13:44:18.196826  Wrote curated messages to xlsx files \n",
      "\n",
      "team-maulana-medkids-games 13:44:18.196851  Set-up channel name and path to directory\n",
      "team-maulana-medkids-games 13:44:18.381953  Collected channel messages from the json files\n",
      "team-maulana-medkids-games 13:44:18.395173  Collected users in current channel\n",
      "team-maulana-medkids-games 13:44:18.468587  Included the users information on channel_messages_df\n",
      "team-maulana-medkids-games 13:44:18.608291  User's id replaced by their names in messages\n",
      "team-maulana-medkids-games 13:44:18.822941  URLs extracted from messages\n",
      "main_analysys ->> team-maulana-medkids-games    13:44:18.976018  Formated the dates and times in the dataframe\n",
      "team-maulana-medkids-games 13:44:19.180188  Wrote curated messages to xlsx files \n",
      "\n",
      "team-christa-medkids-games 13:44:19.180226  Set-up channel name and path to directory\n",
      "team-christa-medkids-games 13:44:19.263992  Collected channel messages from the json files\n",
      "team-christa-medkids-games 13:44:19.276581  Collected users in current channel\n",
      "team-christa-medkids-games 13:44:19.306870  Included the users information on channel_messages_df\n",
      "team-christa-medkids-games 13:44:19.367423  User's id replaced by their names in messages\n",
      "team-christa-medkids-games 13:44:19.454139  URLs extracted from messages\n",
      "main_analysys ->> team-christa-medkids-games    13:44:19.517865  Formated the dates and times in the dataframe\n",
      "team-christa-medkids-games 13:44:19.612553  Wrote curated messages to xlsx files \n",
      "\n",
      "team-front-end-web-developers-medkids 13:44:19.612576  Set-up channel name and path to directory\n",
      "team-front-end-web-developers-medkids 13:44:20.886066  Collected channel messages from the json files\n",
      "team-front-end-web-developers-medkids 13:44:20.900724  Collected users in current channel\n",
      "team-front-end-web-developers-medkids 13:44:21.554086  Included the users information on channel_messages_df\n",
      "team-front-end-web-developers-medkids 13:44:22.748040  User's id replaced by their names in messages\n",
      "team-front-end-web-developers-medkids 13:44:24.417298  URLs extracted from messages\n",
      "main_analysys ->> team-front-end-web-developers-medkids    13:44:25.694549  Formated the dates and times in the dataframe\n",
      "team-front-end-web-developers-medkids 13:44:27.777007  Wrote curated messages to xlsx files \n",
      "\n",
      "team-ink 13:44:27.777060  Set-up channel name and path to directory\n",
      "team-ink 13:44:27.847112  Collected channel messages from the json files\n",
      "team-ink 13:44:27.860699  Collected users in current channel\n",
      "team-ink 13:44:27.894154  Included the users information on channel_messages_df\n",
      "team-ink 13:44:27.971673  User's id replaced by their names in messages\n",
      "team-ink 13:44:28.162923  URLs extracted from messages\n",
      "main_analysys ->> team-ink    13:44:28.227573  Formated the dates and times in the dataframe\n",
      "team-ink 13:44:28.322161  Wrote curated messages to xlsx files \n",
      "\n",
      "cpts-training-team 13:44:28.322184  Set-up channel name and path to directory\n",
      "cpts-training-team 13:44:28.380540  Collected channel messages from the json files\n",
      "cpts-training-team 13:44:28.393138  Collected users in current channel\n",
      "cpts-training-team 13:44:28.412410  Included the users information on channel_messages_df\n",
      "cpts-training-team 13:44:28.436693  User's id replaced by their names in messages\n",
      "cpts-training-team 13:44:28.609893  URLs extracted from messages\n",
      "main_analysys ->> cpts-training-team    13:44:28.647237  Formated the dates and times in the dataframe\n",
      "cpts-training-team 13:44:28.716277  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-ux-ui-designers 13:44:28.716322  Set-up channel name and path to directory\n",
      "landmarks-ux-ui-designers 13:44:29.624132  Collected channel messages from the json files\n",
      "landmarks-ux-ui-designers 13:44:29.637292  Collected users in current channel\n",
      "landmarks-ux-ui-designers 13:44:30.088815  Included the users information on channel_messages_df\n",
      "landmarks-ux-ui-designers 13:44:30.749935  User's id replaced by their names in messages\n",
      "landmarks-ux-ui-designers 13:44:31.966977  URLs extracted from messages\n",
      "main_analysys ->> landmarks-ux-ui-designers    13:44:32.926264  Formated the dates and times in the dataframe\n",
      "landmarks-ux-ui-designers 13:44:34.447810  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-production-team 13:44:34.447873  Set-up channel name and path to directory\n",
      "landmarks-production-team 13:44:34.525631  Collected channel messages from the json files\n",
      "landmarks-production-team 13:44:34.539710  Collected users in current channel\n",
      "landmarks-production-team 13:44:34.578338  Included the users information on channel_messages_df\n",
      "landmarks-production-team 13:44:34.639490  User's id replaced by their names in messages\n",
      "landmarks-production-team 13:44:34.725229  URLs extracted from messages\n",
      "main_analysys ->> landmarks-production-team    13:44:34.796749  Formated the dates and times in the dataframe\n",
      "landmarks-production-team 13:44:34.902657  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks 13:44:34.902682  Set-up channel name and path to directory\n",
      "landmarks 13:44:35.269691  Collected channel messages from the json files\n",
      "landmarks 13:44:35.284207  Collected users in current channel\n",
      "landmarks 13:44:35.428774  Included the users information on channel_messages_df\n",
      "landmarks 13:44:35.832936  User's id replaced by their names in messages\n",
      "landmarks 13:44:36.421494  URLs extracted from messages\n",
      "main_analysys ->> landmarks    13:44:36.717428  Formated the dates and times in the dataframe\n",
      "landmarks 13:44:37.137978  Wrote curated messages to xlsx files \n",
      "\n",
      "salesforce-automation-team 13:44:37.138039  Set-up channel name and path to directory\n",
      "salesforce-automation-team 13:44:37.671194  Collected channel messages from the json files\n",
      "salesforce-automation-team 13:44:37.685201  Collected users in current channel\n",
      "salesforce-automation-team 13:44:37.978930  Included the users information on channel_messages_df\n",
      "salesforce-automation-team 13:44:38.533726  User's id replaced by their names in messages\n",
      "salesforce-automation-team 13:44:39.408635  URLs extracted from messages\n",
      "main_analysys ->> salesforce-automation-team    13:44:39.977915  Formated the dates and times in the dataframe\n",
      "salesforce-automation-team 13:44:40.926159  Wrote curated messages to xlsx files \n",
      "\n",
      "design-brainstorming-sessions 13:44:40.926207  Set-up channel name and path to directory\n",
      "design-brainstorming-sessions 13:44:40.998539  Collected channel messages from the json files\n",
      "design-brainstorming-sessions 13:44:41.011669  Collected users in current channel\n",
      "design-brainstorming-sessions 13:44:41.042511  Included the users information on channel_messages_df\n",
      "design-brainstorming-sessions 13:44:41.098980  User's id replaced by their names in messages\n",
      "design-brainstorming-sessions 13:44:41.196583  URLs extracted from messages\n",
      "main_analysys ->> design-brainstorming-sessions    13:44:41.262007  Formated the dates and times in the dataframe\n",
      "design-brainstorming-sessions 13:44:41.362918  Wrote curated messages to xlsx files \n",
      "\n",
      "policies-and-sops-team 13:44:41.362943  Set-up channel name and path to directory\n",
      "policies-and-sops-team 13:44:41.400322  Collected channel messages from the json files\n",
      "policies-and-sops-team 13:44:41.413406  Collected users in current channel\n",
      "policies-and-sops-team 13:44:41.427974  Included the users information on channel_messages_df\n",
      "policies-and-sops-team 13:44:41.458985  User's id replaced by their names in messages\n",
      "policies-and-sops-team 13:44:41.547744  URLs extracted from messages\n",
      "main_analysys ->> policies-and-sops-team    13:44:41.578500  Formated the dates and times in the dataframe\n",
      "policies-and-sops-team 13:44:41.633174  Wrote curated messages to xlsx files \n",
      "\n",
      "team-2d-art-for-medkids 13:44:41.633198  Set-up channel name and path to directory\n",
      "team-2d-art-for-medkids 13:44:41.924811  Collected channel messages from the json files\n",
      "team-2d-art-for-medkids 13:44:41.939112  Collected users in current channel\n",
      "team-2d-art-for-medkids 13:44:42.053899  Included the users information on channel_messages_df\n",
      "team-2d-art-for-medkids 13:44:42.199757  User's id replaced by their names in messages\n",
      "team-2d-art-for-medkids 13:44:42.377223  URLs extracted from messages\n",
      "main_analysys ->> team-2d-art-for-medkids    13:44:42.605487  Formated the dates and times in the dataframe\n",
      "team-2d-art-for-medkids 13:44:42.914693  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-locations 13:44:42.914741  Set-up channel name and path to directory\n",
      "landmarks-locations 13:44:45.135072  Collected channel messages from the json files\n",
      "landmarks-locations 13:44:45.149913  Collected users in current channel\n",
      "landmarks-locations 13:44:46.111921  Included the users information on channel_messages_df\n",
      "landmarks-locations 13:44:46.561723  User's id replaced by their names in messages\n",
      "landmarks-locations 13:44:47.252254  URLs extracted from messages\n",
      "main_analysys ->> landmarks-locations    13:44:49.064154  Formated the dates and times in the dataframe\n",
      "landmarks-locations 13:44:52.302308  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-design-content-updates 13:44:52.302369  Set-up channel name and path to directory\n",
      "aspects-design-content-updates 13:44:52.610714  Collected channel messages from the json files\n",
      "aspects-design-content-updates 13:44:52.625089  Collected users in current channel\n",
      "aspects-design-content-updates 13:44:52.742969  Included the users information on channel_messages_df\n",
      "aspects-design-content-updates 13:44:52.836007  User's id replaced by their names in messages\n",
      "aspects-design-content-updates 13:44:53.108726  URLs extracted from messages\n",
      "main_analysys ->> aspects-design-content-updates    13:44:53.329023  Formated the dates and times in the dataframe\n",
      "aspects-design-content-updates 13:44:53.809330  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-vertical-slice-team 13:44:53.809380  Set-up channel name and path to directory\n",
      "landmarks-vertical-slice-team 13:44:53.855668  Collected channel messages from the json files\n",
      "landmarks-vertical-slice-team 13:44:53.868601  Collected users in current channel\n",
      "landmarks-vertical-slice-team 13:44:53.889558  Included the users information on channel_messages_df\n",
      "landmarks-vertical-slice-team 13:44:53.924043  User's id replaced by their names in messages\n",
      "landmarks-vertical-slice-team 13:44:53.982747  URLs extracted from messages\n",
      "main_analysys ->> landmarks-vertical-slice-team    13:44:54.025754  Formated the dates and times in the dataframe\n",
      "landmarks-vertical-slice-team 13:44:54.103584  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-mapping 13:44:54.103630  Set-up channel name and path to directory\n",
      "landmarks-mapping 13:44:54.251139  Collected channel messages from the json files\n",
      "landmarks-mapping 13:44:54.263868  Collected users in current channel\n",
      "landmarks-mapping 13:44:54.332151  Included the users information on channel_messages_df\n",
      "landmarks-mapping 13:44:54.420530  User's id replaced by their names in messages\n",
      "landmarks-mapping 13:44:54.632639  URLs extracted from messages\n",
      "main_analysys ->> landmarks-mapping    13:44:54.764945  Formated the dates and times in the dataframe\n",
      "landmarks-mapping 13:44:54.959592  Wrote curated messages to xlsx files \n",
      "\n",
      "grants-team-2024 13:44:54.959643  Set-up channel name and path to directory\n",
      "grants-team-2024 13:44:55.344822  Collected channel messages from the json files\n",
      "grants-team-2024 13:44:55.358690  Collected users in current channel\n",
      "grants-team-2024 13:44:55.543684  Included the users information on channel_messages_df\n",
      "grants-team-2024 13:44:55.935777  User's id replaced by their names in messages\n",
      "grants-team-2024 13:44:56.590200  URLs extracted from messages\n",
      "main_analysys ->> grants-team-2024    13:44:56.957378  Formated the dates and times in the dataframe\n",
      "grants-team-2024 13:44:57.539568  Wrote curated messages to xlsx files \n",
      "\n",
      "fundraising-initiatives 13:44:57.539643  Set-up channel name and path to directory\n",
      "fundraising-initiatives 13:44:57.783410  Collected channel messages from the json files\n",
      "fundraising-initiatives 13:44:57.797606  Collected users in current channel\n",
      "fundraising-initiatives 13:44:57.893513  Included the users information on channel_messages_df\n",
      "fundraising-initiatives 13:44:58.074455  User's id replaced by their names in messages\n",
      "fundraising-initiatives 13:44:58.584158  URLs extracted from messages\n",
      "main_analysys ->> fundraising-initiatives    13:44:58.776541  Formated the dates and times in the dataframe\n",
      "fundraising-initiatives 13:44:59.052352  Wrote curated messages to xlsx files \n",
      "\n",
      "the-jog-app 13:44:59.052405  Set-up channel name and path to directory\n",
      "the-jog-app 13:44:59.202197  Collected channel messages from the json files\n",
      "the-jog-app 13:44:59.215139  Collected users in current channel\n",
      "the-jog-app 13:44:59.286255  Included the users information on channel_messages_df\n",
      "the-jog-app 13:44:59.434673  User's id replaced by their names in messages\n",
      "the-jog-app 13:44:59.796160  URLs extracted from messages\n",
      "main_analysys ->> the-jog-app    13:44:59.947475  Formated the dates and times in the dataframe\n",
      "the-jog-app 13:45:00.262421  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-game-designers 13:45:00.262468  Set-up channel name and path to directory\n",
      "landmarks-game-designers 13:45:00.584397  Collected channel messages from the json files\n",
      "landmarks-game-designers 13:45:00.599608  Collected users in current channel\n",
      "landmarks-game-designers 13:45:00.731769  Included the users information on channel_messages_df\n",
      "landmarks-game-designers 13:45:01.017850  User's id replaced by their names in messages\n",
      "landmarks-game-designers 13:45:01.544550  URLs extracted from messages\n",
      "main_analysys ->> landmarks-game-designers    13:45:01.818554  Formated the dates and times in the dataframe\n",
      "landmarks-game-designers 13:45:02.242565  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-sprint-planning 13:45:02.242611  Set-up channel name and path to directory\n",
      "landmarks-sprint-planning 13:45:02.328384  Collected channel messages from the json files\n",
      "landmarks-sprint-planning 13:45:02.341697  Collected users in current channel\n",
      "landmarks-sprint-planning 13:45:02.377031  Included the users information on channel_messages_df\n",
      "landmarks-sprint-planning 13:45:02.457325  User's id replaced by their names in messages\n",
      "landmarks-sprint-planning 13:45:02.562958  URLs extracted from messages\n",
      "main_analysys ->> landmarks-sprint-planning    13:45:02.636079  Formated the dates and times in the dataframe\n",
      "landmarks-sprint-planning 13:45:02.743013  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-2d-art-items-and-guides 13:45:02.743057  Set-up channel name and path to directory\n",
      "landmarks-2d-art-items-and-guides 13:45:02.786459  Collected channel messages from the json files\n",
      "landmarks-2d-art-items-and-guides 13:45:02.799370  Collected users in current channel\n",
      "landmarks-2d-art-items-and-guides 13:45:02.813545  Included the users information on channel_messages_df\n",
      "landmarks-2d-art-items-and-guides 13:45:02.838633  User's id replaced by their names in messages\n",
      "landmarks-2d-art-items-and-guides 13:45:02.865590  URLs extracted from messages\n",
      "main_analysys ->> landmarks-2d-art-items-and-guides    13:45:02.893739  Formated the dates and times in the dataframe\n",
      "landmarks-2d-art-items-and-guides 13:45:02.965326  Wrote curated messages to xlsx files \n",
      "\n",
      "team-ux-ui-designers-medkids 13:45:02.965417  Set-up channel name and path to directory\n",
      "team-ux-ui-designers-medkids 13:45:03.569053  Collected channel messages from the json files\n",
      "team-ux-ui-designers-medkids 13:45:03.582898  Collected users in current channel\n",
      "team-ux-ui-designers-medkids 13:45:03.798730  Included the users information on channel_messages_df\n",
      "team-ux-ui-designers-medkids 13:45:04.242825  User's id replaced by their names in messages\n",
      "team-ux-ui-designers-medkids 13:45:05.416865  URLs extracted from messages\n",
      "main_analysys ->> team-ux-ui-designers-medkids    13:45:05.873427  Formated the dates and times in the dataframe\n",
      "team-ux-ui-designers-medkids 13:45:06.640505  Wrote curated messages to xlsx files \n",
      "\n",
      "team-cybersecurity-innovations 13:45:06.640553  Set-up channel name and path to directory\n",
      "team-cybersecurity-innovations 13:45:06.758392  Collected channel messages from the json files\n",
      "team-cybersecurity-innovations 13:45:06.771529  Collected users in current channel\n",
      "team-cybersecurity-innovations 13:45:06.825240  Included the users information on channel_messages_df\n",
      "team-cybersecurity-innovations 13:45:06.957197  User's id replaced by their names in messages\n",
      "team-cybersecurity-innovations 13:45:07.245992  URLs extracted from messages\n",
      "main_analysys ->> team-cybersecurity-innovations    13:45:07.358047  Formated the dates and times in the dataframe\n",
      "team-cybersecurity-innovations 13:45:07.596494  Wrote curated messages to xlsx files \n",
      "\n",
      "intros-and-shoutouts 13:45:07.596543  Set-up channel name and path to directory\n",
      "intros-and-shoutouts 13:45:07.745609  Collected channel messages from the json files\n",
      "intros-and-shoutouts 13:45:07.761111  Collected users in current channel\n",
      "intros-and-shoutouts 13:45:07.836979  Included the users information on channel_messages_df\n",
      "intros-and-shoutouts 13:45:07.987872  User's id replaced by their names in messages\n",
      "intros-and-shoutouts 13:45:08.169929  URLs extracted from messages\n",
      "main_analysys ->> intros-and-shoutouts    13:45:08.329869  Formated the dates and times in the dataframe\n",
      "intros-and-shoutouts 13:45:08.550225  Wrote curated messages to xlsx files \n",
      "\n",
      "team-animators-medkids 13:45:08.550275  Set-up channel name and path to directory\n",
      "team-animators-medkids 13:45:08.842058  Collected channel messages from the json files\n",
      "team-animators-medkids 13:45:08.855342  Collected users in current channel\n",
      "team-animators-medkids 13:45:08.960829  Included the users information on channel_messages_df\n",
      "team-animators-medkids 13:45:09.125969  User's id replaced by their names in messages\n",
      "team-animators-medkids 13:45:09.314517  URLs extracted from messages\n",
      "main_analysys ->> team-animators-medkids    13:45:09.528896  Formated the dates and times in the dataframe\n",
      "team-animators-medkids 13:45:09.822962  Wrote curated messages to xlsx files \n",
      "\n",
      "strategic-planning 13:45:09.823010  Set-up channel name and path to directory\n",
      "strategic-planning 13:45:09.922909  Collected channel messages from the json files\n",
      "strategic-planning 13:45:09.936125  Collected users in current channel\n",
      "strategic-planning 13:45:09.973539  Included the users information on channel_messages_df\n",
      "strategic-planning 13:45:10.082865  User's id replaced by their names in messages\n",
      "strategic-planning 13:45:10.339133  URLs extracted from messages\n",
      "main_analysys ->> strategic-planning    13:45:10.414253  Formated the dates and times in the dataframe\n",
      "strategic-planning 13:45:10.547836  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 13:45:10.547861  Set-up channel name and path to directory\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 13:45:14.140859  Collected channel messages from the json files\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 13:45:14.166904  Collected users in current channel\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 13:45:15.919742  Included the users information on channel_messages_df\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 13:45:17.729210  User's id replaced by their names in messages\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 13:45:20.216579  URLs extracted from messages\n",
      "main_analysys ->> aspects-tuition-reimbursement-scholarships-special-projects    13:45:23.389010  Formated the dates and times in the dataframe\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 13:45:28.519242  Wrote curated messages to xlsx files \n",
      "\n",
      "team-orderup-developers-medkids 13:45:28.519313  Set-up channel name and path to directory\n",
      "team-orderup-developers-medkids 13:45:28.948084  Collected channel messages from the json files\n",
      "team-orderup-developers-medkids 13:45:28.961530  Collected users in current channel\n",
      "team-orderup-developers-medkids 13:45:29.188723  Included the users information on channel_messages_df\n",
      "team-orderup-developers-medkids 13:45:29.714107  User's id replaced by their names in messages\n",
      "team-orderup-developers-medkids 13:45:30.218285  URLs extracted from messages\n",
      "main_analysys ->> team-orderup-developers-medkids    13:45:30.718322  Formated the dates and times in the dataframe\n",
      "team-orderup-developers-medkids 13:45:31.542746  Wrote curated messages to xlsx files \n",
      "\n",
      "team-chef-medkids 13:45:31.542797  Set-up channel name and path to directory\n",
      "team-chef-medkids 13:45:31.718544  Collected channel messages from the json files\n",
      "team-chef-medkids 13:45:31.731856  Collected users in current channel\n",
      "team-chef-medkids 13:45:31.810005  Included the users information on channel_messages_df\n",
      "team-chef-medkids 13:45:32.002329  User's id replaced by their names in messages\n",
      "team-chef-medkids 13:45:32.391624  URLs extracted from messages\n",
      "main_analysys ->> team-chef-medkids    13:45:32.555528  Formated the dates and times in the dataframe\n",
      "team-chef-medkids 13:45:32.769352  Wrote curated messages to xlsx files \n",
      "\n",
      "doodly-toonly-cartoons-medkids 13:45:32.769403  Set-up channel name and path to directory\n",
      "doodly-toonly-cartoons-medkids 13:45:32.815117  Collected channel messages from the json files\n",
      "doodly-toonly-cartoons-medkids 13:45:32.827979  Collected users in current channel\n",
      "doodly-toonly-cartoons-medkids 13:45:32.847751  Included the users information on channel_messages_df\n",
      "doodly-toonly-cartoons-medkids 13:45:32.870074  User's id replaced by their names in messages\n",
      "doodly-toonly-cartoons-medkids 13:45:32.942858  URLs extracted from messages\n",
      "main_analysys ->> doodly-toonly-cartoons-medkids    13:45:32.982987  Formated the dates and times in the dataframe\n",
      "doodly-toonly-cartoons-medkids 13:45:33.052608  Wrote curated messages to xlsx files \n",
      "\n",
      "team-bowen-medkids-games 13:45:33.052633  Set-up channel name and path to directory\n",
      "team-bowen-medkids-games 13:45:33.189541  Collected channel messages from the json files\n",
      "team-bowen-medkids-games 13:45:33.204335  Collected users in current channel\n",
      "team-bowen-medkids-games 13:45:33.258020  Included the users information on channel_messages_df\n",
      "team-bowen-medkids-games 13:45:33.326190  User's id replaced by their names in messages\n",
      "team-bowen-medkids-games 13:45:33.488384  URLs extracted from messages\n",
      "main_analysys ->> team-bowen-medkids-games    13:45:33.598140  Formated the dates and times in the dataframe\n",
      "team-bowen-medkids-games 13:45:33.828657  Wrote curated messages to xlsx files \n",
      "\n",
      "general 13:45:33.828719  Set-up channel name and path to directory\n",
      "general 13:45:36.280687  Collected channel messages from the json files\n",
      "general 13:45:36.309549  Collected users in current channel\n",
      "general 13:45:37.600182  Included the users information on channel_messages_df\n",
      "general 13:45:39.402702  User's id replaced by their names in messages\n",
      "general 13:45:42.778297  URLs extracted from messages\n",
      "main_analysys ->> general    13:45:45.016215  Formated the dates and times in the dataframe\n",
      "general 13:45:48.770913  Wrote curated messages to xlsx files \n",
      "\n",
      "champions 13:45:48.770974  Set-up channel name and path to directory\n",
      "champions 13:45:48.927817  Collected channel messages from the json files\n",
      "champions 13:45:48.941305  Collected users in current channel\n",
      "champions 13:45:49.005114  Included the users information on channel_messages_df\n",
      "champions 13:45:49.166402  User's id replaced by their names in messages\n",
      "champions 13:45:49.322316  URLs extracted from messages\n",
      "main_analysys ->> champions    13:45:49.457666  Formated the dates and times in the dataframe\n",
      "champions 13:45:49.637148  Wrote curated messages to xlsx files \n",
      "\n",
      "3d-art-team-a-landmarks 13:45:49.637172  Set-up channel name and path to directory\n",
      "3d-art-team-a-landmarks 13:45:50.017624  Collected channel messages from the json files\n",
      "3d-art-team-a-landmarks 13:45:50.031104  Collected users in current channel\n",
      "3d-art-team-a-landmarks 13:45:50.186611  Included the users information on channel_messages_df\n",
      "3d-art-team-a-landmarks 13:45:50.557337  User's id replaced by their names in messages\n",
      "3d-art-team-a-landmarks 13:45:50.870133  URLs extracted from messages\n",
      "main_analysys ->> 3d-art-team-a-landmarks    13:45:51.226702  Formated the dates and times in the dataframe\n",
      "3d-art-team-a-landmarks 13:45:51.831125  Wrote curated messages to xlsx files \n",
      "\n",
      "team-kamil-medkids-games 13:45:51.831171  Set-up channel name and path to directory\n",
      "team-kamil-medkids-games 13:45:52.111242  Collected channel messages from the json files\n",
      "team-kamil-medkids-games 13:45:52.125239  Collected users in current channel\n",
      "team-kamil-medkids-games 13:45:52.233306  Included the users information on channel_messages_df\n",
      "team-kamil-medkids-games 13:45:52.351734  User's id replaced by their names in messages\n",
      "team-kamil-medkids-games 13:45:52.575669  URLs extracted from messages\n",
      "main_analysys ->> team-kamil-medkids-games    13:45:52.801084  Formated the dates and times in the dataframe\n",
      "team-kamil-medkids-games 13:45:53.099755  Wrote curated messages to xlsx files \n",
      "\n",
      "20-team 13:45:53.099804  Set-up channel name and path to directory\n",
      "20-team 13:45:53.204011  Collected channel messages from the json files\n",
      "20-team 13:45:53.217129  Collected users in current channel\n",
      "20-team 13:45:53.257281  Included the users information on channel_messages_df\n",
      "20-team 13:45:53.343849  User's id replaced by their names in messages\n",
      "20-team 13:45:53.448326  URLs extracted from messages\n",
      "main_analysys ->> 20-team    13:45:53.540010  Formated the dates and times in the dataframe\n",
      "20-team 13:45:53.665115  Wrote curated messages to xlsx files \n",
      "\n",
      "FC_F05L6N323GV_无标题 13:45:53.665161  Set-up channel name and path to directory\n",
      "FC_F05L6N323GV_无标题 13:45:53.668626  Collected channel messages from the json files\n",
      "FC_F05L6N323GV_无标题 13:45:53.681496  Collected users in current channel\n",
      "FC_F05L6N323GV_无标题 13:45:53.683097  Included the users information on channel_messages_df\n",
      "FC_F05L6N323GV_无标题 13:45:53.683177  User's id replaced by their names in messages\n",
      "FC_F05L6N323GV_无标题 13:45:53.693937  URLs extracted from messages\n",
      "main_analysys ->> FC_F05L6N323GV_无标题    13:45:53.698361  Formated the dates and times in the dataframe\n",
      "FC_F05L6N323GV_无标题 13:45:53.712994  Wrote curated messages to xlsx files \n",
      "\n",
      "unequivocally-big-summer-2024 13:45:53.713013  Set-up channel name and path to directory\n",
      "unequivocally-big-summer-2024 13:45:53.846495  Collected channel messages from the json files\n",
      "unequivocally-big-summer-2024 13:45:53.859225  Collected users in current channel\n",
      "unequivocally-big-summer-2024 13:45:53.928622  Included the users information on channel_messages_df\n",
      "unequivocally-big-summer-2024 13:45:54.003405  User's id replaced by their names in messages\n",
      "unequivocally-big-summer-2024 13:45:54.251874  URLs extracted from messages\n",
      "main_analysys ->> unequivocally-big-summer-2024    13:45:54.379770  Formated the dates and times in the dataframe\n",
      "unequivocally-big-summer-2024 13:45:54.584304  Wrote curated messages to xlsx files \n",
      "\n",
      "team-jira 13:45:54.584345  Set-up channel name and path to directory\n",
      "team-jira 13:45:54.635837  Collected channel messages from the json files\n",
      "team-jira 13:45:54.649021  Collected users in current channel\n",
      "team-jira 13:45:54.668836  Included the users information on channel_messages_df\n",
      "team-jira 13:45:54.727131  User's id replaced by their names in messages\n",
      "team-jira 13:45:54.840881  URLs extracted from messages\n",
      "main_analysys ->> team-jira    13:45:54.883399  Formated the dates and times in the dataframe\n",
      "team-jira 13:45:54.952348  Wrote curated messages to xlsx files \n",
      "\n",
      "how-do-i 13:45:54.952377  Set-up channel name and path to directory\n",
      "how-do-i 13:45:54.957786  Collected channel messages from the json files\n",
      "how-do-i 13:45:54.970455  Collected users in current channel\n",
      "how-do-i 13:45:54.972770  Included the users information on channel_messages_df\n",
      "how-do-i 13:45:54.975558  User's id replaced by their names in messages\n",
      "how-do-i 13:45:54.986942  URLs extracted from messages\n",
      "main_analysys ->> how-do-i    13:45:54.992534  Formated the dates and times in the dataframe\n",
      "how-do-i 13:45:55.010111  Wrote curated messages to xlsx files \n",
      "\n",
      "3d-art-blender-landmarks 13:45:55.010140  Set-up channel name and path to directory\n",
      "3d-art-blender-landmarks 13:45:56.629198  Collected channel messages from the json files\n",
      "3d-art-blender-landmarks 13:45:56.644478  Collected users in current channel\n",
      "3d-art-blender-landmarks 13:45:57.374225  Included the users information on channel_messages_df\n",
      "3d-art-blender-landmarks 13:45:58.764087  User's id replaced by their names in messages\n",
      "3d-art-blender-landmarks 13:46:00.254441  URLs extracted from messages\n",
      "main_analysys ->> 3d-art-blender-landmarks    13:46:01.794948  Formated the dates and times in the dataframe\n",
      "3d-art-blender-landmarks 13:46:04.222106  Wrote curated messages to xlsx files \n",
      "\n",
      "pm-tl-channel 13:46:04.222159  Set-up channel name and path to directory\n",
      "pm-tl-channel 13:46:04.358416  Collected channel messages from the json files\n",
      "pm-tl-channel 13:46:04.371586  Collected users in current channel\n",
      "pm-tl-channel 13:46:04.432238  Included the users information on channel_messages_df\n",
      "pm-tl-channel 13:46:04.527181  User's id replaced by their names in messages\n",
      "pm-tl-channel 13:46:04.759914  URLs extracted from messages\n",
      "main_analysys ->> pm-tl-channel    13:46:04.883619  Formated the dates and times in the dataframe\n",
      "pm-tl-channel 13:46:05.080358  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-unity-developers 13:46:05.080451  Set-up channel name and path to directory\n",
      "landmarks-unity-developers 13:46:05.716195  Collected channel messages from the json files\n",
      "landmarks-unity-developers 13:46:05.730861  Collected users in current channel\n",
      "landmarks-unity-developers 13:46:06.007750  Included the users information on channel_messages_df\n",
      "landmarks-unity-developers 13:46:06.438483  User's id replaced by their names in messages\n",
      "landmarks-unity-developers 13:46:07.222956  URLs extracted from messages\n",
      "main_analysys ->> landmarks-unity-developers    13:46:07.801714  Formated the dates and times in the dataframe\n",
      "landmarks-unity-developers 13:46:08.784309  Wrote curated messages to xlsx files \n",
      "\n",
      "real-estate-verification 13:46:08.784359  Set-up channel name and path to directory\n",
      "real-estate-verification 13:46:08.875920  Collected channel messages from the json files\n",
      "real-estate-verification 13:46:08.889982  Collected users in current channel\n",
      "real-estate-verification 13:46:08.924457  Included the users information on channel_messages_df\n",
      "real-estate-verification 13:46:08.961682  User's id replaced by their names in messages\n",
      "real-estate-verification 13:46:09.125489  URLs extracted from messages\n",
      "main_analysys ->> real-estate-verification    13:46:09.196227  Formated the dates and times in the dataframe\n",
      "real-estate-verification 13:46:09.301023  Wrote curated messages to xlsx files \n",
      "\n",
      "think-biver-saturday-checkins 13:46:09.301045  Set-up channel name and path to directory\n",
      "think-biver-saturday-checkins 13:46:12.438084  Collected channel messages from the json files\n",
      "think-biver-saturday-checkins 13:46:12.467884  Collected users in current channel\n",
      "think-biver-saturday-checkins 13:46:14.408856  Included the users information on channel_messages_df\n",
      "think-biver-saturday-checkins 13:46:16.779460  User's id replaced by their names in messages\n",
      "think-biver-saturday-checkins 13:46:22.469696  URLs extracted from messages\n",
      "main_analysys ->> think-biver-saturday-checkins    13:46:25.664909  Formated the dates and times in the dataframe\n",
      "think-biver-saturday-checkins 13:46:31.306269  Wrote curated messages to xlsx files \n",
      "\n",
      "tracker-board 13:46:31.306378  Set-up channel name and path to directory\n",
      "tracker-board 13:46:31.470884  Collected channel messages from the json files\n",
      "tracker-board 13:46:31.484133  Collected users in current channel\n",
      "tracker-board 13:46:31.559651  Included the users information on channel_messages_df\n",
      "tracker-board 13:46:31.638169  User's id replaced by their names in messages\n",
      "tracker-board 13:46:32.027366  URLs extracted from messages\n",
      "main_analysys ->> tracker-board    13:46:32.177907  Formated the dates and times in the dataframe\n",
      "tracker-board 13:46:32.600282  Wrote curated messages to xlsx files \n",
      "\n",
      "unequivocally-big-summer-2023 13:46:32.600333  Set-up channel name and path to directory\n",
      "unequivocally-big-summer-2023 13:46:33.112474  Collected channel messages from the json files\n",
      "unequivocally-big-summer-2023 13:46:33.129764  Collected users in current channel\n",
      "unequivocally-big-summer-2023 13:46:33.521773  Included the users information on channel_messages_df\n",
      "unequivocally-big-summer-2023 13:46:33.721729  User's id replaced by their names in messages\n",
      "unequivocally-big-summer-2023 13:46:34.288252  URLs extracted from messages\n",
      "main_analysys ->> unequivocally-big-summer-2023    13:46:34.850478  Formated the dates and times in the dataframe\n",
      "unequivocally-big-summer-2023 13:46:35.705291  Wrote curated messages to xlsx files \n",
      "\n",
      "budget-template-build 13:46:35.705342  Set-up channel name and path to directory\n",
      "budget-template-build 13:46:35.827947  Collected channel messages from the json files\n",
      "budget-template-build 13:46:35.841976  Collected users in current channel\n",
      "budget-template-build 13:46:35.911396  Included the users information on channel_messages_df\n",
      "budget-template-build 13:46:36.039631  User's id replaced by their names in messages\n",
      "budget-template-build 13:46:36.187789  URLs extracted from messages\n",
      "main_analysys ->> budget-template-build    13:46:36.370014  Formated the dates and times in the dataframe\n",
      "budget-template-build 13:46:36.597324  Wrote curated messages to xlsx files \n",
      "\n",
      "social-media-branding-team 13:46:36.597381  Set-up channel name and path to directory\n",
      "social-media-branding-team 13:46:36.758925  Collected channel messages from the json files\n",
      "social-media-branding-team 13:46:36.776934  Collected users in current channel\n",
      "social-media-branding-team 13:46:36.852520  Included the users information on channel_messages_df\n",
      "social-media-branding-team 13:46:37.015374  User's id replaced by their names in messages\n",
      "social-media-branding-team 13:46:37.440977  URLs extracted from messages\n",
      "main_analysys ->> social-media-branding-team    13:46:37.572574  Formated the dates and times in the dataframe\n",
      "social-media-branding-team 13:46:37.750495  Wrote curated messages to xlsx files \n",
      "\n",
      "team-infographics-and-charting 13:46:37.750550  Set-up channel name and path to directory\n",
      "team-infographics-and-charting 13:46:38.822284  Collected channel messages from the json files\n",
      "team-infographics-and-charting 13:46:38.837392  Collected users in current channel\n",
      "team-infographics-and-charting 13:46:39.300797  Included the users information on channel_messages_df\n",
      "team-infographics-and-charting 13:46:40.276990  User's id replaced by their names in messages\n",
      "team-infographics-and-charting 13:46:41.547005  URLs extracted from messages\n",
      "main_analysys ->> team-infographics-and-charting    13:46:42.711546  Formated the dates and times in the dataframe\n",
      "team-infographics-and-charting 13:46:44.362529  Wrote curated messages to xlsx files \n",
      "\n",
      "campaign-ret 13:46:44.362584  Set-up channel name and path to directory\n",
      "campaign-ret 13:46:44.641086  Collected channel messages from the json files\n",
      "campaign-ret 13:46:44.659937  Collected users in current channel\n",
      "campaign-ret 13:46:44.767600  Included the users information on channel_messages_df\n",
      "campaign-ret 13:46:45.033279  User's id replaced by their names in messages\n",
      "campaign-ret 13:46:45.161528  URLs extracted from messages\n",
      "main_analysys ->> campaign-ret    13:46:45.377021  Formated the dates and times in the dataframe\n",
      "campaign-ret 13:46:45.721201  Wrote curated messages to xlsx files \n",
      "\n",
      "random 13:46:45.721282  Set-up channel name and path to directory\n",
      "random 13:46:46.782206  Collected channel messages from the json files\n",
      "random 13:46:46.817076  Collected users in current channel\n",
      "random 13:46:47.183750  Included the users information on channel_messages_df\n",
      "random 13:46:48.012772  User's id replaced by their names in messages\n",
      "random 13:46:48.250974  URLs extracted from messages\n",
      "main_analysys ->> random    13:46:48.847718  Formated the dates and times in the dataframe\n",
      "random 13:46:49.862027  Wrote curated messages to xlsx files \n",
      "\n",
      "team-chef-logistics-medkids 13:46:49.862079  Set-up channel name and path to directory\n",
      "team-chef-logistics-medkids 13:46:49.985180  Collected channel messages from the json files\n",
      "team-chef-logistics-medkids 13:46:50.000475  Collected users in current channel\n",
      "team-chef-logistics-medkids 13:46:50.061166  Included the users information on channel_messages_df\n",
      "team-chef-logistics-medkids 13:46:50.153773  User's id replaced by their names in messages\n",
      "team-chef-logistics-medkids 13:46:50.451014  URLs extracted from messages\n",
      "main_analysys ->> team-chef-logistics-medkids    13:46:50.574103  Formated the dates and times in the dataframe\n",
      "team-chef-logistics-medkids 13:46:50.759718  Wrote curated messages to xlsx files \n",
      "\n",
      "cpts-strategy-team 13:46:50.759746  Set-up channel name and path to directory\n",
      "cpts-strategy-team 13:46:50.862641  Collected channel messages from the json files\n",
      "cpts-strategy-team 13:46:50.878476  Collected users in current channel\n",
      "cpts-strategy-team 13:46:50.924705  Included the users information on channel_messages_df\n",
      "cpts-strategy-team 13:46:51.025509  User's id replaced by their names in messages\n",
      "cpts-strategy-team 13:46:51.326281  URLs extracted from messages\n",
      "main_analysys ->> cpts-strategy-team    13:46:51.403244  Formated the dates and times in the dataframe\n",
      "cpts-strategy-team 13:46:51.517736  Wrote curated messages to xlsx files \n",
      "\n",
      "3d-art-team-b-landmarks 13:46:51.517759  Set-up channel name and path to directory\n",
      "3d-art-team-b-landmarks 13:46:51.781040  Collected channel messages from the json files\n",
      "3d-art-team-b-landmarks 13:46:51.796052  Collected users in current channel\n",
      "3d-art-team-b-landmarks 13:46:51.906933  Included the users information on channel_messages_df\n",
      "3d-art-team-b-landmarks 13:46:52.170197  User's id replaced by their names in messages\n",
      "3d-art-team-b-landmarks 13:46:52.460621  URLs extracted from messages\n",
      "main_analysys ->> 3d-art-team-b-landmarks    13:46:52.718040  Formated the dates and times in the dataframe\n",
      "3d-art-team-b-landmarks 13:46:53.054518  Wrote curated messages to xlsx files \n",
      "\n",
      "unequivocally-big-suite-content-team 13:46:53.054573  Set-up channel name and path to directory\n",
      "unequivocally-big-suite-content-team 13:46:53.196631  Collected channel messages from the json files\n",
      "unequivocally-big-suite-content-team 13:46:53.213547  Collected users in current channel\n",
      "unequivocally-big-suite-content-team 13:46:53.272317  Included the users information on channel_messages_df\n",
      "unequivocally-big-suite-content-team 13:46:53.407023  User's id replaced by their names in messages\n",
      "unequivocally-big-suite-content-team 13:46:53.630436  URLs extracted from messages\n",
      "main_analysys ->> unequivocally-big-suite-content-team    13:46:53.738333  Formated the dates and times in the dataframe\n",
      "unequivocally-big-suite-content-team 13:46:54.061421  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-ux-meeting-notes 13:46:54.061481  Set-up channel name and path to directory\n",
      "landmarks-ux-meeting-notes 13:46:54.103400  Collected channel messages from the json files\n",
      "landmarks-ux-meeting-notes 13:46:54.122638  Collected users in current channel\n",
      "landmarks-ux-meeting-notes 13:46:54.141430  Included the users information on channel_messages_df\n",
      "landmarks-ux-meeting-notes 13:46:54.179959  User's id replaced by their names in messages\n",
      "landmarks-ux-meeting-notes 13:46:54.292739  URLs extracted from messages\n",
      "main_analysys ->> landmarks-ux-meeting-notes    13:46:54.328283  Formated the dates and times in the dataframe\n",
      "landmarks-ux-meeting-notes 13:46:54.399673  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-content-development 13:46:54.399707  Set-up channel name and path to directory\n",
      "landmarks-content-development 13:46:54.506372  Collected channel messages from the json files\n",
      "landmarks-content-development 13:46:54.533544  Collected users in current channel\n",
      "landmarks-content-development 13:46:54.574182  Included the users information on channel_messages_df\n",
      "landmarks-content-development 13:46:54.636522  User's id replaced by their names in messages\n",
      "landmarks-content-development 13:46:54.876493  URLs extracted from messages\n",
      "main_analysys ->> landmarks-content-development    13:46:54.961412  Formated the dates and times in the dataframe\n",
      "landmarks-content-development 13:46:55.083690  Wrote curated messages to xlsx files \n",
      "\n",
      "team-leads 13:46:55.083754  Set-up channel name and path to directory\n",
      "team-leads 13:46:55.138722  Collected channel messages from the json files\n",
      "team-leads 13:46:55.159890  Collected users in current channel\n",
      "team-leads 13:46:55.184034  Included the users information on channel_messages_df\n",
      "team-leads 13:46:55.239913  User's id replaced by their names in messages\n",
      "team-leads 13:46:55.333720  URLs extracted from messages\n",
      "main_analysys ->> team-leads    13:46:55.378257  Formated the dates and times in the dataframe\n",
      "team-leads 13:46:55.468616  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-data-analysis 13:46:55.468647  Set-up channel name and path to directory\n",
      "aspects-data-analysis 13:46:55.655991  Collected channel messages from the json files\n",
      "aspects-data-analysis 13:46:55.680232  Collected users in current channel\n",
      "aspects-data-analysis 13:46:55.755861  Included the users information on channel_messages_df\n",
      "aspects-data-analysis 13:46:55.824435  User's id replaced by their names in messages\n",
      "aspects-data-analysis 13:46:55.997311  URLs extracted from messages\n",
      "main_analysys ->> aspects-data-analysis    13:46:56.110208  Formated the dates and times in the dataframe\n",
      "aspects-data-analysis 13:46:56.266974  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-uxreview-gd-dev 13:46:56.266998  Set-up channel name and path to directory\n",
      "landmarks-uxreview-gd-dev 13:46:56.303207  Collected channel messages from the json files\n",
      "landmarks-uxreview-gd-dev 13:46:56.317602  Collected users in current channel\n",
      "landmarks-uxreview-gd-dev 13:46:56.332676  Included the users information on channel_messages_df\n",
      "landmarks-uxreview-gd-dev 13:46:56.359294  User's id replaced by their names in messages\n",
      "landmarks-uxreview-gd-dev 13:46:56.414508  URLs extracted from messages\n",
      "main_analysys ->> landmarks-uxreview-gd-dev    13:46:56.446046  Formated the dates and times in the dataframe\n",
      "landmarks-uxreview-gd-dev 13:46:56.498511  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-sprints-2d-art 13:46:56.498533  Set-up channel name and path to directory\n",
      "landmarks-sprints-2d-art 13:46:56.522275  Collected channel messages from the json files\n",
      "landmarks-sprints-2d-art 13:46:56.535868  Collected users in current channel\n",
      "landmarks-sprints-2d-art 13:46:56.546788  Included the users information on channel_messages_df\n",
      "landmarks-sprints-2d-art 13:46:56.567206  User's id replaced by their names in messages\n",
      "landmarks-sprints-2d-art 13:46:56.589269  URLs extracted from messages\n",
      "main_analysys ->> landmarks-sprints-2d-art    13:46:56.611703  Formated the dates and times in the dataframe\n",
      "landmarks-sprints-2d-art 13:46:56.659445  Wrote curated messages to xlsx files \n",
      "\n",
      "artxdev-team 13:46:56.659470  Set-up channel name and path to directory\n",
      "artxdev-team 13:46:56.714102  Collected channel messages from the json files\n",
      "artxdev-team 13:46:56.729126  Collected users in current channel\n",
      "artxdev-team 13:46:56.752026  Included the users information on channel_messages_df\n",
      "artxdev-team 13:46:56.798203  User's id replaced by their names in messages\n",
      "artxdev-team 13:46:56.855179  URLs extracted from messages\n",
      "main_analysys ->> artxdev-team    13:46:56.908946  Formated the dates and times in the dataframe\n",
      "artxdev-team 13:46:56.993489  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-product-managers 13:46:56.993518  Set-up channel name and path to directory\n",
      "landmarks-product-managers 13:46:57.069189  Collected channel messages from the json files\n",
      "landmarks-product-managers 13:46:57.086446  Collected users in current channel\n",
      "landmarks-product-managers 13:46:57.119750  Included the users information on channel_messages_df\n",
      "landmarks-product-managers 13:46:57.197292  User's id replaced by their names in messages\n",
      "landmarks-product-managers 13:46:57.324350  URLs extracted from messages\n",
      "main_analysys ->> landmarks-product-managers    13:46:57.432856  Formated the dates and times in the dataframe\n",
      "landmarks-product-managers 13:46:57.543607  Wrote curated messages to xlsx files \n",
      "\n",
      "chief-of-chatting-space 13:46:57.543636  Set-up channel name and path to directory\n",
      "chief-of-chatting-space 13:46:57.884107  Collected channel messages from the json files\n",
      "chief-of-chatting-space 13:46:57.902925  Collected users in current channel\n",
      "chief-of-chatting-space 13:46:58.048812  Included the users information on channel_messages_df\n",
      "chief-of-chatting-space 13:46:58.298012  User's id replaced by their names in messages\n",
      "chief-of-chatting-space 13:46:58.626937  URLs extracted from messages\n",
      "main_analysys ->> chief-of-chatting-space    13:46:58.897546  Formated the dates and times in the dataframe\n",
      "chief-of-chatting-space 13:46:59.308966  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-forward 13:46:59.309011  Set-up channel name and path to directory\n",
      "landmarks-forward 13:47:00.326750  Collected channel messages from the json files\n",
      "landmarks-forward 13:47:00.341996  Collected users in current channel\n",
      "landmarks-forward 13:47:00.868091  Included the users information on channel_messages_df\n",
      "landmarks-forward 13:47:01.923111  User's id replaced by their names in messages\n",
      "landmarks-forward 13:47:03.105167  URLs extracted from messages\n",
      "main_analysys ->> landmarks-forward    13:47:04.322610  Formated the dates and times in the dataframe\n",
      "landmarks-forward 13:47:05.992679  Wrote curated messages to xlsx files \n",
      "\n",
      "licensing 13:47:05.992730  Set-up channel name and path to directory\n",
      "licensing 13:47:06.048871  Collected channel messages from the json files\n",
      "licensing 13:47:06.062305  Collected users in current channel\n",
      "licensing 13:47:06.085629  Included the users information on channel_messages_df\n",
      "licensing 13:47:06.131904  User's id replaced by their names in messages\n",
      "licensing 13:47:06.232325  URLs extracted from messages\n",
      "main_analysys ->> licensing    13:47:06.279975  Formated the dates and times in the dataframe\n",
      "licensing 13:47:06.357331  Wrote curated messages to xlsx files \n",
      "\n",
      "team-anatomy-island-for-medkids 13:47:06.357371  Set-up channel name and path to directory\n",
      "team-anatomy-island-for-medkids 13:47:08.170572  Collected channel messages from the json files\n",
      "team-anatomy-island-for-medkids 13:47:08.187293  Collected users in current channel\n",
      "team-anatomy-island-for-medkids 13:47:09.005146  Included the users information on channel_messages_df\n",
      "team-anatomy-island-for-medkids 13:47:10.444329  User's id replaced by their names in messages\n",
      "team-anatomy-island-for-medkids 13:47:13.034391  URLs extracted from messages\n",
      "main_analysys ->> team-anatomy-island-for-medkids    13:47:14.833563  Formated the dates and times in the dataframe\n",
      "team-anatomy-island-for-medkids 13:47:17.477480  Wrote curated messages to xlsx files \n",
      "\n",
      "onboarding-central 13:47:17.477536  Set-up channel name and path to directory\n",
      "onboarding-central 13:47:17.507819  Collected channel messages from the json files\n",
      "onboarding-central 13:47:17.521129  Collected users in current channel\n",
      "onboarding-central 13:47:17.536782  Included the users information on channel_messages_df\n",
      "onboarding-central 13:47:17.568042  User's id replaced by their names in messages\n",
      "onboarding-central 13:47:17.608586  URLs extracted from messages\n",
      "main_analysys ->> onboarding-central    13:47:17.640766  Formated the dates and times in the dataframe\n",
      "onboarding-central 13:47:17.695820  Wrote curated messages to xlsx files \n",
      "\n",
      "team-github-solutions 13:47:17.695860  Set-up channel name and path to directory\n",
      "team-github-solutions 13:47:18.096040  Collected channel messages from the json files\n",
      "team-github-solutions 13:47:18.109862  Collected users in current channel\n",
      "team-github-solutions 13:47:18.337516  Included the users information on channel_messages_df\n",
      "team-github-solutions 13:47:18.628909  User's id replaced by their names in messages\n",
      "team-github-solutions 13:47:19.149789  URLs extracted from messages\n",
      "main_analysys ->> team-github-solutions    13:47:19.609690  Formated the dates and times in the dataframe\n",
      "team-github-solutions 13:47:20.255691  Wrote curated messages to xlsx files \n",
      "\n",
      "team-issues-medkids 13:47:20.255797  Set-up channel name and path to directory\n",
      "team-issues-medkids 13:47:20.474026  Collected channel messages from the json files\n",
      "team-issues-medkids 13:47:20.497819  Collected users in current channel\n",
      "team-issues-medkids 13:47:20.605781  Included the users information on channel_messages_df\n",
      "team-issues-medkids 13:47:20.811877  User's id replaced by their names in messages\n",
      "team-issues-medkids 13:47:21.086082  URLs extracted from messages\n",
      "main_analysys ->> team-issues-medkids    13:47:21.248764  Formated the dates and times in the dataframe\n",
      "team-issues-medkids 13:47:21.624305  Wrote curated messages to xlsx files \n",
      "\n",
      "team-budgets 13:47:21.624349  Set-up channel name and path to directory\n",
      "team-budgets 13:47:21.633609  Collected channel messages from the json files\n",
      "team-budgets 13:47:21.646597  Collected users in current channel\n",
      "team-budgets 13:47:21.650593  Included the users information on channel_messages_df\n",
      "team-budgets 13:47:21.661712  User's id replaced by their names in messages\n",
      "team-budgets 13:47:21.691127  URLs extracted from messages\n",
      "main_analysys ->> team-budgets    13:47:21.699870  Formated the dates and times in the dataframe\n",
      "team-budgets 13:47:21.720457  Wrote curated messages to xlsx files \n",
      "\n",
      "team-medkids-minitours 13:47:21.720476  Set-up channel name and path to directory\n",
      "team-medkids-minitours 13:47:21.723157  Collected channel messages from the json files\n",
      "team-medkids-minitours 13:47:21.736046  Collected users in current channel\n",
      "team-medkids-minitours 13:47:21.737315  Included the users information on channel_messages_df\n",
      "team-medkids-minitours 13:47:21.738194  User's id replaced by their names in messages\n",
      "team-medkids-minitours 13:47:21.748684  URLs extracted from messages\n",
      "main_analysys ->> team-medkids-minitours    13:47:21.752415  Formated the dates and times in the dataframe\n",
      "team-medkids-minitours 13:47:21.765890  Wrote curated messages to xlsx files \n",
      "\n",
      "team-voiceover-artists-med-kids 13:47:21.765908  Set-up channel name and path to directory\n",
      "team-voiceover-artists-med-kids 13:47:23.181624  Collected channel messages from the json files\n",
      "team-voiceover-artists-med-kids 13:47:23.197781  Collected users in current channel\n",
      "team-voiceover-artists-med-kids 13:47:23.871989  Included the users information on channel_messages_df\n",
      "team-voiceover-artists-med-kids 13:47:24.906164  User's id replaced by their names in messages\n",
      "team-voiceover-artists-med-kids 13:47:26.606007  URLs extracted from messages\n",
      "main_analysys ->> team-voiceover-artists-med-kids    13:47:27.864158  Formated the dates and times in the dataframe\n",
      "team-voiceover-artists-med-kids 13:47:29.810439  Wrote curated messages to xlsx files \n",
      "\n",
      "team-zixi-medkids-games 13:47:29.810491  Set-up channel name and path to directory\n",
      "team-zixi-medkids-games 13:47:29.981024  Collected channel messages from the json files\n",
      "team-zixi-medkids-games 13:47:29.996254  Collected users in current channel\n",
      "team-zixi-medkids-games 13:47:30.075706  Included the users information on channel_messages_df\n",
      "team-zixi-medkids-games 13:47:30.241649  User's id replaced by their names in messages\n",
      "team-zixi-medkids-games 13:47:30.464568  URLs extracted from messages\n",
      "main_analysys ->> team-zixi-medkids-games    13:47:30.677626  Formated the dates and times in the dataframe\n",
      "team-zixi-medkids-games 13:47:30.932013  Wrote curated messages to xlsx files \n",
      "\n",
      "13:47:30.932218 Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>msg_date</th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>reply_users_count</th>\n",
       "      <th>latest_reply_date</th>\n",
       "      <th>thread_date</th>\n",
       "      <th>parent_user_id</th>\n",
       "      <th>json_name</th>\n",
       "      <th>json_mod_date</th>\n",
       "      <th>channel_folder</th>\n",
       "      <th>name</th>\n",
       "      <th>display_name</th>\n",
       "      <th>is_bot</th>\n",
       "      <th>deactivated</th>\n",
       "      <th>URL(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3c3e415c-f661-4f73-89d3-2edcb5dcd1c1</td>\n",
       "      <td>2023-10-22 12:09:37</td>\n",
       "      <td>U02063W7Z1V</td>\n",
       "      <td>message</td>\n",
       "      <td>Hi @Zixi (Vic) Liu@\\n\\nI'm introducing @Rahul ...</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-10-22.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>ask</td>\n",
       "      <td>Tamara C. Daniels</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98dcef55-5df5-4042-ac8f-1fc809e9ebb5</td>\n",
       "      <td>2023-10-24 22:32:55</td>\n",
       "      <td>U02063W7Z1V</td>\n",
       "      <td>message</td>\n",
       "      <td>Just checking in here. Have you two had an opp...</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-10-24.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>ask</td>\n",
       "      <td>Tamara C. Daniels</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Monday.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fae3ab87-4f6c-427d-a79c-c126b00fc8e8</td>\n",
       "      <td>2023-10-24 22:33:53</td>\n",
       "      <td>U02063W7Z1V</td>\n",
       "      <td>message</td>\n",
       "      <td>Doesn't look like you've been on there either ...</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-10-24.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>ask</td>\n",
       "      <td>Tamara C. Daniels</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A92A2C9E-37C5-4448-93AA-2FD26CA56E34</td>\n",
       "      <td>2023-10-24 23:31:10</td>\n",
       "      <td>U05KTJ0H540</td>\n",
       "      <td>message</td>\n",
       "      <td>Ahh I just received the notice weirdly enough....</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-10-24.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>vic.zixi.liu</td>\n",
       "      <td>Zixi (Vic) Liu</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>channel_join</td>\n",
       "      <td>2023-11-04 14:51:42</td>\n",
       "      <td>U0648871JG3</td>\n",
       "      <td>message</td>\n",
       "      <td>@Mark Fang@ has joined the channel</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-11-04.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>markdfang</td>\n",
       "      <td>Mark Fang</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 msg_id             msg_date         user  \\\n",
       "0  3c3e415c-f661-4f73-89d3-2edcb5dcd1c1  2023-10-22 12:09:37  U02063W7Z1V   \n",
       "1  98dcef55-5df5-4042-ac8f-1fc809e9ebb5  2023-10-24 22:32:55  U02063W7Z1V   \n",
       "2  fae3ab87-4f6c-427d-a79c-c126b00fc8e8  2023-10-24 22:33:53  U02063W7Z1V   \n",
       "3  A92A2C9E-37C5-4448-93AA-2FD26CA56E34  2023-10-24 23:31:10  U05KTJ0H540   \n",
       "4                          channel_join  2023-11-04 14:51:42  U0648871JG3   \n",
       "\n",
       "      type                                               text reply_count  \\\n",
       "0  message  Hi @Zixi (Vic) Liu@\\n\\nI'm introducing @Rahul ...         n/d   \n",
       "1  message  Just checking in here. Have you two had an opp...         n/d   \n",
       "2  message  Doesn't look like you've been on there either ...         n/d   \n",
       "3  message  Ahh I just received the notice weirdly enough....         n/d   \n",
       "4  message                 @Mark Fang@ has joined the channel         n/d   \n",
       "\n",
       "  reply_users_count latest_reply_date thread_date parent_user_id  \\\n",
       "0               n/d               n/d         n/d            n/d   \n",
       "1               n/d               n/d         n/d            n/d   \n",
       "2               n/d               n/d         n/d            n/d   \n",
       "3               n/d               n/d         n/d            n/d   \n",
       "4               n/d               n/d         n/d            n/d   \n",
       "\n",
       "         json_name        json_mod_date           channel_folder  \\\n",
       "0  2023-10-22.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "1  2023-10-24.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "2  2023-10-24.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "3  2023-10-24.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "4  2023-11-04.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "\n",
       "           name       display_name is_bot deactivated      URL(s)  \n",
       "0           ask  Tamara C. Daniels  False       False              \n",
       "1           ask  Tamara C. Daniels  False       False  Monday.com  \n",
       "2           ask  Tamara C. Daniels  False       False              \n",
       "3  vic.zixi.liu     Zixi (Vic) Liu  False        True              \n",
       "4     markdfang          Mark Fang  False        True              "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##-- Main analysis:\n",
    "if continue_analysis==False:\n",
    "    print(\"Please review the input information\")\n",
    "else:    \n",
    "    print(datetime.now().time(), 'Started analysis after sanity checks' )\n",
    "    print(\"slackexport_folder_path =>> \"+slackexport_folder_path)\n",
    "    ##-- Extract the channels and users information into dataframes:\n",
    "    channels_df = get_all_channels_info(slackexport_folder_path)\n",
    "    print(datetime.now().time(), 'Obtained channels_df')\n",
    "    users_df = get_all_users_info(slackexport_folder_path)\n",
    "    print(datetime.now().time(), 'Obtained users_df')\n",
    "    \n",
    "    ##-- Write all channel's info to .xlsx files, if requested by user:\n",
    "    if write_all_channels_info==True:\n",
    "        slack_export_channel_filename = \"_all_channels\"\n",
    "        slack_export_channel_folder_path_xlsx = f\"{converted_directory}/{slack_export_channel_filename}{'.xlsx'}\"\n",
    "        channels_df.to_excel(slack_export_channel_folder_path_xlsx, index=False)\n",
    "        print(datetime.now().time(), 'Wrote channels_df to xlsx file')  \n",
    "    \n",
    "    ##-- Write all users's info to .xlsx files, if requested by user:\n",
    "    if write_all_users_info==True:\n",
    "        slack_export_user_filename = \"_all_users\"        \n",
    "        slack_export_user_folder_path_xlsx = f\"{converted_directory}/{slack_export_user_filename}{'.xlsx'}\" #_IP\n",
    "        users_df.to_excel(slack_export_user_folder_path_xlsx, index=False) #_IP\n",
    "        print(datetime.now().time(), 'Wrote users_df to xlsx file')\n",
    "\n",
    "    ##-- Iterate over channel's folders:\n",
    "    dfs_list = []\n",
    "    print(datetime.now().time(), 'Starting loop over channels', '\\n')\n",
    "    for i_channel in range(len(channels_names)):\n",
    "\n",
    "        ##-- Define the name of the current channel and the source path containing its json files:\n",
    "        curr_channel_name = channels_names[i_channel] \n",
    "        parentfolder_path = f\"{slackexport_folder_path}/{curr_channel_name}\" \n",
    "        print(curr_channel_name, datetime.now().time(), ' Set-up channel name and path to directory')\n",
    "        \n",
    "        ##-- Collect all the current_channel's messages in channel_messages_df through the function get_channel_messages_df:\n",
    "        json_list = all_channels_jsonFiles_dates[i_channel]\n",
    "        channel_messages_df = get_channel_messages_df(slackexport_folder_path, curr_channel_name, json_list)  \n",
    "        print(curr_channel_name, datetime.now().time(), ' Collected channel messages from the json files')\n",
    "        #\n",
    "        #IP20241121 move to separate folders-without-messages-JSONs\n",
    "        if len(channel_messages_df)<1:\n",
    "            print(\"for the folder \",curr_channel_name,\"messages_number= \",len(channel_messages_df),\"there is no channel's folder\", '\\n')\n",
    "            continue    \n",
    "\n",
    "        ##-- Collect all the users in the current channel through the function get_channel_users_df:\n",
    "        channel_users_df = get_channel_users_df(channel_messages_df, users_df )\n",
    "        print(curr_channel_name, datetime.now().time(), ' Collected users in current channel')\n",
    "        \n",
    "        ##-- Use channel_users_df to fill-in the user's information in channel_messages_df: \n",
    "        add_users_info_to_messages(channel_messages_df, channel_users_df)\n",
    "        print(curr_channel_name, datetime.now().time(), ' Included the users information on channel_messages_df')\n",
    "        \n",
    "        ##-- Replace user and team identifiers with their display_names whenever present in a message:\n",
    "        #user_id_to_name(channel_messages_df, users_df) \n",
    "        user_id_to_name(channel_messages_df, users_df) \n",
    "        channel_id_to_name(channel_messages_df, users_df)\n",
    "        parent_user_id_to_name(channel_messages_df, users_df) #AG20241122: routine defined in its own function\n",
    "        print(curr_channel_name, datetime.now().time(), \" User's id replaced by their names in messages\")\n",
    "\n",
    "        ##-- Extract hyperlinks from messages, if present (extracted as a list; edit if needed):\n",
    "        extract_urls(channel_messages_df)\n",
    "        print(curr_channel_name, datetime.now().time(), ' URLs extracted from messages')\n",
    "\n",
    "        ##-- Change format of the time in seconds to a date in the CST time-zone: (Pending 'ts_latest_reply' and 'ts_thread'!)\n",
    "        #channel_messages_mindate = pd.to_datetime(np.float64(channel_messages_df['ts']), unit='s').min().date()   #AG20241120: Can be deleted\n",
    "        #channel_messages_maxdate = pd.to_datetime(np.float64(channel_messages_df['ts']), unit='s').max().date()   #AG20241120: Can be deleted\n",
    "        ts_to_tz(channel_messages_df, 'ts', 'msg_date')\n",
    "        ts_to_tz(channel_messages_df, 'json_mod_ts', 'json_mod_date')\n",
    "        ts_to_tz(channel_messages_df, 'ts_latest_reply', 'latest_reply_date')\n",
    "        ts_to_tz(channel_messages_df, 'ts_thread', 'thread_date')\n",
    "        print('main_analysys ->>',curr_channel_name, \"  \", datetime.now().time(), ' Formated the dates and times in the dataframe')\n",
    "            \n",
    "        ##-- Reorder the columns in channel_messages_df, if necessary:\n",
    "        #channel_messages_df = channel_messages_df[['channel', 'json_name', 'json_mod_date', 'user', 'name', 'display_name', 'ts', 'msg_id', 'type', 'text']]\n",
    "        #channel_messages_df.index = ['']*len(channel_messages_df)\n",
    "        \n",
    "        ##-- Sort the dataframe by msg_date:\n",
    "        channel_messages_df.sort_values(by='msg_date', inplace=True, ignore_index=True)\n",
    "        \n",
    "        ##-- Write channel_messages_df to a .xlsx file:\n",
    "        channel_messages_mindate = channel_messages_df['msg_date'].min().split(\" \")[0]\n",
    "        channel_messages_maxdate = channel_messages_df['msg_date'].max().split(\" \")[0]\n",
    "        #channel_messages_maxdate = channel_messages_df['msg_date'].max().split(\" \")[0]\n",
    "        channel_messages_filename = f\"{curr_channel_name}_{channel_messages_mindate}_to_{channel_messages_maxdate}\"\n",
    "        channel_messages_folder_path = f\"{converted_directory}/{channel_messages_filename}.xlsx\"\n",
    "        channel_messages_df.to_excel(f\"{channel_messages_folder_path}\", index=False)\n",
    "        apply_excel_adjustments(f\"{channel_messages_folder_path}\",curr_channel_name)  #AG: defined this routine in the function apply_excel_adjustments\n",
    "        print(curr_channel_name, datetime.now().time(), ' Wrote curated messages to xlsx files', '\\n')\n",
    "\n",
    "        dfs_list.append(channel_messages_df)\n",
    "        \n",
    "print(datetime.now().time(), 'Done')\n",
    "\n",
    "channel_messages_df.head()   # for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6d865-476d-4774-be0c-62fa71b6b427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
