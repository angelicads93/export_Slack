{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "23326b81-bc35-4147-ae75-377d2e75d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from json import load\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from os import listdir\n",
    "from os.path import getmtime, exists, isdir, isfile\n",
    "from pathlib import Path\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "from urlextract import URLExtract\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "45bf9af4-a979-47e4-bf44-b2ec108cb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows demonstrate in executional cells \n",
    "rows_to_show = 1   # uses for debug with Jupiter's-cells-system\n",
    "\n",
    "## Do you wish to convert all the Slack channels?:\n",
    "analyze_all_flag = False #AG\n",
    "## If not, insert name of Slack channel to convert:\n",
    "exportname = \"general\"\n",
    "## Generate file with the information of all the Slack channels?:\n",
    "write_all_channels_info = True\n",
    "## Generate file with the information of all the Slack users?:\n",
    "write_all_users_info = True\n",
    "\n",
    "\n",
    "#working_directory = \"...\" #AG: not needed, enough with slackexport_folder_path and exporting_directory\n",
    "#working_directory = 'E:\\_RET_slack_export\\RebeccaEverlene Slack export Apr 30 2021 - Oct 3 2024-2' \n",
    "\n",
    "## Insert path where the LOCAL copy of the GoogleDrive folder is:\n",
    "slackexport_folder_path = \"/home/agds/Documents/RebeccaEverleneTrust/App/RebeccaEverlene_Slack_export\" #AG\n",
    "#slackexport_folder_path = f\"{working_directory}\\{exportname}\"\n",
    "\n",
    "exporting_directory = \"/home/agds/Downloads\" #AG\n",
    "Path(f\"{exporting_directory}/RET_converted\").mkdir(parents=True, exist_ok=True) #AG\n",
    "#exporting_directory = f\"{working_directory}\\{'_converted'}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "910a5f89-bf2e-46a2-a0da-021fb024e8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['general']\n"
     ]
    }
   ],
   "source": [
    "#AG: Added a routine that checks the existence/format of files/directories of the channel(s) requested by the user.\n",
    "\n",
    "def check_jsonFile_nameFormat(file_name):\n",
    "    \"\"\" Checks the format of a json file. \n",
    "    Returns True if the name of the file is of the type yyyy-mm-dd.json\"\"\"\n",
    "    list_json_format = file_name.split(\".json\")[0].split(\"-\")   ### COULD BE IMPROVED\n",
    "    try:\n",
    "        if len(list_json_format[0])==4 and len(list_json_format[1])==2 and len(list_json_format[2])==2:\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def review_format_of_jsonFiles(list_names):\n",
    "    \"\"\" Iterates over all the json files in a channel's directory, and separates the ones with the\n",
    "    correct date-format (list_names_dates) from the rest (list_names_others).\n",
    "    It uses the funtion check_jsonFile_nameFormat \"\"\"\n",
    "    list_names_dates = []\n",
    "    list_names_others = []\n",
    "    for i in range(len(list_names)):\n",
    "        if check_jsonFile_nameFormat(list_names[i])==True:\n",
    "            list_names_dates.append(list_names[i])\n",
    "        else:\n",
    "            list_names_others.append(list_names[i])\n",
    "    return list_names_dates, list_names_others\n",
    "    \n",
    "## Analyze directories:\n",
    "flag_continue = True\n",
    "\n",
    "## Check that slackexport_folder_path exists:\n",
    "if exists(slackexport_folder_path)==False:\n",
    "    print('Please enter a valid path to the source directory')\n",
    "    flag_continue = False\n",
    "else:\n",
    "    ## If analysing one channel, check that its directory exists, and default to the 0-th element of channels_names:\n",
    "    ## channels_names = [ exportname ] for one exportchannel\n",
    "    ## channels_names = [channel0, channel1, ...] for all the channels\n",
    "    if analyze_all_flag == False:\n",
    "        if exists(f\"{slackexport_folder_path}/{exportname}\")==False:\n",
    "            print(f\"The source directory for the channel '{exportname}' was not found in {slackexport_folder_path}\")\n",
    "            flag_continue = False\n",
    "        else:\n",
    "            channels_names = [exportname]\n",
    "    else:\n",
    "        all_in_sourceDir = listdir(slackexport_folder_path)\n",
    "        channels_names = [all_in_sourceDir[i] for i in range(len(all_in_sourceDir)) if isdir(f\"{slackexport_folder_path}/{all_in_sourceDir[i]}\")==True]\n",
    "\n",
    "    \n",
    "    ## Check the names of json files (yyyy-mm-dd.json) and stores them:\n",
    "    ## all_channels_jsonFiles_dates = [ [exportname_json0, exportname_json1, ...] ] for one exportchannel\n",
    "    ## all_channels_jsonFiles_dates = [ [channel0_json0, channel0_json1, ...], [channel1_json0, channel1_json1, ...], ... ] for all the channels\n",
    "    all_channels_jsonFiles_dates = []\n",
    "    #all_channels_jsonFiles_others = []\n",
    "    for channel in channels_names:\n",
    "        channel_jsonFiles_dates, channel_jsonFiles_others = review_format_of_jsonFiles( listdir(f\"{slackexport_folder_path}/{channel}\") )\n",
    "        all_channels_jsonFiles_dates.append(channel_jsonFiles_dates)\n",
    "        #all_channels_jsonFiles_others.append(channel_jsonFiles_others)\n",
    "        \n",
    "    ## Check that the users.json files exists:\n",
    "    if exists(f\"{slackexport_folder_path}/users.json\")==False:\n",
    "        print('File \"users.json\" was not found in the source directory')\n",
    "        flag_continue = False\n",
    "\n",
    "\n",
    "#print(flag_continue) \n",
    "print(channels_names)\n",
    "#print(all_channels_jsonFiles_others)\n",
    "#print(all_channels_jsonFiles_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "3d1aa82b-554d-484c-8824-7a52858b2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definition of funtions used later in the analysis:\n",
    "\n",
    "\n",
    "def replace_empty_space(df, column):\n",
    "    \"\"\"Function to replace empty spaces \"\" with the string 'n/a' for a given column\"\"\"\n",
    "    for i in range(len(df)):\n",
    "        if df.at[i,column] == \"\":\n",
    "            df.at[i,column] = 'n/a'\n",
    "def replace_NaN(df, column):\n",
    "    \"\"\"Function to replace missing values with the string 'n/a' for a given column \"\"\"\n",
    "    df[column] = df[column].fillna('n/a')\n",
    "\n",
    "\n",
    "def get_all_channels_info(slackexport_folder_path):\n",
    "    \"\"\"\n",
    "    This function exports the file channels.json into the dataframe all_channels_df and filters/format relevant features.\n",
    "    The primary features of all_users_df are: \n",
    "        id, name, created, creator, is_archived, is_general, members, pins, topic, purpose.\n",
    "    The secondary features of 'pins' are:\n",
    "        id, type, created, user, owner.\n",
    "        Generally a list of dictionaries.\n",
    "    The secondary features of 'topic' are:\n",
    "        value, creator, last_set.\n",
    "    \"\"\"\n",
    "    ### Export channels.json to dataframe    \n",
    "    all_channels_df = pd.read_json(f\"{slackexport_folder_path}/channels.json\")\n",
    "    \n",
    "    ## Format relevant features on all_channels_df:\n",
    "    all_json_files = []\n",
    "    for i in range(len(all_channels_df)):\n",
    "        ## Writes the list of members into a string separated by commnas:\n",
    "        tmp_list = all_channels_df.at[i, 'members']\n",
    "        members_str = \"\".join(f\"{tmp_list[j]}, \" for j in range(len(tmp_list)))\n",
    "        all_channels_df.at[i,'members'] = members_str[:-2]\n",
    "        ## Add the 'purpose' of the channel:\n",
    "        all_channels_df.at[i,'purpose'] = all_channels_df.at[i,'purpose']['value']\n",
    "        ## Adds a list with the channel's json_files with the correct format (yyyy-mm-dd.json):\n",
    "        channel_path = f\"{slackexport_folder_path}/{all_channels_df.at[i,'name']}\"\n",
    "        list_names_dates, list_names_others = review_format_of_jsonFiles(listdir(channel_path))\n",
    "        all_json_files.append(list_names_dates)\n",
    "    all_channels_df['json_files'] = all_json_files\n",
    "    \n",
    "    ## Keep the relevant features:\n",
    "    all_channels_df = all_channels_df[['id', 'name', 'created', 'creator', 'is_archived', 'is_general', 'members', 'purpose', 'json_files']]\n",
    "\n",
    "    ## Handle missing values or empty strings:\n",
    "    replace_empty_space(all_channels_df, 'members')\n",
    "    replace_empty_space(all_channels_df, 'purpose')\n",
    "    \n",
    "    return all_channels_df\n",
    "\n",
    "\n",
    "def get_all_users_info(slackexport_folder_path):\n",
    "    \"\"\"\n",
    "    This function exports the file users.json into the dataframe all_users_df and filters/format relevant features.\n",
    "    The primary features of all_users_df are: \n",
    "        id, team_id, name, deleted, color, real_name, tz, tz_label, tz_offset, profile, is_admin, is_owner,\n",
    "        is_primary_owner, is_restricted,is_ultra_restricted, is_bot, is_app_user, updated, is_email_confirmed,\n",
    "        who_can_share_contact_card, is_invited_user, is_workflow_bot, is_connector_bot.\n",
    "    Among the secondary features of 'profile', there are:\n",
    "        title, phone, skype, real_name, real_name_normalized, display_name, display_name_normalized, fields, \n",
    "        status_text, status_emoji, status_emoji_display_info, status_expiration, \n",
    "        avatar_hash, image_original, is_custom_image, email, huddle_state, huddle_state_expiration_ts, \n",
    "        first_name, last_name, image_24, image_32, image_48, image_72, image_192, image_512, image_1024, \n",
    "        status_text_canonical, team.\n",
    "    \"\"\"\n",
    "    ## Read users.json as a dataframe:\n",
    "    all_users_df = pd.read_json(f\"{slackexport_folder_path}/users.json\")\n",
    "    \n",
    "    ## Keep relevant features on all_users_df:\n",
    "    for i in range(len(all_users_df)):\n",
    "        all_users_df.at[i, 'display_name'] = all_users_df.at[i, 'profile']['display_name']\n",
    "        #all_users_df.at[i, 'profile_title'] = all_users_df.at[i, 'profile']['title']  ## Contain a lot of missing values. Display_name seems more representative.\n",
    "    all_users_df = all_users_df[['id', 'team_id', 'name', 'deleted', 'display_name', 'is_bot']]#,'profile_title']]\n",
    "    \n",
    "    ## Handling missing values in all_users_df:\n",
    "    replace_empty_space(all_users_df, 'display_name')\n",
    "    replace_empty_space(all_users_df, 'name')\n",
    "    replace_empty_space(all_users_df, 'team_id')\n",
    "    replace_empty_space(all_users_df, 'id')\n",
    "    \n",
    "    return all_users_df\n",
    "    \n",
    "def slack_json_to_dataframe(slack_json):\n",
    "    \"\"\" Function to extract channel's messages from a JSON file \"\"\"\n",
    "    \n",
    "    messages_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\", \n",
    "                                        \"reply_count\", \"reply_users_count\", \n",
    "                                        \"ts_latest_reply\", \"ts_thread\", \"parent_user_id\"])\n",
    "    \n",
    "    for message in range(len(slack_json)):\n",
    "        #if 'files' in slack_json[message] and slack_json[message]['files']:            #AG:commented out\n",
    "        #    messages_df.at[message, \"msg_id\"] = slack_json[message]['files'][0]['id']  #AG:commented out\n",
    "        if 'client_msg_id' in slack_json[message]:\n",
    "            messages_df.at[message, \"msg_id\"] = slack_json[message]['client_msg_id']\n",
    "        elif 'subtype' in slack_json[message]:                                       #AG:added\n",
    "            messages_df.at[message, \"msg_id\"] = slack_json[message]['subtype']       #AG:added\n",
    "        else:\n",
    "            messages_df.at[message, \"msg_id\"] = None#'n/a'\n",
    "            \n",
    "        if 'ts' in slack_json[message]:\n",
    "            messages_df.at[message, \"ts\"] = slack_json[message]['ts']\n",
    "        else:\n",
    "            messages_df.at[message, \"ts\"] = None#'n/a'  # 20241110-2\n",
    "            \n",
    "        messages_df.at[message, \"user\"] = slack_json[message].get('user', None)#'n/a')\n",
    "        \n",
    "        if 'type' in slack_json[message]:\n",
    "            messages_df.at[message, \"type\"] = slack_json[message]['type']\n",
    "        else:\n",
    "            messages_df.at[message, \"type\"] = None#'n/a'  # 20241110-2\n",
    "        \n",
    "        if 'text' in slack_json[message]:\n",
    "            messages_df.at[message, \"text\"] = slack_json[message]['text']\n",
    "            #AG:begin\n",
    "            #txt = slack_json[message]['text']\n",
    "            #if txt==\"\" and 'attachments' in slack_json[message]:\n",
    "                ## Covers cases like in 2023/01/11 with the Slackbot messages:\n",
    "            #    messages_df.at[message, \"text\"] = slack_json[message]['attachments'][0]['from_url']\n",
    "                #messages_df.at[message, \"user\"] = slack_json[message]['bot_id']   #overwrittes the empty string, particular to this case.\n",
    "            #else:\n",
    "            #    messages_df.at[message, \"text\"] = txt\n",
    "            #AG:end\n",
    "        else:\n",
    "            messages_df.at[message, \"text\"] = None#'n/a'  # 20241110-2\n",
    "\n",
    "        if 'reply_count' in slack_json[message]:\n",
    "            messages_df.at[message, \"reply_count\"] = slack_json[message]['reply_count']\n",
    "            messages_df.at[message, \"reply_users_count\"] = slack_json[message]['reply_users_count']\n",
    "            messages_df.at[message, \"ts_latest_reply\"] = slack_json[message]['latest_reply']\n",
    "        else:\n",
    "            messages_df.at[message, \"reply_count\"] = None#'n/a'  # 20241110-2\n",
    "            messages_df.at[message, \"reply_users_count\"] = None#'n/a'  # 20241110-2\n",
    "            messages_df.at[message, \"ts_latest_reply\"] = None#'n/a'  # 20241110-2\n",
    "\n",
    "        if 'parent_user_id' in slack_json[message]:\n",
    "            messages_df.at[message, \"ts_thread\"] = slack_json[message]['thread_ts']\n",
    "            messages_df.at[message, \"parent_user_id\"] = slack_json[message]['parent_user_id']\n",
    "        else:\n",
    "            messages_df.at[message, \"ts_thread\"] = None#'n/a'  # 20241110-2\n",
    "            messages_df.at[message, \"parent_user_id\"] = None#'n/a'  # 20241110-2\n",
    "            \n",
    "    return messages_df\n",
    "    \n",
    "\n",
    "def get_channel_messages_df(export_path, curr_channel_name, json_list):\n",
    "    \"\"\" Extracts all the messages of a given channel from its JSON files, and stores them on a data frame \"\"\"\n",
    "    channel_messages_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\",\n",
    "                                                \"reply_count\", \"reply_users_count\",\n",
    "                                                \"ts_latest_reply\", \"ts_thread\", \"parent_user_id\"])\n",
    "                                                # ,\"channel_folder\", \"json_name\", \"json_mod_date\"])          #_IP\n",
    "    \n",
    "    # Iterate over JSONs inside the current channel's folder:\n",
    "    for file_day in range(len(json_list)):\n",
    "        #filejson_path = f\"{parentfolder_path}/{channels_json[curr_channel_name]['dayslist'][file_day]}\"\n",
    "        filejson_path = f\"{export_path}/{curr_channel_name}/{json_list[file_day]}\" #AG\n",
    "        \n",
    "        with open(filejson_path, encoding='utf-8') as f:\n",
    "            import_file_json = load(f)\n",
    "        import_file_df = slack_json_to_dataframe(import_file_json)\n",
    "        import_file_df['json_name'] = json_list[file_day]\n",
    "        import_file_df['json_mod_ts'] = getmtime(filejson_path)\n",
    "        \n",
    "        channel_messages_df = pd.concat([channel_messages_df, import_file_df], axis=0, ignore_index=True) \n",
    "    \n",
    "    channel_messages_df['channel_folder'] = curr_channel_name   #IP\n",
    "    return channel_messages_df\n",
    "\n",
    "\n",
    "def get_channel_users_df(channel_messages_df, users_df ):\n",
    "    \"\"\"Returns a data frame with the information of the users in current channel\"\"\"\n",
    "    # Initialize channel_users_df as a copy of users_df:\n",
    "    channel_users_df = users_df.copy()\n",
    "    # Find the unique set of users in channel:\n",
    "    channel_users_list = channel_messages_df['user'].unique()\n",
    "    # Collect the indices of the users that are NOT in the channel:\n",
    "    indices_to_drop = [i for i in range(len(users_df)) if users_df.at[i,'id'] not in channel_users_list ]\n",
    "    # Drop the rows on indices_to_drop:\n",
    "    channel_users_df.drop(channel_users_df.index[indices_to_drop], inplace=True)\n",
    "    return channel_users_df\n",
    "\n",
    "def add_users_info_to_messages(df_messages, df_users):\n",
    "    for index in df_messages.index.values:\n",
    "        i_df = df_users[df_users['id']==df_messages.at[index,'user']]\n",
    "        if i_df['display_name'].shape[0]==0:        ##AG: 'USLACKBOT' is a special case\n",
    "            df_messages.at[index, 'name'] =  df_messages.at[index, 'user']\n",
    "            df_messages.at[index, 'display_name'] =  df_messages.at[index, 'user']\n",
    "            df_messages.at[index, 'is_bot'] =  True\n",
    "        else:\n",
    "            df_messages.at[index, 'name'] = i_df['name'].values\n",
    "            df_messages.at[index, 'display_name'] = i_df['display_name'].values\n",
    "            df_messages.at[index, 'is_bot'] = i_df['is_bot'].values\n",
    "        del i_df\n",
    "    #del channel_users_df\n",
    "\n",
    "def ts_to_tz(df, original_column_name, new_column_name):\n",
    "    \"\"\"Transforms timestamps in a dataframe's column to dates on the \"US/Central\" timezone\"\"\"\n",
    "    df[original_column_name] = pd.to_numeric(df[original_column_name], errors='coerce')   #_IP\n",
    "    tzs = []\n",
    "    for i in range(len(df)):\n",
    "        if df.at[i,original_column_name] == None:\n",
    "            i_date = '0000-00-00 00:00:00'\n",
    "        else:\n",
    "            i_date = pd.to_datetime(df.at[i,original_column_name], unit='s').tz_localize('US/Eastern').tz_convert('US/Central')\n",
    "            i_date = datetime.strftime(i_date,\"%Y-%m-%d %H:%M:%S\")\n",
    "        tzs.append(i_date)\n",
    "    df[[original_column_name]].astype('datetime64[s]')\n",
    "    df[original_column_name] = tzs\n",
    "    df.rename(columns={original_column_name: new_column_name}, inplace=True)\n",
    "\n",
    "\n",
    "def extract_urls(df):\n",
    "    \"\"\"\"\"\"\n",
    "    extractor = URLExtract()\n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i,'text']\n",
    "        if 'https' in text:\n",
    "            url = extractor.find_urls(text)\n",
    "            df.at[i,'URL'] = url\n",
    "        else:\n",
    "            df.at[i,'URL'] = None\n",
    "\n",
    "\n",
    "def user_id_to_name(df_messages, df_users):\n",
    "    \"\"\"\"\"\"\n",
    "    for i in range(len(df_messages)):\n",
    "        text = df_messages.at[i,'text']\n",
    "        matches = re.findall(r'<+@[A-Za-z0-9]+>',text)\n",
    "        if len(matches)>0:\n",
    "            for match in matches:\n",
    "                user = match[2:-1]\n",
    "                name = df_users[df_users['id']==user]['display_name'].values[0]\n",
    "                if name!='n/a':\n",
    "                    text = re.sub(f\"<@{user}>\", f\"{name}\", text)\n",
    "            df_messages.at[i,'text'] = text\n",
    "    return df_messages\n",
    "\n",
    "\n",
    "def apply_excel_adjustments(file_path, curr_channel_name):\n",
    "    \"\"\" Excel file formatting/adjustments with  openpyxl (IP) \"\"\"\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb.active\n",
    "    # Set the column width\n",
    "    column_widths = {\n",
    "        'B': 19, 'C': 15, 'E': 25, 'K': 25, 'L': 19, 'M': 19, 'N': 13, 'O': 13     \n",
    "    }\n",
    "    # Apply the column widths\n",
    "    for col, width in column_widths.items():\n",
    "        ws.column_dimensions[col].width = width\n",
    "    #\n",
    "    # Freeze the first row (Row 1)\n",
    "    ws.freeze_panes = 'A2'\n",
    "    # Set font size and bold for the first row\n",
    "    font = Font(size=9, bold=True)\n",
    "    # Define the RGB color\n",
    "    fill = PatternFill(start_color=\"e7c9fb\", end_color=\"e7c9fb\", fill_type=\"solid\")\n",
    "    # Apply the color to the first row (row 1)\n",
    "    # Apply the font formatting to the first row (Header row)\n",
    "    for cell in ws[1]:\n",
    "        cell.font = font\n",
    "        cell.fill = fill\n",
    "    #\n",
    "    # Rename the sheet\n",
    "    ws_title = curr_channel_name \n",
    "    ws_title = ws_title[:31]\n",
    "    ws.title = ws_title \n",
    "    #\n",
    "    # Save the changes to the Excel file\n",
    "    wb.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "id": "7ae148b4-3f0b-4f44-9d6b-abe0df76ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:37:11.839167 Started analysis after sanity checks\n",
      "18:37:11.888782 Obtained channels_df\n",
      "18:37:12.130030 Obtained users_df\n",
      "18:37:12.179105 Wrote channels_df to xlsx file\n",
      "18:37:12.387752 Wrote users_df to xlsx file\n",
      "18:37:12.387835 Starting loop over channels \n",
      "\n",
      "general 18:37:12.387858  Set-up channel name and path to directory\n",
      "general 18:37:15.538363  Collected channel messages from the json files\n",
      "general 18:37:15.606135  Collected users in current channel\n",
      "general 18:37:17.831035  Included the users information on channel_messages_df\n",
      "general 18:37:18.785024  User's id replaced by their names in messages\n",
      "general 18:37:21.121686  URLs extracted from messages\n",
      "general 18:37:23.117795  Formated the dates and times in the dataframe\n",
      "general 18:37:26.782814  Wrote curated messages to xlsx files \n",
      "\n",
      "18:37:26.783064 Done\n"
     ]
    }
   ],
   "source": [
    "### Main analysis:\n",
    "if flag_continue==False:\n",
    "    print(\"Please review the input information\")\n",
    "else:    \n",
    "    print(datetime.now().time(), 'Started analysis after sanity checks' )\n",
    "    \n",
    "    ### Extract the channels and users information into dataframes:\n",
    "    channels_df = get_all_channels_info(slackexport_folder_path)\n",
    "    print(datetime.now().time(), 'Obtained channels_df')\n",
    "    users_df = get_all_users_info(slackexport_folder_path)\n",
    "    print(datetime.now().time(), 'Obtained users_df')\n",
    "    \n",
    "    ### Write all channel's info to .xlsx files, if requested by user:\n",
    "    if write_all_channels_info==True:\n",
    "        slack_export_channel_filename = \"_all_channels\"\n",
    "        slack_export_channel_folder_path_xlsx = f\"{exporting_directory}/{slack_export_channel_filename}{'.xlsx'}\"\n",
    "        channels_df.to_excel(slack_export_channel_folder_path_xlsx, index=False)\n",
    "        print(datetime.now().time(), 'Wrote channels_df to xlsx file')  \n",
    "    \n",
    "    ### Write all users's info to .xlsx files, if requested by user:\n",
    "    if write_all_users_info==True:\n",
    "        slack_export_user_filename = \"_all_users\"        \n",
    "        slack_export_user_folder_path_xlsx = f\"{exporting_directory}/{slack_export_user_filename}{'.xlsx'}\" #_IP\n",
    "        users_df.to_excel(slack_export_user_folder_path_xlsx, index=False) #_IP\n",
    "        print(datetime.now().time(), 'Wrote users_df to xlsx file')\n",
    "\n",
    "    ### Iterate over channel's folders:\n",
    "    print(datetime.now().time(), 'Starting loop over channels', '\\n')\n",
    "    for i_channel in range(len(channels_names)):\n",
    "\n",
    "        ## Define the name of the current channel and the source path containing its json files:\n",
    "        curr_channel_name = channels_names[i_channel] \n",
    "        parentfolder_path = f\"{slackexport_folder_path}/{curr_channel_name}\" \n",
    "        print(curr_channel_name, datetime.now().time(), ' Set-up channel name and path to directory')\n",
    "        \n",
    "        ## Collect all the current_channel's messages in channel_messages_df through the function get_channel_messages_df:\n",
    "        json_list = all_channels_jsonFiles_dates[i_channel]\n",
    "        channel_messages_df = get_channel_messages_df(slackexport_folder_path, curr_channel_name, json_list)  \n",
    "        print(curr_channel_name, datetime.now().time(), ' Collected channel messages from the json files')\n",
    "\n",
    "        ## Collect all the users in the current channel through the function get_channel_users_df:\n",
    "        channel_users_df = get_channel_users_df(channel_messages_df, users_df )\n",
    "        print(curr_channel_name, datetime.now().time(), ' Collected users in current channel')\n",
    "        \n",
    "        ## Use channel_users_df to fill-in the user's information in channel_messages_df:  (define in function onces tested)\n",
    "        add_users_info_to_messages(channel_messages_df, channel_users_df)\n",
    "        print(curr_channel_name, datetime.now().time(), ' Included the users information on channel_messages_df')\n",
    "        \n",
    "        ## Replace user and team identifiers with their display_names whenever present in a message:\n",
    "        user_id_to_name(channel_messages_df, users_df)  #(debugging!)\n",
    "        print(curr_channel_name, datetime.now().time(), \" User's id replaced by their names in messages\")\n",
    "\n",
    "        ## Extract hyperlinks from messages, if present (extracted as a list; edit if needed):\n",
    "        extract_urls(channel_messages_df)\n",
    "        print(curr_channel_name, datetime.now().time(), ' URLs extracted from messages')\n",
    "\n",
    "        ## Change format of the time in seconds to a date in the CST time-zone: (Pending 'ts_latest_reply' and 'ts_thread'!)\n",
    "        channel_messages_mindate = pd.to_datetime(np.float64(channel_messages_df['ts']), unit='s').min().date()\n",
    "        channel_messages_maxdate = pd.to_datetime(np.float64(channel_messages_df['ts']), unit='s').max().date()\n",
    "        ts_to_tz(channel_messages_df, 'ts', 'msg_date')\n",
    "        ts_to_tz(channel_messages_df, 'json_mod_ts', 'json_mod_date')\n",
    "        print(curr_channel_name, datetime.now().time(), ' Formated the dates and times in the dataframe')\n",
    "            \n",
    "        ## Reorder the columns in channel_messages_df, if necessary:\n",
    "        #channel_messages_df = channel_messages_df[['channel', 'json_name', 'json_mod_date', 'user', 'name', 'display_name', 'ts', 'msg_id', 'type', 'text']]\n",
    "        #channel_messages_df.index = ['']*len(channel_messages_df)\n",
    "        \n",
    "        ## Write channel_messages_df to a .xlsx file:\n",
    "        channel_messages_filename = f\"{curr_channel_name}_{channel_messages_mindate}_to_{channel_messages_maxdate}\"\n",
    "        channel_messages_folder_path = f\"{exporting_directory}/{channel_messages_filename}.xlsx\"\n",
    "        channel_messages_df.to_excel(f\"{channel_messages_folder_path}\", index=False)\n",
    "        apply_excel_adjustments(f\"{channel_messages_folder_path}\",curr_channel_name)  #AG: defined this routine in the function apply_excel_adjustments\n",
    "        print(curr_channel_name, datetime.now().time(), ' Wrote curated messages to xlsx files', '\\n')\n",
    "\n",
    "print(datetime.now().time(), 'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "id": "93c59bbc-7ee7-4f80-a3e1-f15b122ab821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>msg_date</th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>reply_users_count</th>\n",
       "      <th>ts_latest_reply</th>\n",
       "      <th>ts_thread</th>\n",
       "      <th>parent_user_id</th>\n",
       "      <th>json_name</th>\n",
       "      <th>json_mod_date</th>\n",
       "      <th>channel_folder</th>\n",
       "      <th>name</th>\n",
       "      <th>display_name</th>\n",
       "      <th>is_bot</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0978e8bd-ea36-4201-8248-c3bc5b5ba36c</td>\n",
       "      <td>2022-11-16 07:31:58</td>\n",
       "      <td>U044B44L249</td>\n",
       "      <td>message</td>\n",
       "      <td>Hello everyone\\n\\nCheckout on playstore my fir...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1668608777.331729</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-11-16.json</td>\n",
       "      <td>2024-10-03 18:44:20</td>\n",
       "      <td>general</td>\n",
       "      <td>vigehi2017</td>\n",
       "      <td>Edith Oga</td>\n",
       "      <td>False</td>\n",
       "      <td>[https://play.google.com/store/apps/details?id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slackbot_response</td>\n",
       "      <td>2022-11-16 07:31:59</td>\n",
       "      <td>USLACKBOT</td>\n",
       "      <td>message</td>\n",
       "      <td>Good to see you online again</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-11-16.json</td>\n",
       "      <td>2024-10-03 18:44:20</td>\n",
       "      <td>general</td>\n",
       "      <td>USLACKBOT</td>\n",
       "      <td>USLACKBOT</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9968fcff-3a2e-496d-acdb-67b86aad4c21</td>\n",
       "      <td>2022-11-16 11:23:33</td>\n",
       "      <td>U02063W7Z1V</td>\n",
       "      <td>message</td>\n",
       "      <td>Thanks for sharing. How are those charts for A...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1668587518.470649</td>\n",
       "      <td>U044B44L249</td>\n",
       "      <td>2022-11-16.json</td>\n",
       "      <td>2024-10-03 18:44:20</td>\n",
       "      <td>general</td>\n",
       "      <td>ask</td>\n",
       "      <td>Tamara C. Daniels</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0a85b29e-02ce-4139-a6bb-224ac0d94004</td>\n",
       "      <td>2022-11-16 11:29:31</td>\n",
       "      <td>U02063W7Z1V</td>\n",
       "      <td>message</td>\n",
       "      <td>In the future, please ask me before posting an...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1668587518.470649</td>\n",
       "      <td>U044B44L249</td>\n",
       "      <td>2022-11-16.json</td>\n",
       "      <td>2024-10-03 18:44:20</td>\n",
       "      <td>general</td>\n",
       "      <td>ask</td>\n",
       "      <td>Tamara C. Daniels</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64ea976b-ac51-432c-a9c8-e615fb44f90b</td>\n",
       "      <td>2022-11-16 12:52:28</td>\n",
       "      <td>U044B44L249</td>\n",
       "      <td>message</td>\n",
       "      <td>Hello, let me look for him,</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1668587518.470649</td>\n",
       "      <td>U044B44L249</td>\n",
       "      <td>2022-11-16.json</td>\n",
       "      <td>2024-10-03 18:44:20</td>\n",
       "      <td>general</td>\n",
       "      <td>vigehi2017</td>\n",
       "      <td>Edith Oga</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 msg_id             msg_date         user  \\\n",
       "0  0978e8bd-ea36-4201-8248-c3bc5b5ba36c  2022-11-16 07:31:58  U044B44L249   \n",
       "1                     slackbot_response  2022-11-16 07:31:59    USLACKBOT   \n",
       "2  9968fcff-3a2e-496d-acdb-67b86aad4c21  2022-11-16 11:23:33  U02063W7Z1V   \n",
       "3  0a85b29e-02ce-4139-a6bb-224ac0d94004  2022-11-16 11:29:31  U02063W7Z1V   \n",
       "4  64ea976b-ac51-432c-a9c8-e615fb44f90b  2022-11-16 12:52:28  U044B44L249   \n",
       "\n",
       "      type                                               text reply_count  \\\n",
       "0  message  Hello everyone\\n\\nCheckout on playstore my fir...           6   \n",
       "1  message                       Good to see you online again        None   \n",
       "2  message  Thanks for sharing. How are those charts for A...        None   \n",
       "3  message  In the future, please ask me before posting an...        None   \n",
       "4  message                        Hello, let me look for him,        None   \n",
       "\n",
       "  reply_users_count    ts_latest_reply          ts_thread parent_user_id  \\\n",
       "0                 3  1668608777.331729               None           None   \n",
       "1              None               None               None           None   \n",
       "2              None               None  1668587518.470649    U044B44L249   \n",
       "3              None               None  1668587518.470649    U044B44L249   \n",
       "4              None               None  1668587518.470649    U044B44L249   \n",
       "\n",
       "         json_name        json_mod_date channel_folder        name  \\\n",
       "0  2022-11-16.json  2024-10-03 18:44:20        general  vigehi2017   \n",
       "1  2022-11-16.json  2024-10-03 18:44:20        general   USLACKBOT   \n",
       "2  2022-11-16.json  2024-10-03 18:44:20        general         ask   \n",
       "3  2022-11-16.json  2024-10-03 18:44:20        general         ask   \n",
       "4  2022-11-16.json  2024-10-03 18:44:20        general  vigehi2017   \n",
       "\n",
       "        display_name is_bot                                                URL  \n",
       "0          Edith Oga  False  [https://play.google.com/store/apps/details?id...  \n",
       "1          USLACKBOT   True                                               None  \n",
       "2  Tamara C. Daniels  False                                               None  \n",
       "3  Tamara C. Daniels  False                                               None  \n",
       "4          Edith Oga  False                                               None  "
      ]
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_messages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f0a31-2b34-4e78-ba24-e8ddc0bc8a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
