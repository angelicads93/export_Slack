{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23326b81-bc35-4147-ae75-377d2e75d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from json import load\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from os import listdir\n",
    "from os.path import getmtime, exists, isdir, isfile\n",
    "from pathlib import Path\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "from urlextract import URLExtract\n",
    "import re\n",
    "\n",
    "#IP2024119\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45bf9af4-a979-47e4-bf44-b2ec108cb0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder 'JSONs_converted' already exists in '/home/agds/Downloads' and it will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "## AG20241119: Introduced one extra notation to identify a bit more easily the different comments.\n",
    "## If a comment is part of the description of a given step on the code, it starts with ##--\n",
    "## And if the comment is for suggesting/implementing changes in the code, it starts with #\n",
    "\n",
    "# AG20241119: \"rows_to_show\" is not used in this code. It can be removed.\n",
    "# how many rows demonstrate in executional cells \n",
    "# rows_to_show = 1   # uses for debug with Jupiter's-cells-system\n",
    "\n",
    "# !  IP20241118 naming like \"flag_analyze_all\" & \"info_write_all_channels\" is more understandable from glance\n",
    "# AG20241119: Changed the name \"analyze_all_flag\" to \"analyze_all_channels\" everywhere. (Not to be confused with \"write_all_channels_info\" define below)\n",
    "\n",
    "#AG20241120: replaced every explicit reference to 'n/a', None, ... to the global variable 'missing_value'\n",
    "##-- Syntax to use for missing values:   \n",
    "missing_value = 'n/d'\n",
    "\n",
    "##-- Do you wish to convert all the Slack channels?:\n",
    "analyze_all_channels = True   \n",
    "\n",
    "##-- If not, insert name of Slack channel to convert:\n",
    "export_name = '' # \"general\"        #AG20241119: Changed the name \"exportname\" to \"export_name\" to keep the same naming convention everywhere.\n",
    "\n",
    "##-- Generate file with the information of all the Slack channels?:\n",
    "write_all_channels_info = True\n",
    "##-- Generate file with the information of all the Slack users?:\n",
    "write_all_users_info = True\n",
    "\n",
    "##-- Insert path where the LOCAL copy of the GoogleDrive folder is:\n",
    "slackexport_folder_path = \"/home/agds/Documents/RebeccaEverleneTrust/App/RebeccaEverlene_Slack_export\" #AG\n",
    "#slackexport_folder_path = 'E:\\_RET_slack_export\\RebeccaEverlene Slack export Apr 30 2021 - Oct 3 2024-2short' #IP\n",
    "\n",
    "\n",
    "#working_directory = \"...\" #AG: not needed, enough with slackexport_folder_path and converted_directory. Can be deleted.\n",
    "#working_directory = 'E:\\_RET_slack_export\\RebeccaEverlene Slack export Apr 30 2021 - Oct 3 2024-2' \n",
    "#slackexport_folder_path = f\"{working_directory}\\{expor_tname}\"\n",
    "\n",
    "# ! IP20241118 if \"exporting_directory\" in fact means \"directory-to-where-to-convert\" \n",
    "#    - it shoild be renamed as \"converted_directory\".  !!  diminish any mess with naming of variables\n",
    "# AG20241119: Changed the name \"exporting_directory\" to \"converted_directory\" everywhere.\n",
    "\n",
    "##-- Insert path where the converted files will be saved:\n",
    "converted_directory = \"/home/agds/Downloads\" #AG\n",
    "#converted_directory = 'E:\\_RET_slack_export\\RebeccaEverlene Slack export Apr 30 2021 - Oct 3 2024-2short' #IP\n",
    "converted_directory = f\"{converted_directory}/JSONs_converted\"\n",
    "\n",
    "##-- Check that slackexport_folder_path exists:  #IP20241118\n",
    "if exists(converted_directory)==True:\n",
    "    exprt_folder_path = Path(converted_directory)\n",
    "    if exprt_folder_path.is_dir():\n",
    "        print(f\"The folder 'JSONs_converted' already exists in '{converted_directory.split('JSONs')[0][:-1]}' and it will be overwritten.\") #AG20241120\n",
    "        shutil.rmtree(exprt_folder_path)\n",
    "        \n",
    "Path(f\"{converted_directory}\").mkdir(parents=True, exist_ok=True) #IP20241119\n",
    "        \n",
    "\n",
    "         \n",
    "#Path(f\"{converted_directory}/JSONs_converted\").mkdir(parents=True, exist_ok=True) #AG\n",
    "\n",
    "# IP20241118\n",
    "#converted_directory = f\"{converted_directory}/RET_converted\"\n",
    "\n",
    "#converted_directory = f\"{working_directory}\\{'_converted'}\"  \n",
    "\n",
    "# !!!  IP20241118  above is not ok.: code need to check - if the 'RET_converted'  exist.\n",
    "# if exist - delete current 'RET_converted' . \n",
    "# then create new fresh-&-empty 'RET_converted'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "910a5f89-bf2e-46a2-a0da-021fb024e8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['landmarks-sprint', 'unequivocally-big-ux-ui', 'made-ux-ui', 'outreach-fundraising-communications', 'team-azure', 'sae-performing-arts-medkids', 'team-tech-order-up', 'team-game-designers-medkids', 'aspects-automation-team', 'aws-automation-team', 'team-nabil-medkids-games', 'landmarks-landing-page', 'tutors-on-call', 'FC_F07CWGBGK0D_Untitled', 'landmarks-2d-art-characters', 'college-aspects', 'team-avatars-medkids', 'landmarks-geocodes', 'team-writers-for-rebecca-everlene', 'eat-like-us-inventory-project', 'landmarks-2d-art-locations', 'team-google-workspace', 'aspects-data-cleanup', 'FC_F05PD7LP5C3_Important_links', 'dreampad-for-dreamforce', 'landmarks-unity-lightship-squad', 'team-barbara-medkids-games', 'mockups-for-strategy-finance-budgets', 'FC_F07A54DBKUK_Untitled', 'scrum', 'team-audio-med-kids', 'smitten-hitch-coparenting-project', 'time-off', 'team-yigit-medkids-games', 'team-back-end-dev', 'team-scapegoated', 'grants', 'spaulding-daniels-leadership-group', 'presidential-service-award', 'team-dev-issues-board', 'landmarks-interactive-wall', 'team-maulana-medkids-games', 'team-christa-medkids-games', 'team-front-end-web-developers-medkids', 'team-ink', 'cpts-training-team', 'landmarks-ux-ui-designers', 'landmarks-production-team', 'landmarks', 'salesforce-automation-team', 'design-brainstorming-sessions', 'policies-and-sops-team', 'team-2d-art-for-medkids', 'landmarks-locations', 'aspects-design-content-updates', 'landmarks-vertical-slice-team', 'landmarks-mapping', 'grants-team-2024', 'fundraising-initiatives', 'the-jog-app', 'landmarks-game-designers', 'landmarks-sprint-planning', 'landmarks-2d-art-items-and-guides', 'team-ux-ui-designers-medkids', 'team-cybersecurity-innovations', 'intros-and-shoutouts', 'team-animators-medkids', 'strategic-planning', 'aspects-tuition-reimbursement-scholarships-special-projects', 'team-orderup-developers-medkids', 'team-chef-medkids', 'doodly-toonly-cartoons-medkids', 'team-bowen-medkids-games', 'general', 'champions', '3d-art-team-a-landmarks', 'team-kamil-medkids-games', '20-team', 'FC_F05L6N323GV_无标题', 'unequivocally-big-summer-2024', 'team-jira', 'how-do-i', '3d-art-blender-landmarks', 'pm-tl-channel', 'landmarks-unity-developers', 'real-estate-verification', 'think-biver-saturday-checkins', 'tracker-board', 'unequivocally-big-summer-2023', 'budget-template-build', 'social-media-branding-team', 'team-infographics-and-charting', 'campaign-ret', 'random', 'team-chef-logistics-medkids', 'cpts-strategy-team', '3d-art-team-b-landmarks', 'unequivocally-big-suite-content-team', 'landmarks-ux-meeting-notes', 'landmarks-content-development', 'team-leads', 'aspects-data-analysis', 'landmarks-uxreview-gd-dev', 'landmarks-sprints-2d-art', 'artxdev-team', 'landmarks-product-managers', 'chief-of-chatting-space', 'landmarks-forward', 'licensing', 'team-anatomy-island-for-medkids', 'onboarding-central', 'team-github-solutions', 'team-issues-medkids', 'team-budgets', 'team-medkids-minitours', 'team-voiceover-artists-med-kids', 'team-zixi-medkids-games']\n"
     ]
    }
   ],
   "source": [
    "##--AG: Added a routine that checks the existence/format of files/directories of the channel(s) requested by the user.\n",
    "\n",
    "# !!! IP20241118 should check before - is current file a *.json or file extention is different(then skip this file)\n",
    "#def check_jsonFile_nameFormat(file_name):\n",
    "#    \"\"\" Checks the format of a json file. \n",
    "#    Returns True if the name of the file is of the type yyyy-mm-dd.json\"\"\"\n",
    "#    list_json_format = file_name.split(\".json\")[0].split(\"-\")   ### COULD BE IMPROVED\n",
    "#    try:\n",
    "#        if len(list_json_format[0])==4 and len(list_json_format[1])==2 and len(list_json_format[2])==2:\n",
    "#            return True\n",
    "#    except:\n",
    "#        return False\n",
    "\n",
    "# AG20241119: The function check_jsonFile_nameFormat defined previously can be deleted since the matching of the name of the json file \n",
    "# to the format \"yyyy-mm-dd.json\" was simplified to one line of code. The check of the name of each json file is now done explicitely \n",
    "# in review_format_of_jsonFiles. The name \"review_format_of_jsonFiles\" was further changed to \"check_format_of_json_names\" everyone for \n",
    "# clarity.\n",
    "# list_names_others can be deleted since we don't need it. Description of the function was adjusted.\n",
    "def check_format_of_json_names(list_names):\n",
    "    \"\"\" Iterates over all the json files in a channel's directory, and returns a list with the names of the json files \n",
    "    that have the correct format 'yyyy-mm-dd.json' \"\"\"\n",
    "    list_names_dates = []\n",
    "    #list_names_others = []\n",
    "    for i in range(len(list_names)):\n",
    "        match = re.match(r'(\\d{4})(-)(\\d{2})(-)(\\d{2})(.)(json)',list_names[i])\n",
    "        if match!=None:\n",
    "            list_names_dates.append(list_names[i])\n",
    "        #else:\n",
    "            #list_names_others.append(list_names[i])\n",
    "    return list_names_dates#, list_names_others\n",
    "\n",
    "\n",
    "def get_channels_names(slackexport_folder_path, analyze_all_channels, export_name):     # AG20241120\n",
    "    \"\"\" Returns a list with the name of the Slack channels to be converted.\n",
    "    If analysing one channel, check that its directory exists, and default to the 0-th element of channels_names:\n",
    "    channels_names = [ export_name ] for one channel\n",
    "    channels_names = [channel0, channel1, ...] for all the channels \"\"\"\n",
    "    if analyze_all_channels == False:\n",
    "        if exists(f\"{slackexport_folder_path}/{export_name}\")==False:\n",
    "            print(f\"The source directory for the channel '{export_name}' was not found in {slackexport_folder_path}\")\n",
    "            continue_analysis = False\n",
    "        else:\n",
    "            channels_names = [export_name]\n",
    "    else:\n",
    "        all_in_sourceDir = listdir(slackexport_folder_path)\n",
    "        channels_names = [all_in_sourceDir[i] for i in range(len(all_in_sourceDir)) if isdir(f\"{slackexport_folder_path}/{all_in_sourceDir[i]}\")==True]\n",
    "        \n",
    "    #AG20241120: Pending to check the format of each channel's name. Having empty spaces in the name can cause problems later. \n",
    "    return channels_names\n",
    "\n",
    "\n",
    "def get_all_channels_json_names(channels_names):     # AG20241120\n",
    "    \"\"\" \n",
    "    Check the names of json files in all the channels to be converted and stores them in a list:\n",
    "    all_channels_jsonFiles_dates = [ [export_name_json0, export_name_json1, ...] ] for one exportchannel\n",
    "    all_channels_jsonFiles_dates = [ [channel0_json0, channel0_json1, ...], [channel1_json0, channel1_json1, ...], ... ] for all the channels\n",
    "    \"\"\"\n",
    "    all_channels_jsonFiles_dates = []\n",
    "    #all_channels_jsonFiles_others = []\n",
    "    for channel in channels_names:\n",
    "        channel_jsonFiles_dates = check_format_of_json_names( listdir(f\"{slackexport_folder_path}/{channel}\") )\n",
    "        all_channels_jsonFiles_dates.append(channel_jsonFiles_dates)\n",
    "        #all_channels_jsonFiles_others.append(channel_jsonFiles_others)  \n",
    "        #   IP20241118: \"all_channels_jsonFiles_others.append\"  is senseless, because \"other\" files could have dofferent inner JSON-structure\n",
    "        #   AG20241119: Agree. The two commented lines were added to keep track of all the files in every directory, it was used for checks but it can be deleted.    \n",
    "    return all_channels_jsonFiles_dates\n",
    "\n",
    "\n",
    "continue_analysis = True      # AG20241119 Changed the name from flag_continue to continue_analysis\n",
    "\n",
    "##-- Check that slackexport_folder_path exists:\n",
    "if exists(slackexport_folder_path)==False:\n",
    "    print('Please enter a valid path to the source directory')\n",
    "    continue_analysis = False\n",
    "else:\n",
    "    ##-- Get a list with the name of the channels to be converted:\n",
    "    channels_names = get_channels_names(slackexport_folder_path, analyze_all_channels, export_name) #AG20241120: Defined routine in function\n",
    "    \n",
    "    ##-- Get the name of all the json files of the form \"yyyy-mm-dd.json\" in each channel directory:\n",
    "    all_channels_jsonFiles_dates = get_all_channels_json_names(channels_names) # AG20241120: Defined routine in function\n",
    "    \n",
    "    #  !!! IP2024118  need to check if exist File \"channels.json\"\n",
    "    ##-- Check that the channels.json files exists:     # AG20241119:\n",
    "    if exists(f\"{slackexport_folder_path}/channels.json\")==False:\n",
    "        print('File \"channels.json\" was not found in the source directory')\n",
    "        continue_analysis = False\n",
    "     \n",
    "    ##-- Check that the users.json files exists:\n",
    "    if exists(f\"{slackexport_folder_path}/users.json\")==False:\n",
    "        print('File \"users.json\" was not found in the source directory')\n",
    "        continue_analysis = False\n",
    "\n",
    "\n",
    "#print(continue_analysis) \n",
    "print(channels_names)\n",
    "#print(all_channels_jsonFiles_others)\n",
    "#print(all_channels_jsonFiles_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1aa82b-554d-484c-8824-7a52858b2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definition of funtions used later in the analysis:\n",
    "\n",
    "# !!! IP20241118  check, why 'n_d'  appears in the \"text\"s cells in messages\n",
    "\n",
    "def replace_empty_space(df, column):\n",
    "    \"\"\"Function to replace empty spaces \"\" with the string missing_value for a given column\"\"\"\n",
    "    for i in range(len(df)):\n",
    "        if df.at[i,column] == \"\":\n",
    "            df.at[i,column] = missing_value  \n",
    "            \n",
    "def replace_NaN(df, column):\n",
    "    \"\"\"Function to replace missing values with the string 'n/a' for a given column \"\"\"\n",
    "    df[column] = df[column].fillna(missing_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fbb39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>created</th>\n",
       "      <th>creator</th>\n",
       "      <th>is_archived</th>\n",
       "      <th>is_general</th>\n",
       "      <th>members</th>\n",
       "      <th>pins</th>\n",
       "      <th>topic</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C020HQB61PF</td>\n",
       "      <td>general</td>\n",
       "      <td>1619815937</td>\n",
       "      <td>U02063W7Z1V</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[U02063W7Z1V, U0450DR40FP, U04HGHJ291Q, U04JL6...</td>\n",
       "      <td>[{'id': '1714832626.257419', 'type': 'C', 'cre...</td>\n",
       "      <td>{'value': '', 'creator': '', 'last_set': 0}</td>\n",
       "      <td>{'value': 'This is the one channel that will a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     name     created      creator  is_archived  is_general  \\\n",
       "0  C020HQB61PF  general  1619815937  U02063W7Z1V        False        True   \n",
       "\n",
       "                                             members  \\\n",
       "0  [U02063W7Z1V, U0450DR40FP, U04HGHJ291Q, U04JL6...   \n",
       "\n",
       "                                                pins  \\\n",
       "0  [{'id': '1714832626.257419', 'type': 'C', 'cre...   \n",
       "\n",
       "                                         topic  \\\n",
       "0  {'value': '', 'creator': '', 'last_set': 0}   \n",
       "\n",
       "                                             purpose  \n",
       "0  {'value': 'This is the one channel that will a...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_channels_df = pd.read_json(f\"{slackexport_folder_path}/channels.json\")\n",
    "all_channels_df[0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38f2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_channels_info(slackexport_folder_path):\n",
    "    # ! IP20241118   \"The primary features of all_users_df are: \"  - is correct?  may be - \"all_channels_df\" ??\n",
    "    # AG20241119  Fixed typo (all_users_df >> all_channels_df in the function's decription.\n",
    "    \"\"\"\n",
    "    This function exports the file channels.json into the dataframe all_channels_df and filters/format relevant features.\n",
    "    The primary features of all_channels_df are: \n",
    "        id, name, created, creator, is_archived, is_general, members, pins, topic, purpose.\n",
    "    The secondary features of 'pins' are:\n",
    "        id, type, created, user, owner.\n",
    "        Generally a list of dictionaries.\n",
    "    The secondary features of 'topic' are:\n",
    "        value, creator, last_set.\n",
    "    \"\"\"\n",
    "    ##-- Export channels.json to dataframe    \n",
    "    all_channels_df = pd.read_json(f\"{slackexport_folder_path}/channels.json\")\n",
    "\n",
    "    # ! IP20241118 code below not take in count - which JSONs _supposed-to-present_ in the export folder\n",
    "    #  code below store only JSONs which physically presented in the time of iterating folder\n",
    "    #  think, all_channels_df should preserv initial list of JSON's, which stored in \"channels.json\" originally\n",
    "    #  to provide manual checking of folder/jsons consistence\n",
    "\n",
    "    ##-- Format relevant features on all_channels_df:\n",
    "    all_json_files = []\n",
    "    for i in range(len(all_channels_df)):\n",
    "        ##-- Adds df['members']. Writes the list of members into a string separated by commnas:\n",
    "        tmp_list = all_channels_df.at[i, 'members']\n",
    "        members_str = \"\".join(f\"{tmp_list[j]}, \" for j in range(len(tmp_list)))\n",
    "        all_channels_df.at[i,'members'] = members_str[:-2]\n",
    "        ##-- Adds df['purpose']:\n",
    "        all_channels_df.at[i,'purpose'] = all_channels_df.at[i,'purpose']['value']\n",
    "        ##-- Adds a list with the channel's json_files with the correct format (yyyy-mm-dd.json):\n",
    "        channel_path = f\"{slackexport_folder_path}/{all_channels_df.at[i,'name']}\"\n",
    "        \n",
    "        #print(\"in the  def'get_all_channels_info' channel_path =>> \"+channel_path )\n",
    "\n",
    "        ##-- Check that the channel_path exists:   #IP20241118\n",
    "        if exists(channel_path)==True:\n",
    "            list_names_dates = check_format_of_json_names(listdir(channel_path)) #AG20241120: list_names_others not part of the output anymore\n",
    "            all_json_files.append(list_names_dates)\n",
    "        else:\n",
    "            all_json_files.append(missing_value)\n",
    "\n",
    "        \n",
    "    all_channels_df['json_files'] = all_json_files\n",
    "    \n",
    "    ##-- Keep the relevant features:\n",
    "    all_channels_df = all_channels_df[['id', 'name', 'created', 'creator', 'is_archived', 'is_general', 'members', 'purpose', 'json_files']]\n",
    "\n",
    "    ##-- Handle missing values or empty strings:\n",
    "    replace_empty_space(all_channels_df, 'members')\n",
    "    replace_empty_space(all_channels_df, 'purpose')\n",
    "    \n",
    "    return all_channels_df\n",
    "\n",
    "\n",
    "def get_all_users_info(slackexport_folder_path):\n",
    "    \"\"\"\n",
    "    This function exports the file users.json into the dataframe all_users_df and filters/format relevant features.\n",
    "    The primary features of all_users_df are: \n",
    "        id, team_id, name, deleted, color, real_name, tz, tz_label, tz_offset, profile, is_admin, is_owner,\n",
    "        is_primary_owner, is_restricted,is_ultra_restricted, is_bot, is_app_user, updated, is_email_confirmed,\n",
    "        who_can_share_contact_card, is_invited_user, is_workflow_bot, is_connector_bot.\n",
    "    Among the secondary features of 'profile', there are:\n",
    "        title, phone, skype, real_name, real_name_normalized, display_name, display_name_normalized, fields, \n",
    "        status_text, status_emoji, status_emoji_display_info, status_expiration, \n",
    "        avatar_hash, image_original, is_custom_image, email, huddle_state, huddle_state_expiration_ts, \n",
    "        first_name, last_name, image_24, image_32, image_48, image_72, image_192, image_512, image_1024, \n",
    "        status_text_canonical, team.\n",
    "    \"\"\"\n",
    "    ##-- Read users.json as a dataframe:\n",
    "    all_users_df = pd.read_json(f\"{slackexport_folder_path}/users.json\")\n",
    "    \n",
    "    ##-- Keep relevant features on all_users_df:\n",
    "    for i in range(len(all_users_df)):\n",
    "        all_users_df.at[i, 'display_name'] = all_users_df.at[i, 'profile']['display_name']\n",
    "        #all_users_df.at[i, 'profile_title'] = all_users_df.at[i, 'profile']['title']  ## Contain a lot of missing values. Display_name seems more representative.\n",
    "    all_users_df = all_users_df[['id', 'team_id', 'name', 'deleted', 'display_name', 'is_bot']]#,'profile_title']]\n",
    "    \n",
    "    ##-- Handling missing values in all_users_df:\n",
    "    replace_empty_space(all_users_df, 'display_name')\n",
    "    replace_empty_space(all_users_df, 'name')\n",
    "    replace_empty_space(all_users_df, 'team_id')\n",
    "    replace_empty_space(all_users_df, 'id')\n",
    "    \n",
    "    return all_users_df\n",
    "\n",
    "\n",
    "\n",
    "def slack_json_to_dataframe(slack_json):\n",
    "    \"\"\" Function to extract channel's messages from a JSON file \"\"\"\n",
    "    \n",
    "    messages_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\", \n",
    "                                        \"reply_count\", \"reply_users_count\", \n",
    "                                        \"ts_latest_reply\", \"ts_thread\", \"parent_user_id\"])\n",
    "    \n",
    "    # ! IP20241118  \"= None\"  looks not good.  we need explicit sign of data was not provided\n",
    "    #     so, replace in the code ::  \" = None \"  with \" = 'n/d' \"\n",
    "\n",
    "    for message in range(len(slack_json)):\n",
    "        #if 'files' in slack_json[message] and slack_json[message]['files']:            #AG:commented out\n",
    "        #    messages_df.at[message, \"msg_id\"] = slack_json[message]['files'][0]['id']  #AG:commented out\n",
    "        if 'client_msg_id' in slack_json[message]:\n",
    "            messages_df.at[message, \"msg_id\"] = slack_json[message]['client_msg_id']\n",
    "        elif 'subtype' in slack_json[message]:                                       #AG:added\n",
    "            messages_df.at[message, \"msg_id\"] = slack_json[message]['subtype']       #AG:added\n",
    "        else:\n",
    "            messages_df.at[message, \"msg_id\"] = missing_value #'n/a'\n",
    "            \n",
    "        if 'ts' in slack_json[message]:\n",
    "            messages_df.at[message, \"ts\"] = slack_json[message]['ts']\n",
    "        else:\n",
    "            messages_df.at[message, \"ts\"] = missing_value #'n/a'  # 20241110-2\n",
    "            \n",
    "        messages_df.at[message, \"user\"] = slack_json[message].get('user', missing_value) #'n/a')\n",
    "        \n",
    "        if 'type' in slack_json[message]:\n",
    "            messages_df.at[message, \"type\"] = slack_json[message]['type']\n",
    "        else:\n",
    "            messages_df.at[message, \"type\"] = missing_value #'n/a'  # 20241110-2\n",
    "        \n",
    "        if 'text' in slack_json[message]:\n",
    "            messages_df.at[message, \"text\"] = slack_json[message]['text']\n",
    "        else:\n",
    "            messages_df.at[message, \"text\"] = missing_value #'n/a'  # 20241110-2\n",
    "\n",
    "        if 'reply_count' in slack_json[message]:\n",
    "            messages_df.at[message, \"reply_count\"] = slack_json[message]['reply_count']\n",
    "            messages_df.at[message, \"reply_users_count\"] = slack_json[message]['reply_users_count']\n",
    "            messages_df.at[message, \"ts_latest_reply\"] = slack_json[message]['latest_reply']\n",
    "        else:\n",
    "            messages_df.at[message, \"reply_count\"] = missing_value#'n/a'  # 20241110-2\n",
    "            messages_df.at[message, \"reply_users_count\"] = missing_value#'n/a'  # 20241110-2\n",
    "            messages_df.at[message, \"ts_latest_reply\"] = missing_value#'n/a'  # 20241110-2\n",
    "\n",
    "        if 'parent_user_id' in slack_json[message]:\n",
    "            messages_df.at[message, \"ts_thread\"] = slack_json[message]['thread_ts']\n",
    "            messages_df.at[message, \"parent_user_id\"] = slack_json[message]['parent_user_id']\n",
    "        else:\n",
    "            messages_df.at[message, \"ts_thread\"] = missing_value#'n/a'  # 20241110-2\n",
    "            messages_df.at[message, \"parent_user_id\"] = missing_value#'n/a'  # 20241110-2\n",
    "            \n",
    "    return messages_df\n",
    "    \n",
    "\n",
    "def get_channel_messages_df(export_path, curr_channel_name, json_list):\n",
    "    \"\"\" Extracts all the messages of a given channel from all its JSON files, and stores them on a data frame \"\"\"\n",
    "    channel_messages_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\",\n",
    "                                                \"reply_count\", \"reply_users_count\",\n",
    "                                                \"ts_latest_reply\", \"ts_thread\", \"parent_user_id\"])\n",
    "                                                # ,\"channel_folder\", \"json_name\", \"json_mod_date\"])          #_IP\n",
    "    \n",
    "    ##-- Iterate over JSONs inside the current channel's folder:\n",
    "    for file_day in range(len(json_list)):\n",
    "        #filejson_path = f\"{parentfolder_path}/{channels_json[curr_channel_name]['dayslist'][file_day]}\"\n",
    "        filejson_path = f\"{export_path}/{curr_channel_name}/{json_list[file_day]}\" #AG\n",
    "        \n",
    "        with open(filejson_path, encoding='utf-8') as f:\n",
    "            import_file_json = load(f)\n",
    "        import_file_df = slack_json_to_dataframe(import_file_json)\n",
    "        import_file_df['json_name'] = json_list[file_day]\n",
    "        import_file_df['json_mod_ts'] = getmtime(filejson_path)\n",
    "        \n",
    "        channel_messages_df = pd.concat([channel_messages_df, import_file_df], axis=0, ignore_index=True) \n",
    "    \n",
    "    channel_messages_df['channel_folder'] = curr_channel_name   #IP\n",
    "    return channel_messages_df\n",
    "\n",
    "\n",
    "def get_channel_users_df(channel_messages_df, users_df ):\n",
    "    \"\"\"Returns a data frame with the information of the users in current channel\"\"\"\n",
    "    ##-- Initialize channel_users_df as a copy of users_df:\n",
    "    channel_users_df = users_df.copy()\n",
    "    ##-- Find the unique set of users in channel:\n",
    "    channel_users_list = channel_messages_df['user'].unique()\n",
    "    ##-- Collect the indices of the users that are NOT in the channel:\n",
    "    indices_to_drop = [i for i in range(len(users_df)) if users_df.at[i,'id'] not in channel_users_list ]\n",
    "    ##-- Drop the rows on indices_to_drop:\n",
    "    channel_users_df.drop(channel_users_df.index[indices_to_drop], inplace=True)\n",
    "    return channel_users_df\n",
    "\n",
    "def add_users_info_to_messages(df_messages, df_users):\n",
    "    \"\"\"Uses the user's id in the format U1234567789 from the df_messages to find the \n",
    "    name, display name and if the user is a bot from df_users. \n",
    "    The 'name', 'display_name' and 'is_bot' are then added as columns to df_messages\"\"\"\n",
    "    for index in df_messages.index.values:\n",
    "        i_df = df_users[df_users['id']==df_messages.at[index,'user']]\n",
    "        if i_df['display_name'].shape[0]==0:        ##AG: 'USLACKBOT' is a special case\n",
    "            df_messages.at[index, 'name'] =  df_messages.at[index, 'user']\n",
    "            df_messages.at[index, 'display_name'] =  df_messages.at[index, 'user']\n",
    "            df_messages.at[index, 'is_bot'] =  True\n",
    "        else:\n",
    "            df_messages.at[index, 'name'] = i_df['name'].values\n",
    "            df_messages.at[index, 'display_name'] = i_df['display_name'].values\n",
    "            df_messages.at[index, 'is_bot'] = i_df['is_bot'].values\n",
    "        del i_df\n",
    "    #del channel_users_df\n",
    "\n",
    "\n",
    "\n",
    "# !!!  IP20241118   time convert is not proper. initial time in JSONs is NOT \"EST\" \n",
    "#                       may be - it provided in GMT+0\n",
    "#\n",
    "# !!! encounter problem/bag :: \n",
    "#    \"\" AmbiguousTimeError: Cannot infer dst time from 2023-11-05 01:21:45.201458931, try using the 'ambiguous' argument \"\n",
    "# need to be fixed in the code\n",
    "def ts_to_tz(df, original_column_name, new_column_name):\n",
    "    \"\"\"Transforms timestamps in a dataframe's column to dates on the \"US/Central\" timezone\"\"\"\n",
    "    df[original_column_name] = pd.to_numeric(df[original_column_name], errors='coerce')   #_IP\n",
    "    tzs = []\n",
    "    for i in range(len(df)):\n",
    "        i_is_null = pd.Series(df.at[i,original_column_name]).isnull().values[0]    #AG20241120\n",
    "        if i_is_null == True:\n",
    "            #i_date = '0000-00-00 00:00:00'\n",
    "            i_date = missing_value\n",
    "        else:\n",
    "            #print(i, df.at[i,original_column_name], '...')\n",
    "            # Convert the time to CST (UTC-6)\n",
    "            #df['datetime_cst'] = df['datetime_gmt'].dt.tz_convert('America/Chicago')\n",
    "\n",
    "            # IP20241119\n",
    "            i_date = pd.to_datetime(df.at[i,original_column_name], unit='s').tz_localize('UTC').tz_convert('US/Central')\n",
    "            #i_date = pd.to_datetime(df.at[i,original_column_name], unit='s').tz_localize('US/Eastern').tz_convert('US/Central')\n",
    "            i_date = datetime.strftime(i_date,\"%Y-%m-%d %H:%M:%S\")\n",
    "        tzs.append(i_date)\n",
    "    df[[original_column_name]].astype('datetime64[s]')\n",
    "    df[original_column_name] = tzs\n",
    "    df.rename(columns={original_column_name: new_column_name}, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "# IP20241118   should extract not only 1st url from \"text\", but all of url's\n",
    "# AG20241119   Added description of the function. All the urls present in a text are stored in a list.\n",
    "def extract_urls(df):\n",
    "    \"\"\"Extracts all the url links in df['text'] and stores them as a list in df['URL']\"\"\"\n",
    "    extractor = URLExtract()\n",
    "    for i in range(len(df)):\n",
    "        urls = extractor.find_urls( df.at[i,'text'] )\n",
    "        if len(urls)>0:\n",
    "            df.at[i,'URL'] = urls\n",
    "        else:\n",
    "            df.at[i,'URL'] = \"\" # None   IP2024118\n",
    "\n",
    "# AG20241119  Added description of the function:\n",
    "def user_id_to_name(df_messages, df_users):\n",
    "    \"\"\"Replaces the user_id in the format <@U12345678> to the user's display_name in df_messages['text'], which happens\n",
    "    when the user is mentioned in an Slack message through the option @user_name\"\"\"\n",
    "    for i in range(len(df_messages)):\n",
    "        text = df_messages.at[i,'text']\n",
    "        matches = re.findall(r'<+@[A-Za-z0-9]+>',text)\n",
    "        if len(matches)>0:\n",
    "            for match in matches:\n",
    "                user = match[2:-1]\n",
    "                name = df_users[df_users['id']==user]['display_name'].values[0]\n",
    "                text = re.sub(f\"<@{user}>\", f\"{name}\", text)\n",
    "                #AG20241120: Add cases where the user_id is not found in users_df.\n",
    "            df_messages.at[i,'text'] = text\n",
    "\n",
    "def channel_id_to_name(df_messages, df_users):\n",
    "    \"\"\"Replaces <#channel_id|channel_name> to channel_name in df_messages['text'], which happens\n",
    "    when the channel is mentioned in an Slack message through the option #channel_name\"\"\"\n",
    "    for i in range(len(df_messages)):\n",
    "        text = df_messages.at[i,'text']\n",
    "        matches = re.findall(r'#+[A-Za-z0-9]+\\|',text)\n",
    "        if len(matches)>0:\n",
    "            for match in matches:\n",
    "                text = re.sub(match, \"\", text)\n",
    "                text = re.sub(r\"<+\\|\", \"<\", text)\n",
    "            df_messages.at[i,'text'] = text\n",
    "\n",
    "def apply_excel_adjustments(file_path, curr_channel_name):\n",
    "    \"\"\" Excel file formatting/adjustments with  openpyxl (IP) \"\"\"\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb.active\n",
    "    ##-- Set the column width\n",
    "    column_widths = {\n",
    "        'B': 19, 'C': 15, 'E': 25, 'K': 25, 'L': 19, 'M': 19, 'N': 13, 'O': 13     \n",
    "    }\n",
    "    ##-- Apply the column widths\n",
    "    for col, width in column_widths.items():\n",
    "        ws.column_dimensions[col].width = width\n",
    "    #\n",
    "    ##-- Freeze the first row (Row 1)\n",
    "    ws.freeze_panes = 'A2'\n",
    "    ##-- Set font size and bold for the first row\n",
    "    font = Font(size=9, bold=True)\n",
    "    ##-- Define the RGB color\n",
    "    fill = PatternFill(start_color=\"e7c9fb\", end_color=\"e7c9fb\", fill_type=\"solid\")\n",
    "    ##-- Apply the color to the first row (row 1)\n",
    "    ##-- Apply the font formatting to the first row (Header row)\n",
    "    for cell in ws[1]:\n",
    "        cell.font = font\n",
    "        cell.fill = fill\n",
    "    #\n",
    "    ##-- Rename the sheet\n",
    "    ws_title = curr_channel_name \n",
    "    ws_title = ws_title[:31]\n",
    "    ws.title = ws_title \n",
    "    #\n",
    "    ##-- Save the changes to the Excel file\n",
    "    wb.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae148b4-3f0b-4f44-9d6b-abe0df76ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:09:35.662908 Started analysis after sanity checks\n",
      "slackexport_folder_path =>> /home/agds/Documents/RebeccaEverleneTrust/App/RebeccaEverlene_Slack_export\n",
      "14:09:35.691505 Obtained channels_df\n",
      "14:09:35.788957 Obtained users_df\n",
      "14:09:35.822667 Wrote channels_df to xlsx file\n",
      "14:09:35.921457 Wrote users_df to xlsx file\n",
      "14:09:35.921499 Starting loop over channels \n",
      "\n",
      "landmarks-sprint 14:09:35.921511  Set-up channel name and path to directory\n",
      "landmarks-sprint 14:09:35.925188  Collected channel messages from the json files\n",
      "landmarks-sprint 14:09:35.937273  Collected users in current channel\n",
      "landmarks-sprint 14:09:35.938938  Included the users information on channel_messages_df\n",
      "landmarks-sprint 14:09:35.939602  User's id replaced by their names in messages\n",
      "landmarks-sprint 14:09:35.967521  URLs extracted from messages\n",
      "main_analysys ->> landmarks-sprint 14:09:35.981850  Formated the dates and times in the dataframe\n",
      "landmarks-sprint 14:09:35.995445  Wrote curated messages to xlsx files \n",
      "\n",
      "unequivocally-big-ux-ui 14:09:35.995469  Set-up channel name and path to directory\n",
      "unequivocally-big-ux-ui 14:09:36.180246  Collected channel messages from the json files\n",
      "unequivocally-big-ux-ui 14:09:36.192639  Collected users in current channel\n",
      "unequivocally-big-ux-ui 14:09:36.314780  Included the users information on channel_messages_df\n",
      "unequivocally-big-ux-ui 14:09:36.371700  User's id replaced by their names in messages\n",
      "unequivocally-big-ux-ui 14:09:36.738276  URLs extracted from messages\n",
      "main_analysys ->> unequivocally-big-ux-ui 14:09:37.001465  Formated the dates and times in the dataframe\n",
      "unequivocally-big-ux-ui 14:09:37.277348  Wrote curated messages to xlsx files \n",
      "\n",
      "made-ux-ui 14:09:37.277399  Set-up channel name and path to directory\n",
      "made-ux-ui 14:09:37.383286  Collected channel messages from the json files\n",
      "made-ux-ui 14:09:37.395315  Collected users in current channel\n",
      "made-ux-ui 14:09:37.465344  Included the users information on channel_messages_df\n",
      "made-ux-ui 14:09:37.494755  User's id replaced by their names in messages\n",
      "made-ux-ui 14:09:37.765814  URLs extracted from messages\n",
      "main_analysys ->> made-ux-ui 14:09:37.930804  Formated the dates and times in the dataframe\n",
      "made-ux-ui 14:09:38.067638  Wrote curated messages to xlsx files \n",
      "\n",
      "outreach-fundraising-communications 14:09:38.067687  Set-up channel name and path to directory\n",
      "outreach-fundraising-communications 14:09:38.090064  Collected channel messages from the json files\n",
      "outreach-fundraising-communications 14:09:38.102282  Collected users in current channel\n",
      "outreach-fundraising-communications 14:09:38.114204  Included the users information on channel_messages_df\n",
      "outreach-fundraising-communications 14:09:38.124708  User's id replaced by their names in messages\n",
      "outreach-fundraising-communications 14:09:38.178129  URLs extracted from messages\n",
      "main_analysys ->> outreach-fundraising-communications 14:09:38.204364  Formated the dates and times in the dataframe\n",
      "outreach-fundraising-communications 14:09:38.238863  Wrote curated messages to xlsx files \n",
      "\n",
      "team-azure 14:09:38.238900  Set-up channel name and path to directory\n",
      "team-azure 14:09:38.261487  Collected channel messages from the json files\n",
      "team-azure 14:09:38.273559  Collected users in current channel\n",
      "team-azure 14:09:38.286026  Included the users information on channel_messages_df\n",
      "team-azure 14:09:38.299038  User's id replaced by their names in messages\n",
      "team-azure 14:09:38.351187  URLs extracted from messages\n",
      "main_analysys ->> team-azure 14:09:38.378881  Formated the dates and times in the dataframe\n",
      "team-azure 14:09:38.415186  Wrote curated messages to xlsx files \n",
      "\n",
      "sae-performing-arts-medkids 14:09:38.415212  Set-up channel name and path to directory\n",
      "sae-performing-arts-medkids 14:09:38.427427  Collected channel messages from the json files\n",
      "sae-performing-arts-medkids 14:09:38.439232  Collected users in current channel\n",
      "sae-performing-arts-medkids 14:09:38.445621  Included the users information on channel_messages_df\n",
      "sae-performing-arts-medkids 14:09:38.451289  User's id replaced by their names in messages\n",
      "sae-performing-arts-medkids 14:09:38.489962  URLs extracted from messages\n",
      "main_analysys ->> sae-performing-arts-medkids 14:09:38.504370  Formated the dates and times in the dataframe\n",
      "sae-performing-arts-medkids 14:09:38.529819  Wrote curated messages to xlsx files \n",
      "\n",
      "team-tech-order-up 14:09:38.529875  Set-up channel name and path to directory\n",
      "team-tech-order-up 14:09:38.987261  Collected channel messages from the json files\n",
      "team-tech-order-up 14:09:39.000913  Collected users in current channel\n",
      "team-tech-order-up 14:09:39.326607  Included the users information on channel_messages_df\n",
      "team-tech-order-up 14:09:39.587862  User's id replaced by their names in messages\n",
      "team-tech-order-up 14:09:40.841757  URLs extracted from messages\n",
      "main_analysys ->> team-tech-order-up 14:09:41.577789  Formated the dates and times in the dataframe\n",
      "team-tech-order-up 14:09:42.223845  Wrote curated messages to xlsx files \n",
      "\n",
      "team-game-designers-medkids 14:09:42.223899  Set-up channel name and path to directory\n",
      "team-game-designers-medkids 14:09:42.472008  Collected channel messages from the json files\n",
      "team-game-designers-medkids 14:09:42.485878  Collected users in current channel\n",
      "team-game-designers-medkids 14:09:42.617936  Included the users information on channel_messages_df\n",
      "team-game-designers-medkids 14:09:42.694619  User's id replaced by their names in messages\n",
      "team-game-designers-medkids 14:09:43.050140  URLs extracted from messages\n",
      "main_analysys ->> team-game-designers-medkids 14:09:43.339905  Formated the dates and times in the dataframe\n",
      "team-game-designers-medkids 14:09:43.648169  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-automation-team 14:09:43.648220  Set-up channel name and path to directory\n",
      "aspects-automation-team 14:09:44.233632  Collected channel messages from the json files\n",
      "aspects-automation-team 14:09:44.246215  Collected users in current channel\n",
      "aspects-automation-team 14:09:44.661902  Included the users information on channel_messages_df\n",
      "aspects-automation-team 14:09:44.994945  User's id replaced by their names in messages\n",
      "aspects-automation-team 14:09:46.643262  URLs extracted from messages\n",
      "main_analysys ->> aspects-automation-team 14:09:47.682967  Formated the dates and times in the dataframe\n",
      "aspects-automation-team 14:09:48.527527  Wrote curated messages to xlsx files \n",
      "\n",
      "aws-automation-team 14:09:48.527582  Set-up channel name and path to directory\n",
      "aws-automation-team 14:09:48.597539  Collected channel messages from the json files\n",
      "aws-automation-team 14:09:48.609853  Collected users in current channel\n",
      "aws-automation-team 14:09:48.650489  Included the users information on channel_messages_df\n",
      "aws-automation-team 14:09:48.685278  User's id replaced by their names in messages\n",
      "aws-automation-team 14:09:48.865286  URLs extracted from messages\n",
      "main_analysys ->> aws-automation-team 14:09:48.980987  Formated the dates and times in the dataframe\n",
      "aws-automation-team 14:09:49.083981  Wrote curated messages to xlsx files \n",
      "\n",
      "team-nabil-medkids-games 14:09:49.084019  Set-up channel name and path to directory\n",
      "team-nabil-medkids-games 14:09:49.175748  Collected channel messages from the json files\n",
      "team-nabil-medkids-games 14:09:49.188337  Collected users in current channel\n",
      "team-nabil-medkids-games 14:09:49.242688  Included the users information on channel_messages_df\n",
      "team-nabil-medkids-games 14:09:49.283462  User's id replaced by their names in messages\n",
      "team-nabil-medkids-games 14:09:49.465157  URLs extracted from messages\n",
      "main_analysys ->> team-nabil-medkids-games 14:09:49.575336  Formated the dates and times in the dataframe\n",
      "team-nabil-medkids-games 14:09:49.678441  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-landing-page 14:09:49.678490  Set-up channel name and path to directory\n",
      "landmarks-landing-page 14:09:49.716451  Collected channel messages from the json files\n",
      "landmarks-landing-page 14:09:49.728742  Collected users in current channel\n",
      "landmarks-landing-page 14:09:49.749256  Included the users information on channel_messages_df\n",
      "landmarks-landing-page 14:09:49.768700  User's id replaced by their names in messages\n",
      "landmarks-landing-page 14:09:49.875026  URLs extracted from messages\n",
      "main_analysys ->> landmarks-landing-page 14:09:49.920320  Formated the dates and times in the dataframe\n",
      "landmarks-landing-page 14:09:49.974458  Wrote curated messages to xlsx files \n",
      "\n",
      "tutors-on-call 14:09:49.974507  Set-up channel name and path to directory\n",
      "tutors-on-call 14:09:49.998850  Collected channel messages from the json files\n",
      "tutors-on-call 14:09:50.010909  Collected users in current channel\n",
      "tutors-on-call 14:09:50.023746  Included the users information on channel_messages_df\n",
      "tutors-on-call 14:09:50.029245  User's id replaced by their names in messages\n",
      "tutors-on-call 14:09:50.068982  URLs extracted from messages\n",
      "main_analysys ->> tutors-on-call 14:09:50.096769  Formated the dates and times in the dataframe\n",
      "tutors-on-call 14:09:50.198250  Wrote curated messages to xlsx files \n",
      "\n",
      "FC_F07CWGBGK0D_Untitled 14:09:50.198307  Set-up channel name and path to directory\n",
      "FC_F07CWGBGK0D_Untitled 14:09:50.202798  Collected channel messages from the json files\n",
      "FC_F07CWGBGK0D_Untitled 14:09:50.215113  Collected users in current channel\n",
      "FC_F07CWGBGK0D_Untitled 14:09:50.216897  Included the users information on channel_messages_df\n",
      "FC_F07CWGBGK0D_Untitled 14:09:50.217445  User's id replaced by their names in messages\n",
      "FC_F07CWGBGK0D_Untitled 14:09:50.229181  URLs extracted from messages\n",
      "main_analysys ->> FC_F07CWGBGK0D_Untitled 14:09:50.233598  Formated the dates and times in the dataframe\n",
      "FC_F07CWGBGK0D_Untitled 14:09:50.246031  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-2d-art-characters 14:09:50.246050  Set-up channel name and path to directory\n",
      "landmarks-2d-art-characters 14:09:51.100764  Collected channel messages from the json files\n",
      "landmarks-2d-art-characters 14:09:51.115148  Collected users in current channel\n",
      "landmarks-2d-art-characters 14:09:51.690424  Included the users information on channel_messages_df\n",
      "landmarks-2d-art-characters 14:09:51.877612  User's id replaced by their names in messages\n",
      "landmarks-2d-art-characters 14:09:53.175075  URLs extracted from messages\n",
      "main_analysys ->> landmarks-2d-art-characters 14:09:54.564517  Formated the dates and times in the dataframe\n",
      "landmarks-2d-art-characters 14:09:55.666403  Wrote curated messages to xlsx files \n",
      "\n",
      "college-aspects 14:09:55.666458  Set-up channel name and path to directory\n",
      "college-aspects 14:09:55.706024  Collected channel messages from the json files\n",
      "college-aspects 14:09:55.719543  Collected users in current channel\n",
      "college-aspects 14:09:55.743646  Included the users information on channel_messages_df\n",
      "college-aspects 14:09:55.771466  User's id replaced by their names in messages\n",
      "college-aspects 14:09:55.850205  URLs extracted from messages\n",
      "main_analysys ->> college-aspects 14:09:55.901655  Formated the dates and times in the dataframe\n",
      "college-aspects 14:09:56.024999  Wrote curated messages to xlsx files \n",
      "\n",
      "team-avatars-medkids 14:09:56.025026  Set-up channel name and path to directory\n",
      "team-avatars-medkids 14:09:56.047170  Collected channel messages from the json files\n",
      "team-avatars-medkids 14:09:56.059074  Collected users in current channel\n",
      "team-avatars-medkids 14:09:56.068849  Included the users information on channel_messages_df\n",
      "team-avatars-medkids 14:09:56.078346  User's id replaced by their names in messages\n",
      "team-avatars-medkids 14:09:56.136637  URLs extracted from messages\n",
      "main_analysys ->> team-avatars-medkids 14:09:56.158867  Formated the dates and times in the dataframe\n",
      "team-avatars-medkids 14:09:56.191084  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-geocodes 14:09:56.191114  Set-up channel name and path to directory\n",
      "landmarks-geocodes 14:09:56.262509  Collected channel messages from the json files\n",
      "landmarks-geocodes 14:09:56.275270  Collected users in current channel\n",
      "landmarks-geocodes 14:09:56.325958  Included the users information on channel_messages_df\n",
      "landmarks-geocodes 14:09:56.348775  User's id replaced by their names in messages\n",
      "landmarks-geocodes 14:09:56.461794  URLs extracted from messages\n",
      "main_analysys ->> landmarks-geocodes 14:09:56.572118  Formated the dates and times in the dataframe\n",
      "landmarks-geocodes 14:09:56.670332  Wrote curated messages to xlsx files \n",
      "\n",
      "team-writers-for-rebecca-everlene 14:09:56.670382  Set-up channel name and path to directory\n",
      "team-writers-for-rebecca-everlene 14:09:56.803523  Collected channel messages from the json files\n",
      "team-writers-for-rebecca-everlene 14:09:56.817719  Collected users in current channel\n",
      "team-writers-for-rebecca-everlene 14:09:56.895081  Included the users information on channel_messages_df\n",
      "team-writers-for-rebecca-everlene 14:09:56.948822  User's id replaced by their names in messages\n",
      "team-writers-for-rebecca-everlene 14:09:57.196064  URLs extracted from messages\n",
      "main_analysys ->> team-writers-for-rebecca-everlene 14:09:57.340745  Formated the dates and times in the dataframe\n",
      "team-writers-for-rebecca-everlene 14:09:57.467425  Wrote curated messages to xlsx files \n",
      "\n",
      "eat-like-us-inventory-project 14:09:57.467455  Set-up channel name and path to directory\n",
      "eat-like-us-inventory-project 14:09:57.592011  Collected channel messages from the json files\n",
      "eat-like-us-inventory-project 14:09:57.605063  Collected users in current channel\n",
      "eat-like-us-inventory-project 14:09:57.676254  Included the users information on channel_messages_df\n",
      "eat-like-us-inventory-project 14:09:57.731711  User's id replaced by their names in messages\n",
      "eat-like-us-inventory-project 14:09:57.979702  URLs extracted from messages\n",
      "main_analysys ->> eat-like-us-inventory-project 14:09:58.134477  Formated the dates and times in the dataframe\n",
      "eat-like-us-inventory-project 14:09:58.267802  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-2d-art-locations 14:09:58.267831  Set-up channel name and path to directory\n",
      "landmarks-2d-art-locations 14:09:58.478684  Collected channel messages from the json files\n",
      "landmarks-2d-art-locations 14:09:58.491922  Collected users in current channel\n",
      "landmarks-2d-art-locations 14:09:58.608391  Included the users information on channel_messages_df\n",
      "landmarks-2d-art-locations 14:09:58.687253  User's id replaced by their names in messages\n",
      "landmarks-2d-art-locations 14:09:58.955125  URLs extracted from messages\n",
      "main_analysys ->> landmarks-2d-art-locations 14:09:59.234565  Formated the dates and times in the dataframe\n",
      "landmarks-2d-art-locations 14:09:59.506413  Wrote curated messages to xlsx files \n",
      "\n",
      "team-google-workspace 14:09:59.506465  Set-up channel name and path to directory\n",
      "team-google-workspace 14:09:59.557633  Collected channel messages from the json files\n",
      "team-google-workspace 14:09:59.569637  Collected users in current channel\n",
      "team-google-workspace 14:09:59.606012  Included the users information on channel_messages_df\n",
      "team-google-workspace 14:09:59.636245  User's id replaced by their names in messages\n",
      "team-google-workspace 14:09:59.869727  URLs extracted from messages\n",
      "main_analysys ->> team-google-workspace 14:09:59.963588  Formated the dates and times in the dataframe\n",
      "team-google-workspace 14:10:00.046466  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-data-cleanup 14:10:00.046496  Set-up channel name and path to directory\n",
      "aspects-data-cleanup 14:10:00.108315  Collected channel messages from the json files\n",
      "aspects-data-cleanup 14:10:00.120976  Collected users in current channel\n",
      "aspects-data-cleanup 14:10:00.154138  Included the users information on channel_messages_df\n",
      "aspects-data-cleanup 14:10:00.192140  User's id replaced by their names in messages\n",
      "aspects-data-cleanup 14:10:00.305463  URLs extracted from messages\n",
      "main_analysys ->> aspects-data-cleanup 14:10:00.376318  Formated the dates and times in the dataframe\n",
      "aspects-data-cleanup 14:10:00.471426  Wrote curated messages to xlsx files \n",
      "\n",
      "FC_F05PD7LP5C3_Important_links 14:10:00.471487  Set-up channel name and path to directory\n",
      "FC_F05PD7LP5C3_Important_links 14:10:00.474996  Collected channel messages from the json files\n",
      "FC_F05PD7LP5C3_Important_links 14:10:00.487810  Collected users in current channel\n",
      "FC_F05PD7LP5C3_Important_links 14:10:00.488895  Included the users information on channel_messages_df\n",
      "FC_F05PD7LP5C3_Important_links 14:10:00.488973  User's id replaced by their names in messages\n",
      "FC_F05PD7LP5C3_Important_links 14:10:00.500169  URLs extracted from messages\n",
      "main_analysys ->> FC_F05PD7LP5C3_Important_links 14:10:00.504074  Formated the dates and times in the dataframe\n",
      "FC_F05PD7LP5C3_Important_links 14:10:00.516556  Wrote curated messages to xlsx files \n",
      "\n",
      "dreampad-for-dreamforce 14:10:00.516587  Set-up channel name and path to directory\n",
      "dreampad-for-dreamforce 14:10:00.528882  Collected channel messages from the json files\n",
      "dreampad-for-dreamforce 14:10:00.541685  Collected users in current channel\n",
      "dreampad-for-dreamforce 14:10:00.547901  Included the users information on channel_messages_df\n",
      "dreampad-for-dreamforce 14:10:00.551726  User's id replaced by their names in messages\n",
      "dreampad-for-dreamforce 14:10:00.578877  URLs extracted from messages\n",
      "main_analysys ->> dreampad-for-dreamforce 14:10:00.593123  Formated the dates and times in the dataframe\n",
      "dreampad-for-dreamforce 14:10:00.614713  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-unity-lightship-squad 14:10:00.614738  Set-up channel name and path to directory\n",
      "landmarks-unity-lightship-squad 14:10:00.681747  Collected channel messages from the json files\n",
      "landmarks-unity-lightship-squad 14:10:00.694891  Collected users in current channel\n",
      "landmarks-unity-lightship-squad 14:10:00.731624  Included the users information on channel_messages_df\n",
      "landmarks-unity-lightship-squad 14:10:00.768162  User's id replaced by their names in messages\n",
      "landmarks-unity-lightship-squad 14:10:00.926668  URLs extracted from messages\n",
      "main_analysys ->> landmarks-unity-lightship-squad 14:10:01.011843  Formated the dates and times in the dataframe\n",
      "landmarks-unity-lightship-squad 14:10:01.088190  Wrote curated messages to xlsx files \n",
      "\n",
      "team-barbara-medkids-games 14:10:01.088218  Set-up channel name and path to directory\n",
      "team-barbara-medkids-games 14:10:01.269633  Collected channel messages from the json files\n",
      "team-barbara-medkids-games 14:10:01.282585  Collected users in current channel\n",
      "team-barbara-medkids-games 14:10:01.379456  Included the users information on channel_messages_df\n",
      "team-barbara-medkids-games 14:10:01.417043  User's id replaced by their names in messages\n",
      "team-barbara-medkids-games 14:10:01.711163  URLs extracted from messages\n",
      "main_analysys ->> team-barbara-medkids-games 14:10:01.927974  Formated the dates and times in the dataframe\n",
      "team-barbara-medkids-games 14:10:02.102684  Wrote curated messages to xlsx files \n",
      "\n",
      "mockups-for-strategy-finance-budgets 14:10:02.102713  Set-up channel name and path to directory\n",
      "mockups-for-strategy-finance-budgets 14:10:02.111853  Collected channel messages from the json files\n",
      "mockups-for-strategy-finance-budgets 14:10:02.124258  Collected users in current channel\n",
      "mockups-for-strategy-finance-budgets 14:10:02.129063  Included the users information on channel_messages_df\n",
      "mockups-for-strategy-finance-budgets 14:10:02.132611  User's id replaced by their names in messages\n",
      "mockups-for-strategy-finance-budgets 14:10:02.163269  URLs extracted from messages\n",
      "main_analysys ->> mockups-for-strategy-finance-budgets 14:10:02.175060  Formated the dates and times in the dataframe\n",
      "mockups-for-strategy-finance-budgets 14:10:02.193919  Wrote curated messages to xlsx files \n",
      "\n",
      "FC_F07A54DBKUK_Untitled 14:10:02.193946  Set-up channel name and path to directory\n",
      "FC_F07A54DBKUK_Untitled 14:10:02.197770  Collected channel messages from the json files\n",
      "FC_F07A54DBKUK_Untitled 14:10:02.210427  Collected users in current channel\n",
      "FC_F07A54DBKUK_Untitled 14:10:02.211781  Included the users information on channel_messages_df\n",
      "FC_F07A54DBKUK_Untitled 14:10:02.212284  User's id replaced by their names in messages\n",
      "FC_F07A54DBKUK_Untitled 14:10:02.224853  URLs extracted from messages\n",
      "main_analysys ->> FC_F07A54DBKUK_Untitled 14:10:02.229377  Formated the dates and times in the dataframe\n",
      "FC_F07A54DBKUK_Untitled 14:10:02.242164  Wrote curated messages to xlsx files \n",
      "\n",
      "scrum 14:10:02.242182  Set-up channel name and path to directory\n",
      "scrum 14:10:02.478920  Collected channel messages from the json files\n",
      "scrum 14:10:02.492453  Collected users in current channel\n",
      "scrum 14:10:02.660355  Included the users information on channel_messages_df\n",
      "scrum 14:10:02.927483  User's id replaced by their names in messages\n",
      "scrum 14:10:03.839258  URLs extracted from messages\n",
      "main_analysys ->> scrum 14:10:04.198124  Formated the dates and times in the dataframe\n",
      "scrum 14:10:04.556153  Wrote curated messages to xlsx files \n",
      "\n",
      "team-audio-med-kids 14:10:04.556209  Set-up channel name and path to directory\n",
      "team-audio-med-kids 14:10:04.947084  Collected channel messages from the json files\n",
      "team-audio-med-kids 14:10:04.959334  Collected users in current channel\n",
      "team-audio-med-kids 14:10:05.189486  Included the users information on channel_messages_df\n",
      "team-audio-med-kids 14:10:05.273750  User's id replaced by their names in messages\n",
      "team-audio-med-kids 14:10:05.858357  URLs extracted from messages\n",
      "main_analysys ->> team-audio-med-kids 14:10:06.397883  Formated the dates and times in the dataframe\n",
      "team-audio-med-kids 14:10:06.879634  Wrote curated messages to xlsx files \n",
      "\n",
      "smitten-hitch-coparenting-project 14:10:06.879686  Set-up channel name and path to directory\n",
      "smitten-hitch-coparenting-project 14:10:06.943312  Collected channel messages from the json files\n",
      "smitten-hitch-coparenting-project 14:10:06.955408  Collected users in current channel\n",
      "smitten-hitch-coparenting-project 14:10:06.998881  Included the users information on channel_messages_df\n",
      "smitten-hitch-coparenting-project 14:10:07.032852  User's id replaced by their names in messages\n",
      "smitten-hitch-coparenting-project 14:10:07.216627  URLs extracted from messages\n",
      "main_analysys ->> smitten-hitch-coparenting-project 14:10:07.313715  Formated the dates and times in the dataframe\n",
      "smitten-hitch-coparenting-project 14:10:07.410283  Wrote curated messages to xlsx files \n",
      "\n",
      "time-off 14:10:07.410308  Set-up channel name and path to directory\n",
      "time-off 14:10:07.468672  Collected channel messages from the json files\n",
      "time-off 14:10:07.482376  Collected users in current channel\n",
      "time-off 14:10:07.523351  Included the users information on channel_messages_df\n",
      "time-off 14:10:07.561731  User's id replaced by their names in messages\n",
      "time-off 14:10:07.634367  URLs extracted from messages\n",
      "main_analysys ->> time-off 14:10:07.721389  Formated the dates and times in the dataframe\n",
      "time-off 14:10:07.803878  Wrote curated messages to xlsx files \n",
      "\n",
      "team-yigit-medkids-games 14:10:07.803927  Set-up channel name and path to directory\n",
      "team-yigit-medkids-games 14:10:08.157387  Collected channel messages from the json files\n",
      "team-yigit-medkids-games 14:10:08.170137  Collected users in current channel\n",
      "team-yigit-medkids-games 14:10:08.390900  Included the users information on channel_messages_df\n",
      "team-yigit-medkids-games 14:10:08.544997  User's id replaced by their names in messages\n",
      "team-yigit-medkids-games 14:10:09.422404  URLs extracted from messages\n",
      "main_analysys ->> team-yigit-medkids-games 14:10:09.934614  Formated the dates and times in the dataframe\n",
      "team-yigit-medkids-games 14:10:10.396744  Wrote curated messages to xlsx files \n",
      "\n",
      "team-back-end-dev 14:10:10.396797  Set-up channel name and path to directory\n",
      "team-back-end-dev 14:10:10.410501  Collected channel messages from the json files\n",
      "team-back-end-dev 14:10:10.422418  Collected users in current channel\n",
      "team-back-end-dev 14:10:10.430635  Included the users information on channel_messages_df\n",
      "team-back-end-dev 14:10:10.434269  User's id replaced by their names in messages\n",
      "team-back-end-dev 14:10:10.459329  URLs extracted from messages\n",
      "main_analysys ->> team-back-end-dev 14:10:10.477851  Formated the dates and times in the dataframe\n",
      "team-back-end-dev 14:10:10.505019  Wrote curated messages to xlsx files \n",
      "\n",
      "team-scapegoated 14:10:10.505045  Set-up channel name and path to directory\n",
      "team-scapegoated 14:10:10.563835  Collected channel messages from the json files\n",
      "team-scapegoated 14:10:10.576612  Collected users in current channel\n",
      "team-scapegoated 14:10:10.605399  Included the users information on channel_messages_df\n",
      "team-scapegoated 14:10:10.633053  User's id replaced by their names in messages\n",
      "team-scapegoated 14:10:10.781767  URLs extracted from messages\n",
      "main_analysys ->> team-scapegoated 14:10:10.857345  Formated the dates and times in the dataframe\n",
      "team-scapegoated 14:10:10.938260  Wrote curated messages to xlsx files \n",
      "\n",
      "grants 14:10:10.938319  Set-up channel name and path to directory\n",
      "grants 14:10:10.986464  Collected channel messages from the json files\n",
      "grants 14:10:11.002028  Collected users in current channel\n",
      "grants 14:10:11.022309  Included the users information on channel_messages_df\n",
      "grants 14:10:11.041553  User's id replaced by their names in messages\n",
      "grants 14:10:11.133575  URLs extracted from messages\n",
      "main_analysys ->> grants 14:10:11.177801  Formated the dates and times in the dataframe\n",
      "grants 14:10:11.230968  Wrote curated messages to xlsx files \n",
      "\n",
      "spaulding-daniels-leadership-group 14:10:11.231028  Set-up channel name and path to directory\n",
      "spaulding-daniels-leadership-group 14:10:11.264509  Collected channel messages from the json files\n",
      "spaulding-daniels-leadership-group 14:10:11.280021  Collected users in current channel\n",
      "spaulding-daniels-leadership-group 14:10:11.297857  Included the users information on channel_messages_df\n",
      "spaulding-daniels-leadership-group 14:10:11.318470  User's id replaced by their names in messages\n",
      "spaulding-daniels-leadership-group 14:10:11.467945  URLs extracted from messages\n",
      "main_analysys ->> spaulding-daniels-leadership-group 14:10:11.506832  Formated the dates and times in the dataframe\n",
      "spaulding-daniels-leadership-group 14:10:11.563067  Wrote curated messages to xlsx files \n",
      "\n",
      "presidential-service-award 14:10:11.563100  Set-up channel name and path to directory\n",
      "presidential-service-award 14:10:11.598070  Collected channel messages from the json files\n",
      "presidential-service-award 14:10:11.612903  Collected users in current channel\n",
      "presidential-service-award 14:10:11.630415  Included the users information on channel_messages_df\n",
      "presidential-service-award 14:10:11.646845  User's id replaced by their names in messages\n",
      "presidential-service-award 14:10:11.698220  URLs extracted from messages\n",
      "main_analysys ->> presidential-service-award 14:10:11.736699  Formated the dates and times in the dataframe\n",
      "presidential-service-award 14:10:11.781487  Wrote curated messages to xlsx files \n",
      "\n",
      "team-dev-issues-board 14:10:11.781538  Set-up channel name and path to directory\n",
      "team-dev-issues-board 14:10:11.789238  Collected channel messages from the json files\n",
      "team-dev-issues-board 14:10:11.802882  Collected users in current channel\n",
      "team-dev-issues-board 14:10:11.806178  Included the users information on channel_messages_df\n",
      "team-dev-issues-board 14:10:11.809179  User's id replaced by their names in messages\n",
      "team-dev-issues-board 14:10:11.822372  URLs extracted from messages\n",
      "main_analysys ->> team-dev-issues-board 14:10:11.830687  Formated the dates and times in the dataframe\n",
      "team-dev-issues-board 14:10:11.851105  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-interactive-wall 14:10:11.851135  Set-up channel name and path to directory\n",
      "landmarks-interactive-wall 14:10:11.986964  Collected channel messages from the json files\n",
      "landmarks-interactive-wall 14:10:12.001381  Collected users in current channel\n",
      "landmarks-interactive-wall 14:10:12.061867  Included the users information on channel_messages_df\n",
      "landmarks-interactive-wall 14:10:12.088422  User's id replaced by their names in messages\n",
      "landmarks-interactive-wall 14:10:12.308816  URLs extracted from messages\n",
      "main_analysys ->> landmarks-interactive-wall 14:10:12.427517  Formated the dates and times in the dataframe\n",
      "landmarks-interactive-wall 14:10:12.535334  Wrote curated messages to xlsx files \n",
      "\n",
      "team-maulana-medkids-games 14:10:12.535368  Set-up channel name and path to directory\n",
      "team-maulana-medkids-games 14:10:12.666219  Collected channel messages from the json files\n",
      "team-maulana-medkids-games 14:10:12.679323  Collected users in current channel\n",
      "team-maulana-medkids-games 14:10:12.748045  Included the users information on channel_messages_df\n",
      "team-maulana-medkids-games 14:10:12.784596  User's id replaced by their names in messages\n",
      "team-maulana-medkids-games 14:10:12.981862  URLs extracted from messages\n",
      "main_analysys ->> team-maulana-medkids-games 14:10:13.138082  Formated the dates and times in the dataframe\n",
      "team-maulana-medkids-games 14:10:13.266896  Wrote curated messages to xlsx files \n",
      "\n",
      "team-christa-medkids-games 14:10:13.266931  Set-up channel name and path to directory\n",
      "team-christa-medkids-games 14:10:13.326703  Collected channel messages from the json files\n",
      "team-christa-medkids-games 14:10:13.339568  Collected users in current channel\n",
      "team-christa-medkids-games 14:10:13.369511  Included the users information on channel_messages_df\n",
      "team-christa-medkids-games 14:10:13.385387  User's id replaced by their names in messages\n",
      "team-christa-medkids-games 14:10:13.475706  URLs extracted from messages\n",
      "main_analysys ->> team-christa-medkids-games 14:10:13.539996  Formated the dates and times in the dataframe\n",
      "team-christa-medkids-games 14:10:13.606404  Wrote curated messages to xlsx files \n",
      "\n",
      "team-front-end-web-developers-medkids 14:10:13.606460  Set-up channel name and path to directory\n",
      "team-front-end-web-developers-medkids 14:10:14.437614  Collected channel messages from the json files\n",
      "team-front-end-web-developers-medkids 14:10:14.451601  Collected users in current channel\n",
      "team-front-end-web-developers-medkids 14:10:15.087953  Included the users information on channel_messages_df\n",
      "team-front-end-web-developers-medkids 14:10:15.499344  User's id replaced by their names in messages\n",
      "team-front-end-web-developers-medkids 14:10:17.116780  URLs extracted from messages\n",
      "main_analysys ->> team-front-end-web-developers-medkids 14:10:18.416051  Formated the dates and times in the dataframe\n",
      "team-front-end-web-developers-medkids 14:10:19.565256  Wrote curated messages to xlsx files \n",
      "\n",
      "team-ink 14:10:19.565310  Set-up channel name and path to directory\n",
      "team-ink 14:10:19.611439  Collected channel messages from the json files\n",
      "team-ink 14:10:19.623648  Collected users in current channel\n",
      "team-ink 14:10:19.651990  Included the users information on channel_messages_df\n",
      "team-ink 14:10:19.679764  User's id replaced by their names in messages\n",
      "team-ink 14:10:19.888534  URLs extracted from messages\n",
      "main_analysys ->> team-ink 14:10:19.977215  Formated the dates and times in the dataframe\n",
      "team-ink 14:10:20.054764  Wrote curated messages to xlsx files \n",
      "\n",
      "cpts-training-team 14:10:20.054795  Set-up channel name and path to directory\n",
      "cpts-training-team 14:10:20.107012  Collected channel messages from the json files\n",
      "cpts-training-team 14:10:20.121596  Collected users in current channel\n",
      "cpts-training-team 14:10:20.142571  Included the users information on channel_messages_df\n",
      "cpts-training-team 14:10:20.156586  User's id replaced by their names in messages\n",
      "cpts-training-team 14:10:20.342570  URLs extracted from messages\n",
      "main_analysys ->> cpts-training-team 14:10:20.383113  Formated the dates and times in the dataframe\n",
      "cpts-training-team 14:10:20.430862  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-ux-ui-designers 14:10:20.430886  Set-up channel name and path to directory\n",
      "landmarks-ux-ui-designers 14:10:21.052713  Collected channel messages from the json files\n",
      "landmarks-ux-ui-designers 14:10:21.067747  Collected users in current channel\n",
      "landmarks-ux-ui-designers 14:10:21.522032  Included the users information on channel_messages_df\n",
      "landmarks-ux-ui-designers 14:10:21.643169  User's id replaced by their names in messages\n",
      "landmarks-ux-ui-designers 14:10:22.833193  URLs extracted from messages\n",
      "main_analysys ->> landmarks-ux-ui-designers 14:10:23.825467  Formated the dates and times in the dataframe\n",
      "landmarks-ux-ui-designers 14:10:24.698191  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-production-team 14:10:24.698242  Set-up channel name and path to directory\n",
      "landmarks-production-team 14:10:24.750153  Collected channel messages from the json files\n",
      "landmarks-production-team 14:10:24.762546  Collected users in current channel\n",
      "landmarks-production-team 14:10:24.793794  Included the users information on channel_messages_df\n",
      "landmarks-production-team 14:10:24.807591  User's id replaced by their names in messages\n",
      "landmarks-production-team 14:10:24.887368  URLs extracted from messages\n",
      "main_analysys ->> landmarks-production-team 14:10:24.961416  Formated the dates and times in the dataframe\n",
      "landmarks-production-team 14:10:25.029847  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks 14:10:25.029900  Set-up channel name and path to directory\n",
      "landmarks 14:10:25.281745  Collected channel messages from the json files\n",
      "landmarks 14:10:25.295935  Collected users in current channel\n",
      "landmarks 14:10:25.431723  Included the users information on channel_messages_df\n",
      "landmarks 14:10:25.574902  User's id replaced by their names in messages\n",
      "landmarks 14:10:26.149906  URLs extracted from messages\n",
      "main_analysys ->> landmarks 14:10:26.449617  Formated the dates and times in the dataframe\n",
      "landmarks 14:10:26.693141  Wrote curated messages to xlsx files \n",
      "\n",
      "salesforce-automation-team 14:10:26.693197  Set-up channel name and path to directory\n",
      "salesforce-automation-team 14:10:27.101783  Collected channel messages from the json files\n",
      "salesforce-automation-team 14:10:27.119683  Collected users in current channel\n",
      "salesforce-automation-team 14:10:27.451230  Included the users information on channel_messages_df\n",
      "salesforce-automation-team 14:10:27.636609  User's id replaced by their names in messages\n",
      "salesforce-automation-team 14:10:28.525252  URLs extracted from messages\n",
      "main_analysys ->> salesforce-automation-team 14:10:29.096809  Formated the dates and times in the dataframe\n",
      "salesforce-automation-team 14:10:29.610135  Wrote curated messages to xlsx files \n",
      "\n",
      "design-brainstorming-sessions 14:10:29.610191  Set-up channel name and path to directory\n",
      "design-brainstorming-sessions 14:10:29.660909  Collected channel messages from the json files\n",
      "design-brainstorming-sessions 14:10:29.673386  Collected users in current channel\n",
      "design-brainstorming-sessions 14:10:29.702060  Included the users information on channel_messages_df\n",
      "design-brainstorming-sessions 14:10:29.724271  User's id replaced by their names in messages\n",
      "design-brainstorming-sessions 14:10:29.812683  URLs extracted from messages\n",
      "main_analysys ->> design-brainstorming-sessions 14:10:29.882607  Formated the dates and times in the dataframe\n",
      "design-brainstorming-sessions 14:10:29.955642  Wrote curated messages to xlsx files \n",
      "\n",
      "policies-and-sops-team 14:10:29.955696  Set-up channel name and path to directory\n",
      "policies-and-sops-team 14:10:29.984422  Collected channel messages from the json files\n",
      "policies-and-sops-team 14:10:29.997754  Collected users in current channel\n",
      "policies-and-sops-team 14:10:30.012326  Included the users information on channel_messages_df\n",
      "policies-and-sops-team 14:10:30.024759  User's id replaced by their names in messages\n",
      "policies-and-sops-team 14:10:30.117482  URLs extracted from messages\n",
      "main_analysys ->> policies-and-sops-team 14:10:30.149700  Formated the dates and times in the dataframe\n",
      "policies-and-sops-team 14:10:30.188655  Wrote curated messages to xlsx files \n",
      "\n",
      "team-2d-art-for-medkids 14:10:30.188704  Set-up channel name and path to directory\n",
      "team-2d-art-for-medkids 14:10:30.393708  Collected channel messages from the json files\n",
      "team-2d-art-for-medkids 14:10:30.407238  Collected users in current channel\n",
      "team-2d-art-for-medkids 14:10:30.515132  Included the users information on channel_messages_df\n",
      "team-2d-art-for-medkids 14:10:30.552768  User's id replaced by their names in messages\n",
      "team-2d-art-for-medkids 14:10:30.723537  URLs extracted from messages\n",
      "main_analysys ->> team-2d-art-for-medkids 14:10:30.964983  Formated the dates and times in the dataframe\n",
      "team-2d-art-for-medkids 14:10:31.216089  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-locations 14:10:31.216145  Set-up channel name and path to directory\n",
      "landmarks-locations 14:10:32.629560  Collected channel messages from the json files\n",
      "landmarks-locations 14:10:32.643826  Collected users in current channel\n",
      "landmarks-locations 14:10:33.591487  Included the users information on channel_messages_df\n",
      "landmarks-locations 14:10:33.746862  User's id replaced by their names in messages\n",
      "landmarks-locations 14:10:34.438082  URLs extracted from messages\n",
      "main_analysys ->> landmarks-locations 14:10:36.312735  Formated the dates and times in the dataframe\n",
      "landmarks-locations 14:10:38.023839  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-design-content-updates 14:10:38.023894  Set-up channel name and path to directory\n",
      "aspects-design-content-updates 14:10:38.219209  Collected channel messages from the json files\n",
      "aspects-design-content-updates 14:10:38.231805  Collected users in current channel\n",
      "aspects-design-content-updates 14:10:38.337161  Included the users information on channel_messages_df\n",
      "aspects-design-content-updates 14:10:38.371024  User's id replaced by their names in messages\n",
      "aspects-design-content-updates 14:10:38.637524  URLs extracted from messages\n",
      "main_analysys ->> aspects-design-content-updates 14:10:38.858370  Formated the dates and times in the dataframe\n",
      "aspects-design-content-updates 14:10:39.093947  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-vertical-slice-team 14:10:39.094006  Set-up channel name and path to directory\n",
      "landmarks-vertical-slice-team 14:10:39.133244  Collected channel messages from the json files\n",
      "landmarks-vertical-slice-team 14:10:39.148392  Collected users in current channel\n",
      "landmarks-vertical-slice-team 14:10:39.170944  Included the users information on channel_messages_df\n",
      "landmarks-vertical-slice-team 14:10:39.180484  User's id replaced by their names in messages\n",
      "landmarks-vertical-slice-team 14:10:39.246142  URLs extracted from messages\n",
      "main_analysys ->> landmarks-vertical-slice-team 14:10:39.295835  Formated the dates and times in the dataframe\n",
      "landmarks-vertical-slice-team 14:10:39.346381  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-mapping 14:10:39.346435  Set-up channel name and path to directory\n",
      "landmarks-mapping 14:10:39.450094  Collected channel messages from the json files\n",
      "landmarks-mapping 14:10:39.463526  Collected users in current channel\n",
      "landmarks-mapping 14:10:39.531236  Included the users information on channel_messages_df\n",
      "landmarks-mapping 14:10:39.566728  User's id replaced by their names in messages\n",
      "landmarks-mapping 14:10:39.776378  URLs extracted from messages\n",
      "main_analysys ->> landmarks-mapping 14:10:39.917742  Formated the dates and times in the dataframe\n",
      "landmarks-mapping 14:10:40.135127  Wrote curated messages to xlsx files \n",
      "\n",
      "grants-team-2024 14:10:40.135179  Set-up channel name and path to directory\n",
      "grants-team-2024 14:10:40.364802  Collected channel messages from the json files\n",
      "grants-team-2024 14:10:40.377594  Collected users in current channel\n",
      "grants-team-2024 14:10:40.544430  Included the users information on channel_messages_df\n",
      "grants-team-2024 14:10:40.681119  User's id replaced by their names in messages\n",
      "grants-team-2024 14:10:41.322522  URLs extracted from messages\n",
      "main_analysys ->> grants-team-2024 14:10:41.685856  Formated the dates and times in the dataframe\n",
      "grants-team-2024 14:10:42.005479  Wrote curated messages to xlsx files \n",
      "\n",
      "fundraising-initiatives 14:10:42.005542  Set-up channel name and path to directory\n",
      "fundraising-initiatives 14:10:42.177718  Collected channel messages from the json files\n",
      "fundraising-initiatives 14:10:42.190566  Collected users in current channel\n",
      "fundraising-initiatives 14:10:42.284159  Included the users information on channel_messages_df\n",
      "fundraising-initiatives 14:10:42.353457  User's id replaced by their names in messages\n",
      "fundraising-initiatives 14:10:42.885927  URLs extracted from messages\n",
      "main_analysys ->> fundraising-initiatives 14:10:43.124475  Formated the dates and times in the dataframe\n",
      "fundraising-initiatives 14:10:43.340268  Wrote curated messages to xlsx files \n",
      "\n",
      "the-jog-app 14:10:43.340327  Set-up channel name and path to directory\n",
      "the-jog-app 14:10:43.461191  Collected channel messages from the json files\n",
      "the-jog-app 14:10:43.477269  Collected users in current channel\n",
      "the-jog-app 14:10:43.560306  Included the users information on channel_messages_df\n",
      "the-jog-app 14:10:43.618820  User's id replaced by their names in messages\n",
      "the-jog-app 14:10:44.023669  URLs extracted from messages\n",
      "main_analysys ->> the-jog-app 14:10:44.206997  Formated the dates and times in the dataframe\n",
      "the-jog-app 14:10:44.434666  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-game-designers 14:10:44.434736  Set-up channel name and path to directory\n",
      "landmarks-game-designers 14:10:44.733081  Collected channel messages from the json files\n",
      "landmarks-game-designers 14:10:44.751952  Collected users in current channel\n",
      "landmarks-game-designers 14:10:44.955299  Included the users information on channel_messages_df\n",
      "landmarks-game-designers 14:10:45.088860  User's id replaced by their names in messages\n",
      "landmarks-game-designers 14:10:45.812456  URLs extracted from messages\n",
      "main_analysys ->> landmarks-game-designers 14:10:46.115152  Formated the dates and times in the dataframe\n",
      "landmarks-game-designers 14:10:46.349469  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-sprint-planning 14:10:46.349518  Set-up channel name and path to directory\n",
      "landmarks-sprint-planning 14:10:46.409867  Collected channel messages from the json files\n",
      "landmarks-sprint-planning 14:10:46.423453  Collected users in current channel\n",
      "landmarks-sprint-planning 14:10:46.458549  Included the users information on channel_messages_df\n",
      "landmarks-sprint-planning 14:10:46.483826  User's id replaced by their names in messages\n",
      "landmarks-sprint-planning 14:10:46.603788  URLs extracted from messages\n",
      "main_analysys ->> landmarks-sprint-planning 14:10:46.702452  Formated the dates and times in the dataframe\n",
      "landmarks-sprint-planning 14:10:46.788317  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-2d-art-items-and-guides 14:10:46.788354  Set-up channel name and path to directory\n",
      "landmarks-2d-art-items-and-guides 14:10:46.830987  Collected channel messages from the json files\n",
      "landmarks-2d-art-items-and-guides 14:10:46.847716  Collected users in current channel\n",
      "landmarks-2d-art-items-and-guides 14:10:46.864921  Included the users information on channel_messages_df\n",
      "landmarks-2d-art-items-and-guides 14:10:46.879476  User's id replaced by their names in messages\n",
      "landmarks-2d-art-items-and-guides 14:10:46.913408  URLs extracted from messages\n",
      "main_analysys ->> landmarks-2d-art-items-and-guides 14:10:46.954751  Formated the dates and times in the dataframe\n",
      "landmarks-2d-art-items-and-guides 14:10:47.008691  Wrote curated messages to xlsx files \n",
      "\n",
      "team-ux-ui-designers-medkids 14:10:47.008725  Set-up channel name and path to directory\n",
      "team-ux-ui-designers-medkids 14:10:47.452793  Collected channel messages from the json files\n",
      "team-ux-ui-designers-medkids 14:10:47.466962  Collected users in current channel\n",
      "team-ux-ui-designers-medkids 14:10:47.678879  Included the users information on channel_messages_df\n",
      "team-ux-ui-designers-medkids 14:10:47.814245  User's id replaced by their names in messages\n",
      "team-ux-ui-designers-medkids 14:10:48.980320  URLs extracted from messages\n",
      "main_analysys ->> team-ux-ui-designers-medkids 14:10:49.440864  Formated the dates and times in the dataframe\n",
      "team-ux-ui-designers-medkids 14:10:49.875684  Wrote curated messages to xlsx files \n",
      "\n",
      "team-cybersecurity-innovations 14:10:49.875744  Set-up channel name and path to directory\n",
      "team-cybersecurity-innovations 14:10:49.952492  Collected channel messages from the json files\n",
      "team-cybersecurity-innovations 14:10:49.964673  Collected users in current channel\n",
      "team-cybersecurity-innovations 14:10:50.012409  Included the users information on channel_messages_df\n",
      "team-cybersecurity-innovations 14:10:50.055169  User's id replaced by their names in messages\n",
      "team-cybersecurity-innovations 14:10:50.335760  URLs extracted from messages\n",
      "main_analysys ->> team-cybersecurity-innovations 14:10:50.448938  Formated the dates and times in the dataframe\n",
      "team-cybersecurity-innovations 14:10:50.545990  Wrote curated messages to xlsx files \n",
      "\n",
      "intros-and-shoutouts 14:10:50.546016  Set-up channel name and path to directory\n",
      "intros-and-shoutouts 14:10:50.637206  Collected channel messages from the json files\n",
      "intros-and-shoutouts 14:10:50.651752  Collected users in current channel\n",
      "intros-and-shoutouts 14:10:50.720571  Included the users information on channel_messages_df\n",
      "intros-and-shoutouts 14:10:50.761696  User's id replaced by their names in messages\n",
      "intros-and-shoutouts 14:10:50.944427  URLs extracted from messages\n",
      "main_analysys ->> intros-and-shoutouts 14:10:51.109398  Formated the dates and times in the dataframe\n",
      "intros-and-shoutouts 14:10:51.240316  Wrote curated messages to xlsx files \n",
      "\n",
      "team-animators-medkids 14:10:51.240366  Set-up channel name and path to directory\n",
      "team-animators-medkids 14:10:51.444450  Collected channel messages from the json files\n",
      "team-animators-medkids 14:10:51.457500  Collected users in current channel\n",
      "team-animators-medkids 14:10:51.554554  Included the users information on channel_messages_df\n",
      "team-animators-medkids 14:10:51.601304  User's id replaced by their names in messages\n",
      "team-animators-medkids 14:10:51.788358  URLs extracted from messages\n",
      "main_analysys ->> team-animators-medkids 14:10:52.001969  Formated the dates and times in the dataframe\n",
      "team-animators-medkids 14:10:52.238119  Wrote curated messages to xlsx files \n",
      "\n",
      "strategic-planning 14:10:52.238172  Set-up channel name and path to directory\n",
      "strategic-planning 14:10:52.307729  Collected channel messages from the json files\n",
      "strategic-planning 14:10:52.320302  Collected users in current channel\n",
      "strategic-planning 14:10:52.354377  Included the users information on channel_messages_df\n",
      "strategic-planning 14:10:52.390480  User's id replaced by their names in messages\n",
      "strategic-planning 14:10:52.617028  URLs extracted from messages\n",
      "main_analysys ->> strategic-planning 14:10:52.691522  Formated the dates and times in the dataframe\n",
      "strategic-planning 14:10:52.766210  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 14:10:52.766237  Set-up channel name and path to directory\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 14:10:55.068594  Collected channel messages from the json files\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 14:10:55.094737  Collected users in current channel\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 14:10:56.755667  Included the users information on channel_messages_df\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 14:10:57.309574  User's id replaced by their names in messages\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 14:10:59.705966  URLs extracted from messages\n",
      "main_analysys ->> aspects-tuition-reimbursement-scholarships-special-projects 14:11:02.968476  Formated the dates and times in the dataframe\n",
      "aspects-tuition-reimbursement-scholarships-special-projects 14:11:05.921831  Wrote curated messages to xlsx files \n",
      "\n",
      "team-orderup-developers-medkids 14:11:05.921910  Set-up channel name and path to directory\n",
      "team-orderup-developers-medkids 14:11:06.193410  Collected channel messages from the json files\n",
      "team-orderup-developers-medkids 14:11:06.206445  Collected users in current channel\n",
      "team-orderup-developers-medkids 14:11:06.417970  Included the users information on channel_messages_df\n",
      "team-orderup-developers-medkids 14:11:06.608078  User's id replaced by their names in messages\n",
      "team-orderup-developers-medkids 14:11:07.158205  URLs extracted from messages\n",
      "main_analysys ->> team-orderup-developers-medkids 14:11:07.662948  Formated the dates and times in the dataframe\n",
      "team-orderup-developers-medkids 14:11:08.051250  Wrote curated messages to xlsx files \n",
      "\n",
      "team-chef-medkids 14:11:08.051306  Set-up channel name and path to directory\n",
      "team-chef-medkids 14:11:08.172815  Collected channel messages from the json files\n",
      "team-chef-medkids 14:11:08.185959  Collected users in current channel\n",
      "team-chef-medkids 14:11:08.258081  Included the users information on channel_messages_df\n",
      "team-chef-medkids 14:11:08.324476  User's id replaced by their names in messages\n",
      "team-chef-medkids 14:11:08.702187  URLs extracted from messages\n",
      "main_analysys ->> team-chef-medkids 14:11:08.859637  Formated the dates and times in the dataframe\n",
      "team-chef-medkids 14:11:09.130063  Wrote curated messages to xlsx files \n",
      "\n",
      "doodly-toonly-cartoons-medkids 14:11:09.130123  Set-up channel name and path to directory\n",
      "doodly-toonly-cartoons-medkids 14:11:09.163324  Collected channel messages from the json files\n",
      "doodly-toonly-cartoons-medkids 14:11:09.177350  Collected users in current channel\n",
      "doodly-toonly-cartoons-medkids 14:11:09.197874  Included the users information on channel_messages_df\n",
      "doodly-toonly-cartoons-medkids 14:11:09.208295  User's id replaced by their names in messages\n",
      "doodly-toonly-cartoons-medkids 14:11:09.282317  URLs extracted from messages\n",
      "main_analysys ->> doodly-toonly-cartoons-medkids 14:11:09.324266  Formated the dates and times in the dataframe\n",
      "doodly-toonly-cartoons-medkids 14:11:09.372537  Wrote curated messages to xlsx files \n",
      "\n",
      "team-bowen-medkids-games 14:11:09.372589  Set-up channel name and path to directory\n",
      "team-bowen-medkids-games 14:11:09.465487  Collected channel messages from the json files\n",
      "team-bowen-medkids-games 14:11:09.478382  Collected users in current channel\n",
      "team-bowen-medkids-games 14:11:09.526410  Included the users information on channel_messages_df\n",
      "team-bowen-medkids-games 14:11:09.553787  User's id replaced by their names in messages\n",
      "team-bowen-medkids-games 14:11:09.717580  URLs extracted from messages\n",
      "main_analysys ->> team-bowen-medkids-games 14:11:09.816231  Formated the dates and times in the dataframe\n",
      "team-bowen-medkids-games 14:11:09.907510  Wrote curated messages to xlsx files \n",
      "\n",
      "general 14:11:09.907533  Set-up channel name and path to directory\n",
      "general 14:11:11.560661  Collected channel messages from the json files\n",
      "general 14:11:11.589226  Collected users in current channel\n",
      "general 14:11:12.841202  Included the users information on channel_messages_df\n",
      "general 14:11:13.428200  User's id replaced by their names in messages\n",
      "general 14:11:17.070566  URLs extracted from messages\n",
      "main_analysys ->> general 14:11:19.364611  Formated the dates and times in the dataframe\n",
      "general 14:11:21.561043  Wrote curated messages to xlsx files \n",
      "\n",
      "champions 14:11:21.561109  Set-up channel name and path to directory\n",
      "champions 14:11:21.674191  Collected channel messages from the json files\n",
      "champions 14:11:21.687118  Collected users in current channel\n",
      "champions 14:11:21.744999  Included the users information on channel_messages_df\n",
      "champions 14:11:21.787537  User's id replaced by their names in messages\n",
      "champions 14:11:21.937681  URLs extracted from messages\n",
      "main_analysys ->> champions 14:11:22.070727  Formated the dates and times in the dataframe\n",
      "champions 14:11:22.182055  Wrote curated messages to xlsx files \n",
      "\n",
      "3d-art-team-a-landmarks 14:11:22.182109  Set-up channel name and path to directory\n",
      "3d-art-team-a-landmarks 14:11:22.431526  Collected channel messages from the json files\n",
      "3d-art-team-a-landmarks 14:11:22.444314  Collected users in current channel\n",
      "3d-art-team-a-landmarks 14:11:22.587140  Included the users information on channel_messages_df\n",
      "3d-art-team-a-landmarks 14:11:22.624016  User's id replaced by their names in messages\n",
      "3d-art-team-a-landmarks 14:11:22.941452  URLs extracted from messages\n",
      "main_analysys ->> 3d-art-team-a-landmarks 14:11:23.299460  Formated the dates and times in the dataframe\n",
      "3d-art-team-a-landmarks 14:11:23.555542  Wrote curated messages to xlsx files \n",
      "\n",
      "team-kamil-medkids-games 14:11:23.555595  Set-up channel name and path to directory\n",
      "team-kamil-medkids-games 14:11:23.745925  Collected channel messages from the json files\n",
      "team-kamil-medkids-games 14:11:23.758425  Collected users in current channel\n",
      "team-kamil-medkids-games 14:11:23.861503  Included the users information on channel_messages_df\n",
      "team-kamil-medkids-games 14:11:23.888412  User's id replaced by their names in messages\n",
      "team-kamil-medkids-games 14:11:24.138759  URLs extracted from messages\n",
      "main_analysys ->> team-kamil-medkids-games 14:11:24.373132  Formated the dates and times in the dataframe\n",
      "team-kamil-medkids-games 14:11:24.556318  Wrote curated messages to xlsx files \n",
      "\n",
      "20-team 14:11:24.556361  Set-up channel name and path to directory\n",
      "20-team 14:11:24.628768  Collected channel messages from the json files\n",
      "20-team 14:11:24.641348  Collected users in current channel\n",
      "20-team 14:11:24.679434  Included the users information on channel_messages_df\n",
      "20-team 14:11:24.694370  User's id replaced by their names in messages\n",
      "20-team 14:11:24.800944  URLs extracted from messages\n",
      "main_analysys ->> 20-team 14:11:24.893453  Formated the dates and times in the dataframe\n",
      "20-team 14:11:25.096009  Wrote curated messages to xlsx files \n",
      "\n",
      "FC_F05L6N323GV_无标题 14:11:25.096049  Set-up channel name and path to directory\n",
      "FC_F05L6N323GV_无标题 14:11:25.099140  Collected channel messages from the json files\n",
      "FC_F05L6N323GV_无标题 14:11:25.111752  Collected users in current channel\n",
      "FC_F05L6N323GV_无标题 14:11:25.113254  Included the users information on channel_messages_df\n",
      "FC_F05L6N323GV_无标题 14:11:25.113318  User's id replaced by their names in messages\n",
      "FC_F05L6N323GV_无标题 14:11:25.124259  URLs extracted from messages\n",
      "main_analysys ->> FC_F05L6N323GV_无标题 14:11:25.128624  Formated the dates and times in the dataframe\n",
      "FC_F05L6N323GV_无标题 14:11:25.141130  Wrote curated messages to xlsx files \n",
      "\n",
      "unequivocally-big-summer-2024 14:11:25.141147  Set-up channel name and path to directory\n",
      "unequivocally-big-summer-2024 14:11:25.224854  Collected channel messages from the json files\n",
      "unequivocally-big-summer-2024 14:11:25.236728  Collected users in current channel\n",
      "unequivocally-big-summer-2024 14:11:25.295915  Included the users information on channel_messages_df\n",
      "unequivocally-big-summer-2024 14:11:25.319045  User's id replaced by their names in messages\n",
      "unequivocally-big-summer-2024 14:11:25.559756  URLs extracted from messages\n",
      "main_analysys ->> unequivocally-big-summer-2024 14:11:25.684344  Formated the dates and times in the dataframe\n",
      "unequivocally-big-summer-2024 14:11:25.799911  Wrote curated messages to xlsx files \n",
      "\n",
      "team-jira 14:11:25.799938  Set-up channel name and path to directory\n",
      "team-jira 14:11:25.833764  Collected channel messages from the json files\n",
      "team-jira 14:11:25.846196  Collected users in current channel\n",
      "team-jira 14:11:25.864707  Included the users information on channel_messages_df\n",
      "team-jira 14:11:25.885873  User's id replaced by their names in messages\n",
      "team-jira 14:11:26.002656  URLs extracted from messages\n",
      "main_analysys ->> team-jira 14:11:26.044951  Formated the dates and times in the dataframe\n",
      "team-jira 14:11:26.089927  Wrote curated messages to xlsx files \n",
      "\n",
      "how-do-i 14:11:26.089968  Set-up channel name and path to directory\n",
      "how-do-i 14:11:26.094378  Collected channel messages from the json files\n",
      "how-do-i 14:11:26.109736  Collected users in current channel\n",
      "how-do-i 14:11:26.113371  Included the users information on channel_messages_df\n",
      "how-do-i 14:11:26.115893  User's id replaced by their names in messages\n",
      "how-do-i 14:11:26.138619  URLs extracted from messages\n",
      "main_analysys ->> how-do-i 14:11:26.149291  Formated the dates and times in the dataframe\n",
      "how-do-i 14:11:26.175568  Wrote curated messages to xlsx files \n",
      "\n",
      "3d-art-blender-landmarks 14:11:26.175597  Set-up channel name and path to directory\n",
      "3d-art-blender-landmarks 14:11:27.324081  Collected channel messages from the json files\n",
      "3d-art-blender-landmarks 14:11:27.339932  Collected users in current channel\n",
      "3d-art-blender-landmarks 14:11:28.048241  Included the users information on channel_messages_df\n",
      "3d-art-blender-landmarks 14:11:28.282068  User's id replaced by their names in messages\n",
      "3d-art-blender-landmarks 14:11:29.773663  URLs extracted from messages\n",
      "main_analysys ->> 3d-art-blender-landmarks 14:11:31.414323  Formated the dates and times in the dataframe\n",
      "3d-art-blender-landmarks 14:11:32.745780  Wrote curated messages to xlsx files \n",
      "\n",
      "pm-tl-channel 14:11:32.745832  Set-up channel name and path to directory\n",
      "pm-tl-channel 14:11:32.835578  Collected channel messages from the json files\n",
      "pm-tl-channel 14:11:32.848152  Collected users in current channel\n",
      "pm-tl-channel 14:11:32.903932  Included the users information on channel_messages_df\n",
      "pm-tl-channel 14:11:32.947630  User's id replaced by their names in messages\n",
      "pm-tl-channel 14:11:33.222076  URLs extracted from messages\n",
      "main_analysys ->> pm-tl-channel 14:11:33.349928  Formated the dates and times in the dataframe\n",
      "pm-tl-channel 14:11:33.463463  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-unity-developers 14:11:33.463490  Set-up channel name and path to directory\n",
      "landmarks-unity-developers 14:11:33.872675  Collected channel messages from the json files\n",
      "landmarks-unity-developers 14:11:33.886602  Collected users in current channel\n",
      "landmarks-unity-developers 14:11:34.144676  Included the users information on channel_messages_df\n",
      "landmarks-unity-developers 14:11:34.256128  User's id replaced by their names in messages\n",
      "landmarks-unity-developers 14:11:35.016984  URLs extracted from messages\n",
      "main_analysys ->> landmarks-unity-developers 14:11:35.580646  Formated the dates and times in the dataframe\n",
      "landmarks-unity-developers 14:11:36.114199  Wrote curated messages to xlsx files \n",
      "\n",
      "real-estate-verification 14:11:36.114250  Set-up channel name and path to directory\n",
      "real-estate-verification 14:11:36.177503  Collected channel messages from the json files\n",
      "real-estate-verification 14:11:36.189774  Collected users in current channel\n",
      "real-estate-verification 14:11:36.220923  Included the users information on channel_messages_df\n",
      "real-estate-verification 14:11:36.234845  User's id replaced by their names in messages\n",
      "real-estate-verification 14:11:36.388782  URLs extracted from messages\n",
      "main_analysys ->> real-estate-verification 14:11:36.455903  Formated the dates and times in the dataframe\n",
      "real-estate-verification 14:11:36.536724  Wrote curated messages to xlsx files \n",
      "\n",
      "think-biver-saturday-checkins 14:11:36.536751  Set-up channel name and path to directory\n",
      "think-biver-saturday-checkins 14:11:38.127460  Collected channel messages from the json files\n",
      "think-biver-saturday-checkins 14:11:38.148385  Collected users in current channel\n",
      "think-biver-saturday-checkins 14:11:39.738870  Included the users information on channel_messages_df\n",
      "think-biver-saturday-checkins 14:11:40.564356  User's id replaced by their names in messages\n",
      "think-biver-saturday-checkins 14:11:46.053664  URLs extracted from messages\n",
      "main_analysys ->> think-biver-saturday-checkins 14:11:49.356060  Formated the dates and times in the dataframe\n",
      "think-biver-saturday-checkins 14:11:52.175929  Wrote curated messages to xlsx files \n",
      "\n",
      "tracker-board 14:11:52.175976  Set-up channel name and path to directory\n",
      "tracker-board 14:11:52.280557  Collected channel messages from the json files\n",
      "tracker-board 14:11:52.292601  Collected users in current channel\n",
      "tracker-board 14:11:52.357980  Included the users information on channel_messages_df\n",
      "tracker-board 14:11:52.382673  User's id replaced by their names in messages\n",
      "tracker-board 14:11:52.765690  URLs extracted from messages\n",
      "main_analysys ->> tracker-board 14:11:52.902672  Formated the dates and times in the dataframe\n",
      "tracker-board 14:11:53.032929  Wrote curated messages to xlsx files \n",
      "\n",
      "unequivocally-big-summer-2023 14:11:53.032980  Set-up channel name and path to directory\n",
      "unequivocally-big-summer-2023 14:11:53.353364  Collected channel messages from the json files\n",
      "unequivocally-big-summer-2023 14:11:53.370468  Collected users in current channel\n",
      "unequivocally-big-summer-2023 14:11:53.674467  Included the users information on channel_messages_df\n",
      "unequivocally-big-summer-2023 14:11:53.717068  User's id replaced by their names in messages\n",
      "unequivocally-big-summer-2023 14:11:54.281968  URLs extracted from messages\n",
      "main_analysys ->> unequivocally-big-summer-2023 14:11:54.800279  Formated the dates and times in the dataframe\n",
      "unequivocally-big-summer-2023 14:11:55.364308  Wrote curated messages to xlsx files \n",
      "\n",
      "budget-template-build 14:11:55.364359  Set-up channel name and path to directory\n",
      "budget-template-build 14:11:55.433575  Collected channel messages from the json files\n",
      "budget-template-build 14:11:55.445775  Collected users in current channel\n",
      "budget-template-build 14:11:55.505233  Included the users information on channel_messages_df\n",
      "budget-template-build 14:11:55.525874  User's id replaced by their names in messages\n",
      "budget-template-build 14:11:55.640602  URLs extracted from messages\n",
      "main_analysys ->> budget-template-build 14:11:55.783244  Formated the dates and times in the dataframe\n",
      "budget-template-build 14:11:55.912796  Wrote curated messages to xlsx files \n",
      "\n",
      "social-media-branding-team 14:11:55.912831  Set-up channel name and path to directory\n",
      "social-media-branding-team 14:11:55.991842  Collected channel messages from the json files\n",
      "social-media-branding-team 14:11:56.005560  Collected users in current channel\n",
      "social-media-branding-team 14:11:56.052796  Included the users information on channel_messages_df\n",
      "social-media-branding-team 14:11:56.092661  User's id replaced by their names in messages\n",
      "social-media-branding-team 14:11:56.390945  URLs extracted from messages\n",
      "main_analysys ->> social-media-branding-team 14:11:56.489677  Formated the dates and times in the dataframe\n",
      "social-media-branding-team 14:11:56.649686  Wrote curated messages to xlsx files \n",
      "\n",
      "team-infographics-and-charting 14:11:56.649777  Set-up channel name and path to directory\n",
      "team-infographics-and-charting 14:11:57.240323  Collected channel messages from the json files\n",
      "team-infographics-and-charting 14:11:57.255177  Collected users in current channel\n",
      "team-infographics-and-charting 14:11:57.675365  Included the users information on channel_messages_df\n",
      "team-infographics-and-charting 14:11:57.900550  User's id replaced by their names in messages\n",
      "team-infographics-and-charting 14:11:59.074789  URLs extracted from messages\n",
      "main_analysys ->> team-infographics-and-charting 14:11:59.988297  Formated the dates and times in the dataframe\n",
      "team-infographics-and-charting 14:12:00.764026  Wrote curated messages to xlsx files \n",
      "\n",
      "campaign-ret 14:12:00.764079  Set-up channel name and path to directory\n",
      "campaign-ret 14:12:00.947270  Collected channel messages from the json files\n",
      "campaign-ret 14:12:00.963565  Collected users in current channel\n",
      "campaign-ret 14:12:01.056521  Included the users information on channel_messages_df\n",
      "campaign-ret 14:12:01.148636  User's id replaced by their names in messages\n",
      "campaign-ret 14:12:01.259496  URLs extracted from messages\n",
      "main_analysys ->> campaign-ret 14:12:01.449010  Formated the dates and times in the dataframe\n",
      "campaign-ret 14:12:01.611713  Wrote curated messages to xlsx files \n",
      "\n",
      "random 14:12:01.611742  Set-up channel name and path to directory\n",
      "random 14:12:02.252910  Collected channel messages from the json files\n",
      "random 14:12:02.281121  Collected users in current channel\n",
      "random 14:12:02.582868  Included the users information on channel_messages_df\n",
      "random 14:12:02.922524  User's id replaced by their names in messages\n",
      "random 14:12:03.202752  URLs extracted from messages\n",
      "main_analysys ->> random 14:12:03.859239  Formated the dates and times in the dataframe\n",
      "random 14:12:04.389687  Wrote curated messages to xlsx files \n",
      "\n",
      "team-chef-logistics-medkids 14:12:04.389739  Set-up channel name and path to directory\n",
      "team-chef-logistics-medkids 14:12:04.462164  Collected channel messages from the json files\n",
      "team-chef-logistics-medkids 14:12:04.474596  Collected users in current channel\n",
      "team-chef-logistics-medkids 14:12:04.524806  Included the users information on channel_messages_df\n",
      "team-chef-logistics-medkids 14:12:04.554051  User's id replaced by their names in messages\n",
      "team-chef-logistics-medkids 14:12:04.834466  URLs extracted from messages\n",
      "main_analysys ->> team-chef-logistics-medkids 14:12:04.944915  Formated the dates and times in the dataframe\n",
      "team-chef-logistics-medkids 14:12:05.104023  Wrote curated messages to xlsx files \n",
      "\n",
      "cpts-strategy-team 14:12:05.104057  Set-up channel name and path to directory\n",
      "cpts-strategy-team 14:12:05.183145  Collected channel messages from the json files\n",
      "cpts-strategy-team 14:12:05.204459  Collected users in current channel\n",
      "cpts-strategy-team 14:12:05.259685  Included the users information on channel_messages_df\n",
      "cpts-strategy-team 14:12:05.301563  User's id replaced by their names in messages\n",
      "cpts-strategy-team 14:12:05.591092  URLs extracted from messages\n",
      "main_analysys ->> cpts-strategy-team 14:12:05.669403  Formated the dates and times in the dataframe\n",
      "cpts-strategy-team 14:12:05.742900  Wrote curated messages to xlsx files \n",
      "\n",
      "3d-art-team-b-landmarks 14:12:05.742928  Set-up channel name and path to directory\n",
      "3d-art-team-b-landmarks 14:12:05.921480  Collected channel messages from the json files\n",
      "3d-art-team-b-landmarks 14:12:05.934705  Collected users in current channel\n",
      "3d-art-team-b-landmarks 14:12:06.033778  Included the users information on channel_messages_df\n",
      "3d-art-team-b-landmarks 14:12:06.074280  User's id replaced by their names in messages\n",
      "3d-art-team-b-landmarks 14:12:06.356152  URLs extracted from messages\n",
      "main_analysys ->> 3d-art-team-b-landmarks 14:12:06.585980  Formated the dates and times in the dataframe\n",
      "3d-art-team-b-landmarks 14:12:06.755263  Wrote curated messages to xlsx files \n",
      "\n",
      "unequivocally-big-suite-content-team 14:12:06.755293  Set-up channel name and path to directory\n",
      "unequivocally-big-suite-content-team 14:12:06.835992  Collected channel messages from the json files\n",
      "unequivocally-big-suite-content-team 14:12:06.848724  Collected users in current channel\n",
      "unequivocally-big-suite-content-team 14:12:06.893567  Included the users information on channel_messages_df\n",
      "unequivocally-big-suite-content-team 14:12:06.937318  User's id replaced by their names in messages\n",
      "unequivocally-big-suite-content-team 14:12:07.133730  URLs extracted from messages\n",
      "main_analysys ->> unequivocally-big-suite-content-team 14:12:07.229765  Formated the dates and times in the dataframe\n",
      "unequivocally-big-suite-content-team 14:12:07.321439  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-ux-meeting-notes 14:12:07.321467  Set-up channel name and path to directory\n",
      "landmarks-ux-meeting-notes 14:12:07.342309  Collected channel messages from the json files\n",
      "landmarks-ux-meeting-notes 14:12:07.355236  Collected users in current channel\n",
      "landmarks-ux-meeting-notes 14:12:07.370370  Included the users information on channel_messages_df\n",
      "landmarks-ux-meeting-notes 14:12:07.382406  User's id replaced by their names in messages\n",
      "landmarks-ux-meeting-notes 14:12:07.464875  URLs extracted from messages\n",
      "main_analysys ->> landmarks-ux-meeting-notes 14:12:07.490827  Formated the dates and times in the dataframe\n",
      "landmarks-ux-meeting-notes 14:12:07.525600  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-content-development 14:12:07.525628  Set-up channel name and path to directory\n",
      "landmarks-content-development 14:12:07.573561  Collected channel messages from the json files\n",
      "landmarks-content-development 14:12:07.586573  Collected users in current channel\n",
      "landmarks-content-development 14:12:07.610335  Included the users information on channel_messages_df\n",
      "landmarks-content-development 14:12:07.628921  User's id replaced by their names in messages\n",
      "landmarks-content-development 14:12:07.781709  URLs extracted from messages\n",
      "main_analysys ->> landmarks-content-development 14:12:07.830905  Formated the dates and times in the dataframe\n",
      "landmarks-content-development 14:12:07.885445  Wrote curated messages to xlsx files \n",
      "\n",
      "team-leads 14:12:07.885473  Set-up channel name and path to directory\n",
      "team-leads 14:12:07.907172  Collected channel messages from the json files\n",
      "team-leads 14:12:07.921956  Collected users in current channel\n",
      "team-leads 14:12:07.935943  Included the users information on channel_messages_df\n",
      "team-leads 14:12:07.951705  User's id replaced by their names in messages\n",
      "team-leads 14:12:08.007131  URLs extracted from messages\n",
      "main_analysys ->> team-leads 14:12:08.037581  Formated the dates and times in the dataframe\n",
      "team-leads 14:12:08.076784  Wrote curated messages to xlsx files \n",
      "\n",
      "aspects-data-analysis 14:12:08.076834  Set-up channel name and path to directory\n",
      "aspects-data-analysis 14:12:08.152831  Collected channel messages from the json files\n",
      "aspects-data-analysis 14:12:08.165294  Collected users in current channel\n",
      "aspects-data-analysis 14:12:08.211169  Included the users information on channel_messages_df\n",
      "aspects-data-analysis 14:12:08.231089  User's id replaced by their names in messages\n",
      "aspects-data-analysis 14:12:08.368958  URLs extracted from messages\n",
      "main_analysys ->> aspects-data-analysis 14:12:08.472223  Formated the dates and times in the dataframe\n",
      "aspects-data-analysis 14:12:08.562046  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-uxreview-gd-dev 14:12:08.562072  Set-up channel name and path to directory\n",
      "landmarks-uxreview-gd-dev 14:12:08.585207  Collected channel messages from the json files\n",
      "landmarks-uxreview-gd-dev 14:12:08.597613  Collected users in current channel\n",
      "landmarks-uxreview-gd-dev 14:12:08.610252  Included the users information on channel_messages_df\n",
      "landmarks-uxreview-gd-dev 14:12:08.617040  User's id replaced by their names in messages\n",
      "landmarks-uxreview-gd-dev 14:12:08.674175  URLs extracted from messages\n",
      "main_analysys ->> landmarks-uxreview-gd-dev 14:12:08.704804  Formated the dates and times in the dataframe\n",
      "landmarks-uxreview-gd-dev 14:12:08.755191  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-sprints-2d-art 14:12:08.755218  Set-up channel name and path to directory\n",
      "landmarks-sprints-2d-art 14:12:08.770955  Collected channel messages from the json files\n",
      "landmarks-sprints-2d-art 14:12:08.783321  Collected users in current channel\n",
      "landmarks-sprints-2d-art 14:12:08.792469  Included the users information on channel_messages_df\n",
      "landmarks-sprints-2d-art 14:12:08.800594  User's id replaced by their names in messages\n",
      "landmarks-sprints-2d-art 14:12:08.820929  URLs extracted from messages\n",
      "main_analysys ->> landmarks-sprints-2d-art 14:12:08.841542  Formated the dates and times in the dataframe\n",
      "landmarks-sprints-2d-art 14:12:08.867266  Wrote curated messages to xlsx files \n",
      "\n",
      "artxdev-team 14:12:08.867289  Set-up channel name and path to directory\n",
      "artxdev-team 14:12:08.900973  Collected channel messages from the json files\n",
      "artxdev-team 14:12:08.915003  Collected users in current channel\n",
      "artxdev-team 14:12:08.933966  Included the users information on channel_messages_df\n",
      "artxdev-team 14:12:08.942143  User's id replaced by their names in messages\n",
      "artxdev-team 14:12:08.989629  URLs extracted from messages\n",
      "main_analysys ->> artxdev-team 14:12:09.036091  Formated the dates and times in the dataframe\n",
      "artxdev-team 14:12:09.140945  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-product-managers 14:12:09.140998  Set-up channel name and path to directory\n",
      "landmarks-product-managers 14:12:09.187600  Collected channel messages from the json files\n",
      "landmarks-product-managers 14:12:09.202314  Collected users in current channel\n",
      "landmarks-product-managers 14:12:09.230396  Included the users information on channel_messages_df\n",
      "landmarks-product-managers 14:12:09.248173  User's id replaced by their names in messages\n",
      "landmarks-product-managers 14:12:09.351153  URLs extracted from messages\n",
      "main_analysys ->> landmarks-product-managers 14:12:09.414131  Formated the dates and times in the dataframe\n",
      "landmarks-product-managers 14:12:09.475941  Wrote curated messages to xlsx files \n",
      "\n",
      "chief-of-chatting-space 14:12:09.475973  Set-up channel name and path to directory\n",
      "chief-of-chatting-space 14:12:09.686748  Collected channel messages from the json files\n",
      "chief-of-chatting-space 14:12:09.703556  Collected users in current channel\n",
      "chief-of-chatting-space 14:12:09.824858  Included the users information on channel_messages_df\n",
      "chief-of-chatting-space 14:12:09.904241  User's id replaced by their names in messages\n",
      "chief-of-chatting-space 14:12:10.170364  URLs extracted from messages\n",
      "main_analysys ->> chief-of-chatting-space 14:12:10.409512  Formated the dates and times in the dataframe\n",
      "chief-of-chatting-space 14:12:10.609885  Wrote curated messages to xlsx files \n",
      "\n",
      "landmarks-forward 14:12:10.609914  Set-up channel name and path to directory\n",
      "landmarks-forward 14:12:11.235319  Collected channel messages from the json files\n",
      "landmarks-forward 14:12:11.248885  Collected users in current channel\n",
      "landmarks-forward 14:12:11.729961  Included the users information on channel_messages_df\n",
      "landmarks-forward 14:12:11.957966  User's id replaced by their names in messages\n",
      "landmarks-forward 14:12:13.105927  URLs extracted from messages\n",
      "main_analysys ->> landmarks-forward 14:12:14.192160  Formated the dates and times in the dataframe\n",
      "landmarks-forward 14:12:15.188698  Wrote curated messages to xlsx files \n",
      "\n",
      "licensing 14:12:15.188759  Set-up channel name and path to directory\n",
      "licensing 14:12:15.234322  Collected channel messages from the json files\n",
      "licensing 14:12:15.248734  Collected users in current channel\n",
      "licensing 14:12:15.272983  Included the users information on channel_messages_df\n",
      "licensing 14:12:15.290374  User's id replaced by their names in messages\n",
      "licensing 14:12:15.392636  URLs extracted from messages\n",
      "main_analysys ->> licensing 14:12:15.441905  Formated the dates and times in the dataframe\n",
      "licensing 14:12:15.500564  Wrote curated messages to xlsx files \n",
      "\n",
      "team-anatomy-island-for-medkids 14:12:15.500592  Set-up channel name and path to directory\n",
      "team-anatomy-island-for-medkids 14:12:16.584670  Collected channel messages from the json files\n",
      "team-anatomy-island-for-medkids 14:12:16.599539  Collected users in current channel\n",
      "team-anatomy-island-for-medkids 14:12:17.344339  Included the users information on channel_messages_df\n",
      "team-anatomy-island-for-medkids 14:12:17.651411  User's id replaced by their names in messages\n",
      "team-anatomy-island-for-medkids 14:12:20.277724  URLs extracted from messages\n",
      "main_analysys ->> team-anatomy-island-for-medkids 14:12:22.081662  Formated the dates and times in the dataframe\n",
      "team-anatomy-island-for-medkids 14:12:23.505487  Wrote curated messages to xlsx files \n",
      "\n",
      "onboarding-central 14:12:23.505540  Set-up channel name and path to directory\n",
      "onboarding-central 14:12:23.525563  Collected channel messages from the json files\n",
      "onboarding-central 14:12:23.537808  Collected users in current channel\n",
      "onboarding-central 14:12:23.551510  Included the users information on channel_messages_df\n",
      "onboarding-central 14:12:23.561964  User's id replaced by their names in messages\n",
      "onboarding-central 14:12:23.596434  URLs extracted from messages\n",
      "main_analysys ->> onboarding-central 14:12:23.627275  Formated the dates and times in the dataframe\n",
      "onboarding-central 14:12:23.664472  Wrote curated messages to xlsx files \n",
      "\n",
      "team-github-solutions 14:12:23.664498  Set-up channel name and path to directory\n",
      "team-github-solutions 14:12:23.892772  Collected channel messages from the json files\n",
      "team-github-solutions 14:12:23.905174  Collected users in current channel\n",
      "team-github-solutions 14:12:24.115820  Included the users information on channel_messages_df\n",
      "team-github-solutions 14:12:24.232213  User's id replaced by their names in messages\n",
      "team-github-solutions 14:12:24.718514  URLs extracted from messages\n",
      "main_analysys ->> team-github-solutions 14:12:25.140918  Formated the dates and times in the dataframe\n",
      "team-github-solutions 14:12:25.585553  Wrote curated messages to xlsx files \n",
      "\n",
      "team-issues-medkids 14:12:25.585605  Set-up channel name and path to directory\n",
      "team-issues-medkids 14:12:25.724327  Collected channel messages from the json files\n",
      "team-issues-medkids 14:12:25.737453  Collected users in current channel\n",
      "team-issues-medkids 14:12:25.804053  Included the users information on channel_messages_df\n",
      "team-issues-medkids 14:12:25.864155  User's id replaced by their names in messages\n",
      "team-issues-medkids 14:12:26.119495  URLs extracted from messages\n",
      "main_analysys ->> team-issues-medkids 14:12:26.270400  Formated the dates and times in the dataframe\n",
      "team-issues-medkids 14:12:26.416395  Wrote curated messages to xlsx files \n",
      "\n",
      "team-budgets 14:12:26.416446  Set-up channel name and path to directory\n",
      "team-budgets 14:12:26.423679  Collected channel messages from the json files\n",
      "team-budgets 14:12:26.435664  Collected users in current channel\n",
      "team-budgets 14:12:26.439186  Included the users information on channel_messages_df\n",
      "team-budgets 14:12:26.444042  User's id replaced by their names in messages\n",
      "team-budgets 14:12:26.473806  URLs extracted from messages\n",
      "main_analysys ->> team-budgets 14:12:26.482555  Formated the dates and times in the dataframe\n",
      "team-budgets 14:12:26.498851  Wrote curated messages to xlsx files \n",
      "\n",
      "team-medkids-minitours 14:12:26.498875  Set-up channel name and path to directory\n",
      "team-medkids-minitours 14:12:26.501199  Collected channel messages from the json files\n",
      "team-medkids-minitours 14:12:26.513021  Collected users in current channel\n",
      "team-medkids-minitours 14:12:26.514031  Included the users information on channel_messages_df\n",
      "team-medkids-minitours 14:12:26.514474  User's id replaced by their names in messages\n",
      "team-medkids-minitours 14:12:26.525169  URLs extracted from messages\n",
      "main_analysys ->> team-medkids-minitours 14:12:26.528886  Formated the dates and times in the dataframe\n",
      "team-medkids-minitours 14:12:26.540635  Wrote curated messages to xlsx files \n",
      "\n",
      "team-voiceover-artists-med-kids 14:12:26.540652  Set-up channel name and path to directory\n",
      "team-voiceover-artists-med-kids 14:12:27.521395  Collected channel messages from the json files\n",
      "team-voiceover-artists-med-kids 14:12:27.535904  Collected users in current channel\n",
      "team-voiceover-artists-med-kids 14:12:28.135119  Included the users information on channel_messages_df\n",
      "team-voiceover-artists-med-kids 14:12:28.412918  User's id replaced by their names in messages\n",
      "team-voiceover-artists-med-kids 14:12:30.113057  URLs extracted from messages\n",
      "main_analysys ->> team-voiceover-artists-med-kids 14:12:31.376292  Formated the dates and times in the dataframe\n",
      "team-voiceover-artists-med-kids 14:12:32.510683  Wrote curated messages to xlsx files \n",
      "\n",
      "team-zixi-medkids-games 14:12:32.510736  Set-up channel name and path to directory\n",
      "team-zixi-medkids-games 14:12:32.616330  Collected channel messages from the json files\n",
      "team-zixi-medkids-games 14:12:32.628550  Collected users in current channel\n",
      "team-zixi-medkids-games 14:12:32.690261  Included the users information on channel_messages_df\n",
      "team-zixi-medkids-games 14:12:32.735266  User's id replaced by their names in messages\n",
      "team-zixi-medkids-games 14:12:32.895680  URLs extracted from messages\n",
      "main_analysys ->> team-zixi-medkids-games 14:12:33.044677  Formated the dates and times in the dataframe\n",
      "team-zixi-medkids-games 14:12:33.214456  Wrote curated messages to xlsx files \n",
      "\n",
      "14:12:33.214625 Done\n"
     ]
    }
   ],
   "source": [
    "##-- Main analysis:\n",
    "if continue_analysis==False:\n",
    "    print(\"Please review the input information\")\n",
    "else:    \n",
    "    print(datetime.now().time(), 'Started analysis after sanity checks' )\n",
    "    print(\"slackexport_folder_path =>> \"+slackexport_folder_path)\n",
    "    ##-- Extract the channels and users information into dataframes:\n",
    "    channels_df = get_all_channels_info(slackexport_folder_path)\n",
    "    print(datetime.now().time(), 'Obtained channels_df')\n",
    "    users_df = get_all_users_info(slackexport_folder_path)\n",
    "    print(datetime.now().time(), 'Obtained users_df')\n",
    "    \n",
    "    ##-- Write all channel's info to .xlsx files, if requested by user:\n",
    "    if write_all_channels_info==True:\n",
    "        slack_export_channel_filename = \"_all_channels\"\n",
    "        slack_export_channel_folder_path_xlsx = f\"{converted_directory}/{slack_export_channel_filename}{'.xlsx'}\"\n",
    "        channels_df.to_excel(slack_export_channel_folder_path_xlsx, index=False)\n",
    "        print(datetime.now().time(), 'Wrote channels_df to xlsx file')  \n",
    "    \n",
    "    ##-- Write all users's info to .xlsx files, if requested by user:\n",
    "    if write_all_users_info==True:\n",
    "        slack_export_user_filename = \"_all_users\"        \n",
    "        slack_export_user_folder_path_xlsx = f\"{converted_directory}/{slack_export_user_filename}{'.xlsx'}\" #_IP\n",
    "        users_df.to_excel(slack_export_user_folder_path_xlsx, index=False) #_IP\n",
    "        print(datetime.now().time(), 'Wrote users_df to xlsx file')\n",
    "\n",
    "    ##-- Iterate over channel's folders:\n",
    "    print(datetime.now().time(), 'Starting loop over channels', '\\n')\n",
    "    for i_channel in range(len(channels_names)):\n",
    "\n",
    "        ##-- Define the name of the current channel and the source path containing its json files:\n",
    "        curr_channel_name = channels_names[i_channel] \n",
    "        parentfolder_path = f\"{slackexport_folder_path}/{curr_channel_name}\" \n",
    "        print(curr_channel_name, datetime.now().time(), ' Set-up channel name and path to directory')\n",
    "        \n",
    "        ##-- Collect all the current_channel's messages in channel_messages_df through the function get_channel_messages_df:\n",
    "        json_list = all_channels_jsonFiles_dates[i_channel]\n",
    "        channel_messages_df = get_channel_messages_df(slackexport_folder_path, curr_channel_name, json_list)  \n",
    "        print(curr_channel_name, datetime.now().time(), ' Collected channel messages from the json files')\n",
    "\n",
    "        ##-- Collect all the users in the current channel through the function get_channel_users_df:\n",
    "        channel_users_df = get_channel_users_df(channel_messages_df, users_df )\n",
    "        print(curr_channel_name, datetime.now().time(), ' Collected users in current channel')\n",
    "        \n",
    "        ##-- Use channel_users_df to fill-in the user's information in channel_messages_df:  (define in function onces tested)\n",
    "        add_users_info_to_messages(channel_messages_df, channel_users_df)\n",
    "        print(curr_channel_name, datetime.now().time(), ' Included the users information on channel_messages_df')\n",
    "        \n",
    "        ##-- Replace user and team identifiers with their display_names whenever present in a message:\n",
    "        user_id_to_name(channel_messages_df, users_df) \n",
    "        channel_id_to_name(channel_messages_df, users_df)\n",
    "        print(curr_channel_name, datetime.now().time(), \" User's id replaced by their names in messages\")\n",
    "\n",
    "        ##-- Extract hyperlinks from messages, if present (extracted as a list; edit if needed):\n",
    "        extract_urls(channel_messages_df)\n",
    "        print(curr_channel_name, datetime.now().time(), ' URLs extracted from messages')\n",
    "\n",
    "        ##-- Change format of the time in seconds to a date in the CST time-zone: (Pending 'ts_latest_reply' and 'ts_thread'!)\n",
    "        #channel_messages_mindate = pd.to_datetime(np.float64(channel_messages_df['ts']), unit='s').min().date()   #AG20241120: Can be deleted\n",
    "        #channel_messages_maxdate = pd.to_datetime(np.float64(channel_messages_df['ts']), unit='s').max().date()   #AG20241120: Can be deleted\n",
    "        ts_to_tz(channel_messages_df, 'ts', 'msg_date')\n",
    "        ts_to_tz(channel_messages_df, 'json_mod_ts', 'json_mod_date')\n",
    "        ts_to_tz(channel_messages_df, 'ts_latest_reply', 'latest_reply_date')\n",
    "        ts_to_tz(channel_messages_df, 'ts_thread', 'thread_date')\n",
    "        print('main_analysys ->>',curr_channel_name, datetime.now().time(), ' Formated the dates and times in the dataframe')\n",
    "            \n",
    "        ##-- Reorder the columns in channel_messages_df, if necessary:\n",
    "        #channel_messages_df = channel_messages_df[['channel', 'json_name', 'json_mod_date', 'user', 'name', 'display_name', 'ts', 'msg_id', 'type', 'text']]\n",
    "        #channel_messages_df.index = ['']*len(channel_messages_df)\n",
    "        \n",
    "        ##-- Write channel_messages_df to a .xlsx file:\n",
    "        channel_messages_mindate = channel_messages_df['msg_date'].min().split(\" \")[0]\n",
    "        channel_messages_maxdate = channel_messages_df['msg_date'].max().split(\" \")[0]\n",
    "        channel_messages_filename = f\"{curr_channel_name}_{channel_messages_mindate}_to_{channel_messages_maxdate}\"\n",
    "        channel_messages_folder_path = f\"{converted_directory}/{channel_messages_filename}.xlsx\"\n",
    "        channel_messages_df.to_excel(f\"{channel_messages_folder_path}\", index=False)\n",
    "        apply_excel_adjustments(f\"{channel_messages_folder_path}\",curr_channel_name)  #AG: defined this routine in the function apply_excel_adjustments\n",
    "        print(curr_channel_name, datetime.now().time(), ' Wrote curated messages to xlsx files', '\\n')\n",
    "\n",
    "print(datetime.now().time(), 'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82fcdc7-f683-4b1a-8372-df61a76aecd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>msg_date</th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>reply_users_count</th>\n",
       "      <th>latest_reply_date</th>\n",
       "      <th>thread_date</th>\n",
       "      <th>parent_user_id</th>\n",
       "      <th>json_name</th>\n",
       "      <th>json_mod_date</th>\n",
       "      <th>channel_folder</th>\n",
       "      <th>name</th>\n",
       "      <th>display_name</th>\n",
       "      <th>is_bot</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2215a72-2d2c-4241-8bd6-a84961993ae1</td>\n",
       "      <td>2023-12-22 11:42:16</td>\n",
       "      <td>U02063W7Z1V</td>\n",
       "      <td>message</td>\n",
       "      <td>Good morning &lt;team-zixi-medkids-games&gt;\\nWhat's...</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-12-22.json</td>\n",
       "      <td>2024-10-03 14:47:46</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>ask</td>\n",
       "      <td>Tamara C. Daniels</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3F7B86F4-B2A2-44D1-A93E-40637BDAF64B</td>\n",
       "      <td>2023-11-11 12:02:26</td>\n",
       "      <td>U05ASBTDAHK</td>\n",
       "      <td>message</td>\n",
       "      <td>Hey Zixi (Vic) Liu! Are we still meeting at 2p...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-11-11 12:43:57</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-11-11.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>jzhu</td>\n",
       "      <td>Julia Zhu</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81635d1e-5c9f-4bae-8b31-fe97470c6c55</td>\n",
       "      <td>2023-11-11 12:12:58</td>\n",
       "      <td>U02063W7Z1V</td>\n",
       "      <td>message</td>\n",
       "      <td>Miku I'm adding you to &lt;team-zixi-medkids-game...</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-11-11.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>ask</td>\n",
       "      <td>Tamara C. Daniels</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FF06AB53-0F70-432C-BF62-095AE439E837</td>\n",
       "      <td>2023-11-11 12:28:09</td>\n",
       "      <td>U05KTJ0H540</td>\n",
       "      <td>message</td>\n",
       "      <td>Yes we are! I’ll see you in 30min</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-11-11 12:02:26</td>\n",
       "      <td>U05ASBTDAHK</td>\n",
       "      <td>2023-11-11.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>vic.zixi.liu</td>\n",
       "      <td>Zixi (Vic) Liu</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>911e54c3-fe42-4775-9b81-b3435f24f34c</td>\n",
       "      <td>2023-11-11 12:43:17</td>\n",
       "      <td>U0648871JG3</td>\n",
       "      <td>message</td>\n",
       "      <td>Hi Zixi (Vic) Liu would you mind to send me th...</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>n/d</td>\n",
       "      <td>2023-11-11.json</td>\n",
       "      <td>2024-10-03 14:47:44</td>\n",
       "      <td>team-zixi-medkids-games</td>\n",
       "      <td>markdfang</td>\n",
       "      <td>Mark Fang</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 msg_id             msg_date         user  \\\n",
       "0  f2215a72-2d2c-4241-8bd6-a84961993ae1  2023-12-22 11:42:16  U02063W7Z1V   \n",
       "1  3F7B86F4-B2A2-44D1-A93E-40637BDAF64B  2023-11-11 12:02:26  U05ASBTDAHK   \n",
       "2  81635d1e-5c9f-4bae-8b31-fe97470c6c55  2023-11-11 12:12:58  U02063W7Z1V   \n",
       "3  FF06AB53-0F70-432C-BF62-095AE439E837  2023-11-11 12:28:09  U05KTJ0H540   \n",
       "4  911e54c3-fe42-4775-9b81-b3435f24f34c  2023-11-11 12:43:17  U0648871JG3   \n",
       "\n",
       "      type                                               text reply_count  \\\n",
       "0  message  Good morning <team-zixi-medkids-games>\\nWhat's...         n/d   \n",
       "1  message  Hey Zixi (Vic) Liu! Are we still meeting at 2p...           5   \n",
       "2  message  Miku I'm adding you to <team-zixi-medkids-game...         n/d   \n",
       "3  message                  Yes we are! I’ll see you in 30min         n/d   \n",
       "4  message  Hi Zixi (Vic) Liu would you mind to send me th...         n/d   \n",
       "\n",
       "  reply_users_count    latest_reply_date          thread_date parent_user_id  \\\n",
       "0               n/d                  n/d                  n/d            n/d   \n",
       "1                 3  2023-11-11 12:43:57                  n/d            n/d   \n",
       "2               n/d                  n/d                  n/d            n/d   \n",
       "3               n/d                  n/d  2023-11-11 12:02:26    U05ASBTDAHK   \n",
       "4               n/d                  n/d                  n/d            n/d   \n",
       "\n",
       "         json_name        json_mod_date           channel_folder  \\\n",
       "0  2023-12-22.json  2024-10-03 14:47:46  team-zixi-medkids-games   \n",
       "1  2023-11-11.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "2  2023-11-11.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "3  2023-11-11.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "4  2023-11-11.json  2024-10-03 14:47:44  team-zixi-medkids-games   \n",
       "\n",
       "           name       display_name is_bot URL  \n",
       "0           ask  Tamara C. Daniels  False      \n",
       "1          jzhu          Julia Zhu  False      \n",
       "2           ask  Tamara C. Daniels  False      \n",
       "3  vic.zixi.liu     Zixi (Vic) Liu  False      \n",
       "4     markdfang          Mark Fang  False      "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_messages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60eedf0-e7a9-4dd3-8862-afd7968ca627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(channel_messages_df)):\n",
    "    print(channel_messages_df.at[0,'URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b55b03-67b2-4e17-83b2-9304f533c8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://youtu.be/l7aEJufAXfk?si=8NHVu0ItcEOKYhyq|https://youtu.be/l7aEJufAXfk?si=8NHVu0ItcEOKYhyq',\n",
       " 'https://learn.unity.com/tutorial/introduction-to-sprite-animations|https://learn.unity.com/tutorial/introduction-to-sprite-animations']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_messages_df.at[69,'URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33c7ab46-772d-41d7-9c30-2a1fe08b6f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    All of you have been added to <http://Monday.c...\n",
       "URL                                          [Monday.com]\n",
       "Name: 205, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_urls_test(df):\n",
    "    \"\"\"Extracts all the url links in df['text'] and stores them as a list in df['URL']\"\"\"\n",
    "    extractor = URLExtract()\n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i,'text']\n",
    "        if 'https' in text:\n",
    "            url = extractor.find_urls(text)\n",
    "            df.at[i,'URL'] = url\n",
    "            print(i, url)\n",
    "        else:\n",
    "            df.at[i,'URL'] = missing_value # None   IP2024118\n",
    "\n",
    "df_test = channel_messages_df[['text','URL']].copy()\n",
    "df_test.loc[205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee6220a-2911-423a-bd35-3a8fcd385aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monday.com']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = URLExtract()\n",
    "extractor.find_urls(df_test.at[205, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f94a0687-2ffd-4697-a79c-5a18fd1c26ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"All of you have been added to <http://Monday.com|Monday.com>. You can view progress for Zixi (Vic) Liu's game designs there. I've provided a screenshot of how you can review them. Just type his name into the search window and everything that he's worked on can be viewed there. Let me know if you have questions.\\n\\nZixi (Vic) Liu is also big on meetings and very hands on. If you would share your availability for the week so that he can meet with you, that would be great. Thanks so much.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.at[205, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b13157-762c-4f05-8b21-afd6954a2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test)):\n",
    "    urls = extractor.find_urls(df_test.at[i, 'text'])\n",
    "    #print(i, urls)\n",
    "    if len(urls)>0:\n",
    "        df_test.at[i, 'URL'] = urls\n",
    "    else:\n",
    "        df_test.at[i, 'URL'] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e328e256-3db2-42d3-b9b8-71cf8d5937e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "44\n",
      "49\n",
      "61\n",
      "69\n",
      "111\n",
      "120\n",
      "122\n",
      "141\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_test)):\n",
    "    if \"http\" in df_test.at[i,'text']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63862711-6f53-4f62-ade7-df10e3ee47fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Zhu \n",
      "Hi this is a pretty good resource to start creating assets for Unity: <https://youtu.be/l7aEJufAXfk?si=8NHVu0ItcEOKYhyq|https://youtu.be/l7aEJufAXfk?si=8NHVu0ItcEOKYhyq>\n",
      "\n",
      "Here is an official tutorial on importing 2D animations in a single sprite sheet: <https://learn.unity.com/tutorial/introduction-to-sprite-animations|https://learn.unity.com/tutorial/introduction-to-sprite-animations>\n",
      "\n",
      "Please let me know if you have any further questions!\n",
      "['https://youtu.be/l7aEJufAXfk?si=8NHVu0ItcEOKYhyq|https://youtu.be/l7aEJufAXfk?si=8NHVu0ItcEOKYhyq', 'https://learn.unity.com/tutorial/introduction-to-sprite-animations|https://learn.unity.com/tutorial/introduction-to-sprite-animations']\n"
     ]
    }
   ],
   "source": [
    "i = 69\n",
    "\n",
    "print(df_test[['text','URL']].at[i, 'text'])\n",
    "print(df_test[['text','URL']].at[i, 'URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a062ddd-0fa8-4209-9906-e48ca13b425b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
