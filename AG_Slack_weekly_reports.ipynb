{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d872bd5-0073-4721-aa0e-2c659ece7420",
   "metadata": {},
   "source": [
    "Preliminary code to extract the check-in messages in the Slack channel \"think-biver-sunday-checkins\".\n",
    "\n",
    "Many of the steps/functions used in \"AG_slack-export-data-compilation.ipynb\" could be use to clean further this data (PENDING).\n",
    "\n",
    "The main objective so far was to separate the text into the expected categories: 'project_name', 'working_on', 'progress_and_roadblocks', 'plans_for_following_week', 'meetings'. Here are some comments/considerations:\n",
    "\n",
    "    1) When parsing the text, it is assumed that each category starts with the category_name followed by a semicolon. It works in most of the cases but there are exceptions where another symbol, or no symbol at all, is used. These messages cannot be confidently parsed.\n",
    "\n",
    "    2) There are entries that do not correspond to a real check-in, most of these entries were dropped. They can be SlackBot messages, or messages sent multiple times as a reminder of the expected format for the check-ins.\n",
    "\n",
    "    3) Some check-in messages contain more than one project. For these cases, each project is assigned to a different row in the final dataframe (preserving all relevant info as user, msg_id, ...). \n",
    "\n",
    "    4) The code was generalized to not rely on having the line \"Weekly report\" or \"Weekly update\" (since most of the messages do not have them). It makes things easier if it does have it, but it won't break if a message does not have it.\n",
    "\n",
    "    5) Different words/phrases that could refer (without ambiguitity) to a category are defined in keywords_dictionary. When parsing the text, all these possible ways of writting a category_name are considered.\n",
    "\n",
    "    6) The code was generalized to parse messages with semicolons in the bulk of the text other than the semicolons following the category name.\n",
    "\n",
    "PENDING:\n",
    "    \n",
    "    1) Convert users and channel ids to their display names when used in the messages.\n",
    "    2) Modify if necessary the format of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606426fe-4921-4b80-96bd-8a1c587780d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import getmtime, exists, isdir, isfile\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773d7e4-98be-47e9-8676-df1c53111441",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Global variables:\n",
    "missing_value = 'n/d'\n",
    "\n",
    "source_path = \"/home/agds/Documents/RebeccaEverleneTrust/RebeccaEverlene_Slack_export/think-biver-sunday-checkins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d11a4-18b3-4409-ac20-d2288b80bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Introduce expected/possible keywords per report's category:\n",
    "keywords_dictionary = {\n",
    "    'header' : ['weekly report', 'report', \"week's report\"],\n",
    "    'project_name': ['project name'],\n",
    "    'working_on' : ['working on', 'working', 'what you are working on', 'worked on'],\n",
    "    'progress_and_roadblocks' : ['progress and roadblocks', 'progress and roadblock', 'progress &amp; roadblocks', 'Progress/Roadblocks'],#, 'progress', 'roadblocks'],\n",
    "    'progress' : ['progress'],\n",
    "    'roadblocks' : ['roadblocks', 'roadblock'],\n",
    "    'plans_for_following_week' : ['plans for the following week', 'plans for next week', 'following week', 'next week', 'plans for the upcoming week'],\n",
    "    'meetings' : ['meetings', 'meet', 'met', \"meetings you've attended\", 'upcoming meetings', 'meetings', 'Meeting attended', 'Meetings attended']\n",
    "}\n",
    "all_keywords = ['project_name', 'working_on', 'progress_and_roadblocks', 'progress', 'roadblocks','plans_for_following_week', 'meetings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b8e7c-2dcc-48cf-a927-052030882a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Extract messages from the Slack channel \"think-biver-sunday-checkins\":\n",
    "\n",
    "def check_format_of_json_names(list_names):\n",
    "    \"\"\" Iterates over all the json files in a channel's directory, and returns a list with the names of the json files \n",
    "    that have the correct format 'yyyy-mm-dd.json' \"\"\"\n",
    "    list_names_dates = []\n",
    "    for i in range(len(list_names)):\n",
    "        match = re.match(r'(\\d{4})(-)(\\d{2})(-)(\\d{2})(.)(json)',list_names[i])\n",
    "        if match!=None:\n",
    "            list_names_dates.append(list_names[i])\n",
    "    return list_names_dates\n",
    "\n",
    "##-- Initialize dataframe with first json file:\n",
    "json_names = check_format_of_json_names(listdir(source_path))\n",
    "checkins_df = pd.read_json(source_path+'/'+json_names[0])\n",
    "checkins_df['json_name'] = json_names[0]\n",
    "\n",
    "##-- Iterate over the remaining json files and concat info to checkins_df:\n",
    "for file in json_names[1:]:\n",
    "    file_df = pd.read_json(source_path+'/'+file)\n",
    "    file_df['json_name'] = file\n",
    "    checkins_df = pd.concat([checkins_df,file_df], axis=0, ignore_index=True)\n",
    "\n",
    "##-- Keep relevant columns:\n",
    "checkins_df = checkins_df[['user', 'client_msg_id', 'ts', 'json_name', 'text']]\n",
    "\n",
    "##-- Set dtypes:\n",
    "checkins_column_names = list(checkins_df.columns)\n",
    "checkins_column_dtypes = ['string','string','float64','string','string']\n",
    "for i in range(len(checkins_column_names)):\n",
    "    checkins_df[checkins_column_names[i]] = checkins_df[checkins_column_names[i]].astype(checkins_column_dtypes[i])\n",
    "\n",
    "##-- Fix the dtype of each column:\n",
    "checkins_column_types = [checkins_df[feature].dtypes for feature in list(checkins_df.columns)]\n",
    "\n",
    "checkins_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf36803-0f14-4fc0-89c1-df09461de0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, missing_value):\n",
    "    df = df.replace(pd.NaT, missing_value)\n",
    "    df = df.replace(np.nan, missing_value) \n",
    "    df = df.fillna(missing_value)\n",
    "    return df\n",
    "    \n",
    "def get_indices_with_repeated_text(df):\n",
    "    \"\"\" Function to get the dataframe's indices of the rows that have exactly the same text \"\"\"\n",
    "    indices_before_drop = list(df.index)\n",
    "    indices_after_drop = list(df[['text']].drop_duplicates(subset=['text'], keep='last').index )\n",
    "    indices_same_text = []\n",
    "    for i in indices_before_drop:\n",
    "        flag = False\n",
    "        for j in indices_after_drop:\n",
    "            if i == j and flag == False:\n",
    "                flag = True\n",
    "        if flag == False:\n",
    "            indices_same_text.append(i)\n",
    "    return np.array(indices_same_text)\n",
    "\n",
    "##-- Check for messages that have repeated text:\n",
    "indices_same_text = get_indices_with_repeated_text(checkins_df)\n",
    "print('indices_same_text: ', np.array(indices_same_text), '\\n')\n",
    "\n",
    "##-- Messages explaining how the format of the checkins should be:\n",
    "sample_format_msg_text = checkins_df.at[10,'text']\n",
    "sample_format_msg_indices = checkins_df[checkins_df['text']==sample_format_msg_text].index\n",
    "print('sample_format_msg_indices: ', np.array(sample_format_msg_indices), '\\n')\n",
    "\n",
    "sample_text_indices = []\n",
    "sample_text_1 = '\\n\\n*Project Name* :Scapegoated \\n1. *What you are working on:* Currently focusing on designs and other suggestions as per the discussions with other team members as well as improving the design of the website\\n2. *Progress and Roadblocks:* Regularly asking for suggestions and in contact with other team members,no roadblocks so far.\\n3. *Plans for the following week:* To continue to work with the frontend part\\n4. *Meetings:* No meetings conducted'\n",
    "sample_text_2 = 'Hey *<!here>*, I’m Deeptha from the AWS team'\n",
    "sample_text_3 = \"<!channel> reposting <@U07FCQXU7Q9>'s message. Please adhere to it. THANK YOU.\"\n",
    "sample_text_4 = 'please follow this structure when posting updates'\n",
    "for i in range(len(checkins_df)):\n",
    "    text_i = checkins_df.at[i,'text']\n",
    "    if sample_text_1 in text_i or sample_text_2 in text_i or sample_text_3 in text_i or sample_text_4 in text_i:\n",
    "        sample_text_indices.append(i)\n",
    "print('sample_text_indices: ', np.array(sample_text_indices), '\\n')\n",
    "\n",
    "##-- Messages from USLACKBOT:\n",
    "bot_indices = checkins_df[checkins_df['user']=='USLACKBOT'].index\n",
    "print('bot_indices: ', np.array(bot_indices), '\\n')\n",
    "\n",
    "##-- Joined-the-channel messages:\n",
    "joined_channel_indices = []\n",
    "for i in list(checkins_df.index):\n",
    "    if 'has joined the channel' in checkins_df.at[i,'text']:\n",
    "      joined_channel_indices.append(i)\n",
    "print('joined_channel_indices: ', joined_channel_indices, '\\n')\n",
    "\n",
    "##-- Drop from dataframe:\n",
    "for msg_type_indices in [sample_format_msg_indices, sample_text_indices, bot_indices, joined_channel_indices]:\n",
    "    try:\n",
    "        checkins_df = checkins_df.drop(msg_type_indices,axis=0)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "##-- Remaining messages:\n",
    "#indices_same_text_remaining = get_indices_with_repeated_text(checkins_df)\n",
    "#print('indices_same_text_remaining: ', np.array(indices_same_text_remaining), '\\n')\n",
    "#checkins_df.loc[indices_same_text_remaining]\n",
    "\n",
    "##-- Handle missing values:\n",
    "checkins_df = handle_missing_values(checkins_df, missing_value)\n",
    "\n",
    "##-- Reset indices:\n",
    "checkins_df.index = np.arange(0,len(checkins_df),1)\n",
    "checkins_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454e7d2-7e4f-4c7a-8331-3402115c9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_message_format(text):\n",
    "    is_format_correct = [0]*len(all_keywords)\n",
    "    indices = []\n",
    "    \n",
    "    if text!='':\n",
    "        for line in text.splitlines():\n",
    "            line = line.lower().lstrip('*-•. ').rstrip('*-•. ').replace('*', '').replace(' ','')\n",
    "            for i in range(len(all_keywords)):\n",
    "                feature = all_keywords[i]\n",
    "                for keyword in keywords_dictionary[feature]:\n",
    "                    if keyword.lower().replace(' ','')+':' in line:\n",
    "                        is_format_correct[i] = 1\n",
    "                        indices.append(i)\n",
    "                        break\n",
    "                ##-- Double check 'roadblocks:' vs. 'progress and roadblocks:'\n",
    "                if feature == 'roadblocks':\n",
    "                    for keyword in keywords_dictionary['progress_and_roadblocks']:\n",
    "                        if keyword.lower().replace(' ','')+':' in line:\n",
    "                            is_format_correct[i] = 0\n",
    "                            indices = indices[:-1]\n",
    "    \n",
    "    check_format_dict = {}\n",
    "    for i in range(len(all_keywords)):\n",
    "        check_format_dict[all_keywords[i]] = is_format_correct[i]\n",
    "\n",
    "    return check_format_dict\n",
    "\n",
    "def check_messages_format(df):\n",
    "    indices_all_missing = []\n",
    "    indices_review = []\n",
    "    indices_all_pandr = []\n",
    "    indices_all_p_r = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i,'text']\n",
    "        \n",
    "        check_format_dict = check_message_format(text)\n",
    "        check_format_list = []\n",
    "        for j in range(len(check_format_dict)):\n",
    "            df.at[i, f\"format_{all_keywords[j]}\"] = check_format_dict[all_keywords[j]]\n",
    "            check_format_list.append( check_format_dict[all_keywords[j]] )\n",
    "        [pn, wo, pandr, p, r, nw, m] = check_format_list\n",
    "        \n",
    "        if 1 not in check_format_list:\n",
    "            indices_all_missing.append(i)\n",
    "            df.at[i,'status'] = 'Not parsed'\n",
    "        \n",
    "        elif pn==1 and wo==1 and pandr==1 and p==0 and r==0 and nw==1 and m==1:\n",
    "            indices_all_pandr.append(i)\n",
    "            df.at[i,'status'] = 'Fully parsed (p&r)'\n",
    "    \n",
    "        elif pn==1 and wo==1 and pandr==0 and p==1 and r==1 and nw==1 and m==1:\n",
    "            indices_all_p_r.append(i)\n",
    "            df.at[i,'status'] = 'Fully parsed (p,r)'\n",
    "    \n",
    "        else:\n",
    "            indices_review.append(i)\n",
    "            df.at[i,'status'] = 'review'\n",
    "\n",
    "\n",
    "    print(f\"All_missing: (({len(indices_all_missing)})) {indices_all_missing}\", '\\n')    \n",
    "    print(f\"Partially missing: (({len(indices_review)})) {indices_review}\", '\\n')\n",
    "    print(f\"All p&r: (({len(indices_all_pandr)})) {indices_all_pandr}\", '\\n')\n",
    "    print(f\"All p, r: (({len(indices_all_p_r)})) {indices_all_p_r}\", '\\n')\n",
    "\n",
    "check_messages_format(checkins_df)\n",
    "checkins_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94cca1-ec8b-4132-8db2-21f7529685d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_category(line, category_name):\n",
    "    \"\"\"\n",
    "    Returns True if the category_name, followed by a semicolon, was found in a line of the message.\n",
    "    \"\"\"\n",
    "    line = line.lower().lstrip('*-•. ').rstrip('*-•. ').replace('*', '').replace(' ','')\n",
    "    out = False\n",
    "    for keyword in keywords_dictionary[category_name]:\n",
    "        if keyword.lower().replace(' ','')+':' in line:\n",
    "            out = True\n",
    "    return out\n",
    "            \n",
    "\n",
    "def review_format(text):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with keys:\n",
    "        project_name, working_on, progress_and_roadblocks, progress, roadblocks, plans_for_following_week and meetings.\n",
    "    And values={0,1,missing_value} depending if the above keywords were found in the text as a whole.\n",
    "    \"\"\"\n",
    "    is_format_correct_list = [0]*len(all_keywords)\n",
    "    is_format_correct_dict = {}\n",
    "    \n",
    "    if text!='':\n",
    "        text_to_lines = text.splitlines()\n",
    "        for i_line in range(len(text_to_lines)):\n",
    "            line = text_to_lines[i_line]\n",
    "            for i in range(len(all_keywords)):\n",
    "                category_name = all_keywords[i]\n",
    "                if match_to_category(line, category_name) == True:\n",
    "                    is_format_correct_list[i] = 1\n",
    "                    break\n",
    "                ##-- Double check 'roadblocks:' vs. 'progress and roadblocks:'\n",
    "                if category_name == 'roadblocks' and match_to_category(line, 'roadblocks') == True:\n",
    "                    is_format_correct_list[i] = 0\n",
    "    \n",
    "    for i in range(len(all_keywords)):\n",
    "        is_format_correct_dict[all_keywords[i]] = is_format_correct_list[i]\n",
    "\n",
    "    return is_format_correct_dict\n",
    "\n",
    "\n",
    "def get_indices_of_lines_with_category_name(text):\n",
    "    \"\"\"\n",
    "    Returns two lists. One with the number of the line in the text where a keyword was identified and the other list with the corresponding \n",
    "    category_names\n",
    "    \"\"\"\n",
    "    indices_start_of_category = []  \n",
    "    category_names = []\n",
    "    if text!='':\n",
    "        text_to_lines = text.splitlines()\n",
    "        for i_line in range(len(text_to_lines)):\n",
    "            line = text_to_lines[i_line]\n",
    "            for i in range(len(all_keywords)):\n",
    "                category_name = all_keywords[i]\n",
    "                if match_to_category(line, category_name) == True:\n",
    "                    indices_start_of_category.append(i_line)\n",
    "                    category_names.append(category_name)\n",
    "                    break\n",
    "                ##-- Double check 'roadblocks:' vs. 'progress and roadblocks:'\n",
    "                if category_name == 'roadblocks' and match_to_category(line, 'roadblocks') == True:\n",
    "                    indices_start_of_category = indices_start_of_category[:-1]\n",
    "                    category_names = category_names[:-1]\n",
    "                    \n",
    "    return indices_start_of_category, category_names\n",
    "\n",
    "\n",
    "\n",
    "def group_lines(text, indices_start_of_category):\n",
    "    \"\"\"\n",
    "    Returns a list of lists, where each elements collects the content (1 or more lines) for each category in the text.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    begin = indices_start_of_category[0]\n",
    "    end = indices_start_of_category[-1]\n",
    "    text_to_lines = text.splitlines()\n",
    "    for i in range(len(indices_start_of_category)-1):\n",
    "        begin = indices_start_of_category[i]\n",
    "        end = indices_start_of_category[i+1]\n",
    "        blocks.append(text_to_lines[begin:end]) \n",
    "    blocks.append(text_to_lines[end:]) \n",
    "    return blocks\n",
    "\n",
    "def count_projects(category_names):\n",
    "    \"\"\"\n",
    "    Returns an integer with the number of identified projects in the text. A project is identified in the category label is:\n",
    "        \"Project name:\"\n",
    "    independently of lowercase or uppercase letters.\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for name in category_names:\n",
    "        if name == 'project_name':\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "def count_weekly_report_label(df):\n",
    "    \"\"\"\n",
    "    Retunrs a list of dataframe indices such that the label \"Weekly report:\" was found in the corresponding text.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i,'text']\n",
    "        for line in text.splitlines():\n",
    "            line = line.lower().lstrip('*-•. ').rstrip('*-•. ').replace('*', '')\n",
    "            if 'weekly report' in line or 'weekly update' in line:\n",
    "                indices.append(i)\n",
    "    return indices\n",
    "    \n",
    "\n",
    "def extract_answers(blocks_list):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, where each string corresponds to the \"answer\" of a given category.\n",
    "    It removes the category_name label, and combined multiple lines if necessary.\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    for block in blocks_list:\n",
    "        answer_text = ''\n",
    "        for line in block:\n",
    "            line_matches = False\n",
    "            for category in all_keywords:\n",
    "                if match_to_category(line, category)==True:\n",
    "                    answer_text += line.split(\":\")[1].lstrip('*-•. ').rstrip('*-•. ').replace('*', '')\n",
    "                    line_matches = True\n",
    "                    break\n",
    "            if line_matches==False:\n",
    "                answer_text += line\n",
    "        answers.append(answer_text)\n",
    "    return answers\n",
    "\n",
    "\n",
    "def create_empty_df_with_categories(n_rows):\n",
    "    \"\"\"\n",
    "    Returns an empty dataframe with n_rows number of rows and columns:\n",
    "        project_name, working_on, progress_and_roadblocks, progress, roadblocks, plans_for_following_week, meetings, n_projects, index_\n",
    "    The column index_ is for internal development of the code. It can be remove at the end.\n",
    "    \"\"\"\n",
    "    columns=list(all_keywords)+['n_projects','index_']\n",
    "    df = pd.DataFrame([[np.nan]*n_rows]*len(columns)).T\n",
    "    df.columns = columns  \n",
    "    df = df.astype('object')\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_msg_to_df(df, text, indices_start_of_category, category_names, answers):\n",
    "    \"\"\"\n",
    "    Takes the empty dataframe created with the function \"create_empty_df_with_categories(n_rows)\" and fills the cells \n",
    "    with the \"answers\" to the categories that were correctly identified in the text.\n",
    "    \"\"\"    \n",
    "    n_project = count_projects(category_names)\n",
    "\n",
    "    project_counter = -1\n",
    "    for i in range(len(category_names)):\n",
    "        if category_names[i] == 'project_name':\n",
    "            project_counter += 1\n",
    "            #df.at[project_counter, 'text'] = text\n",
    "        df.at[project_counter, category_names[i]] = answers[i]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_indices_progress_roadblocks(df, missing_value):\n",
    "    \"\"\"\n",
    "    Function to collect the dataframe's indices that contain:\n",
    "        progress_roadblocks = entries that have both \"Progress\" and \"Roadblocks\"\n",
    "        progress = entries that have only \"Progress\"\n",
    "        roadblocks = entries that have only \"Roadblocks\"\n",
    "        progress_and_roadblocks_true = entries that have the desire label \"progress_and_roadblocks\"\n",
    "        progress_and_roadblocks_other = []    \n",
    "    \"\"\"\n",
    "    progress = []\n",
    "    roadblocks = []\n",
    "    progress_roadblocks = []\n",
    "    progress_and_roadblocks_true = []\n",
    "    progress_and_roadblocks_other = []\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            if df.at[i, 'progress'] != missing_value and df.at[i, 'roadblocks'] != missing_value:\n",
    "                progress_roadblocks.append(i)\n",
    "            else:\n",
    "                if df.at[i, 'progress'] != missing_value :\n",
    "                    progress.append(i)\n",
    "                if df.at[i, 'roadblocks'] != missing_value :\n",
    "                    roadblocks.append(i)\n",
    "            if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'progress'] != missing_value:\n",
    "                progress_and_roadblocks_true.append(i)\n",
    "            if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'roadblocks'] != missing_value:\n",
    "                progress_and_roadblocks_true.append(i)\n",
    "            if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'progress'] != missing_value and df.at[i, 'roadblocks'] != missing_value:\n",
    "                progress_and_roadblocks_other.append(i)\n",
    "        except:\n",
    "            continue\n",
    "    return [progress, roadblocks, progress_roadblocks, progress_and_roadblocks_true, progress_and_roadblocks_other]\n",
    "\n",
    "\n",
    "def combine_progress_and_roadblocks(df, missing_value):\n",
    "    \"\"\" Combines the information in 'progress' and 'roadblocks' into 'progress_and_roadblocks', such that\n",
    "    the text in progress_and_roadblocks becomes:\n",
    "        \"Progress: progress_text\n",
    "         new_line\n",
    "         Roadblocks: roadblocks_text\"\n",
    "    An alternative is to split 'progress_and_roadblocks' although it is much more complicated.\n",
    "    \"\"\"\n",
    "    for i in range(len(df)):\n",
    "        pr_text = ''\n",
    "        if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'progress'] != missing_value:\n",
    "            pr_text += 'Progress: ' + df.at[i, 'progress'] + '\\n'\n",
    "        if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'roadblocks'] != missing_value:\n",
    "            pr_text += 'Roadblocks: ' + df.at[i, 'roadblocks']\n",
    "        \n",
    "        if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'roadblocks'] == missing_value:\n",
    "            pr_text = missing_value\n",
    "\n",
    "        if df.at[i, 'progress_and_roadblocks'] != missing_value and df.at[i, 'progress'] == missing_value and df.at[i, 'roadblocks'] == missing_value:\n",
    "            pr_text = df.at[i, 'progress_and_roadblocks']\n",
    "        \n",
    "        df.at[i, 'progress_and_roadblocks_combined'] = pr_text\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5f0e5-5811-40d4-9c9b-b813d6cfb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###-- MAIN ANALYSIS OF SECOND IMPLEMENTATION:\n",
    "\n",
    "def parse_dataframe(df):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with the parsed text.\n",
    "    Messages with weekly reports of more than one project are splitted in as many rows as projects in the report. \n",
    "    The columns are:\n",
    "       'user', 'client_msg_id', 'ts', 'json_name', 'text',\n",
    "       'format_project_name', 'format_working_on', 'format_progress_and_roadblocks', 'format_progress', 'format_roadblocks', 'format_plans_for_following_week','format_meetings', \n",
    "       'status', \n",
    "       'project_name', 'working_on', 'progress_and_roadblocks', 'progress', 'roadblocks', 'plans_for_following_week', 'meetings', \n",
    "       'n_projects', 'index_', 'index','progress_and_roadblocks_combined'\n",
    "    \"\"\"\n",
    "    ##-- Initialize a dataframe to collect the original and parsed information:\n",
    "    checkins_parsed_df = pd.DataFrame(columns=list(df)+list(all_keywords)+['n_projects','index_'])\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i,'text']   \n",
    "        \n",
    "        indices_start_of_category, category_names = get_indices_of_lines_with_category_name(text)\n",
    "        #print(indices_start_of_category)\n",
    "        #print(category_names, '\\n')\n",
    "        \n",
    "        if len(indices_start_of_category) == 0:   \n",
    "            ##-- If no keywords were identified in the non-empty text:\n",
    "            df_i_blocks = create_empty_df_with_categories(1)\n",
    "            n_projects = missing_value\n",
    "        elif len(indices_start_of_category) > 0:\n",
    "            blocks_list = group_lines(text, indices_start_of_category)\n",
    "            #print(blocks_list, '\\n')\n",
    "        \n",
    "            answers = extract_answers(blocks_list)\n",
    "            #print('answers =', answers, '\\n')\n",
    "        \n",
    "            n_projects = count_projects(category_names)\n",
    "            #print(f\"n_projects = {n_projects}\" , '\\n')\n",
    "            \n",
    "            if n_projects == 0:\n",
    "                ##-- If project_name was not identified:\n",
    "                df_i_blocks = create_empty_df_with_categories(1)\n",
    "            else:\n",
    "                df_i_blocks = create_empty_df_with_categories(n_projects)\n",
    "                df_i_blocks = parse_msg_to_df(df_i_blocks, text, indices_start_of_category, category_names, answers)      \n",
    "            \n",
    "        df_i_blocks['n_projects'] = n_projects\n",
    "        df_i_blocks['index_'] = i\n",
    "        df_i_blocks = handle_missing_values(df_i_blocks, missing_value)  \n",
    "        #display(df_i_blocks)\n",
    "            \n",
    "        ##-- Dataframe with the original text. Rows are dublicated as many times as projects in the checkin:\n",
    "        df_i_text = pd.DataFrame([list(df.loc[i].values)]*len(df_i_blocks))\n",
    "        df_i_text.columns = df.columns\n",
    "        df_i_text['index'] = i\n",
    "        df_i_text = handle_missing_values(df_i_text, missing_value)\n",
    "        #display(df_i_text)\n",
    "        \n",
    "        ##-- Concatenate df_i_text and df_i_blocks for i-th message:\n",
    "        df_i_all = pd.concat([df_i_text, df_i_blocks], axis=1, ignore_index=True)\n",
    "        df_i_all.columns = list(df_i_text.columns) + list(df_i_blocks.columns)\n",
    "        df_i_all = handle_missing_values(df_i_all, missing_value)  \n",
    "        #display(df_i_all)\n",
    "        \n",
    "        ##-- Concatenate to checkins_parsed_df:\n",
    "        checkins_parsed_df = pd.concat([checkins_parsed_df, df_i_all], axis=0, ignore_index=True)\n",
    "\n",
    "    ##-- Combine \"Progress\" and \"Roadblocks\":\n",
    "    #checkins_parsed_df = combine_progress_and_roadblocks(checkins_parsed_df, missing_value)\n",
    "    #checkins_parsed_df = handle_missing_values(checkins_parsed_df, missing_value)\n",
    "\n",
    "    return checkins_parsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03916ce2-1ead-46d9-8a4b-a5ef4e9c6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkins_parsed_df = parse_dataframe(checkins_df)\n",
    "checkins_parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7ff68-4f03-4a68-8b44-0ad6d64d5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['user', 'client_msg_id', 'ts', 'json_name', 'text','project_name', 'working_on','progress_and_roadblocks', 'progress', 'roadblocks', 'plans_for_following_week', 'meetings', 'n_projects']\n",
    "checkins_parsed_df = checkins_parsed_df[columns_to_keep]\n",
    "checkins_parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdb966-60f4-463e-96e3-a5e51afbcf48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
