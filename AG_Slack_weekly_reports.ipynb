{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d872bd5-0073-4721-aa0e-2c659ece7420",
   "metadata": {},
   "source": [
    "Preliminary code to extract the check-in messages in the Slack channel \"think-biver-sunday-checkins\".\n",
    "\n",
    "Many of the steps/functions used in \"AG_slack-export-data-compilation.ipynb\" could be use to clean further this data (PENDING).\n",
    "\n",
    "The main objective so far was to separate the text into the expected categories: 'project_name', 'working_on', 'progress_and_roadblocks', 'plans_for_following_week', 'meetings'.\n",
    "\n",
    "    1) When parsing the text, it is assumed that each category starts with the category_name followed by a semicolon. It works in most of the cases but there are exceptions where another symbol, or no symbol at all, is used. PENDING to generalize the first separation of the categories.\n",
    "\n",
    "    2) There are entries that do not correspond to a real check-in, most of these entries were dropped. They can be SlackBot messages, or messages sent multiple times as a reminder of the expected format for the check-ins.\n",
    "\n",
    "    3) Some check-in messages contain more than one project. For these cases, each project is assign to a different row in the final dataframe (preserving all relevant info as user, msg_id, ...). PENDING to include some edge cases.\n",
    "\n",
    "    4) Some messages split \"progress\" from \"roadblocks\". These cases where combined keeping the format:\n",
    "        \n",
    "        Progress: aaaaaaaaa.\n",
    "        \n",
    "        (new_line)\n",
    "        \n",
    "        Roadblocks: bbbbbbb.\n",
    "    \n",
    "    5) Preliminary stage. Some rows have been added to the dataframe for developing/debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606426fe-4921-4b80-96bd-8a1c587780d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import getmtime, exists, isdir, isfile\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773d7e4-98be-47e9-8676-df1c53111441",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Global variables:\n",
    "missing_value = 'n/d'\n",
    "\n",
    "source_path = \"/home/agds/Documents/RebeccaEverleneTrust/RebeccaEverlene_Slack_export/think-biver-sunday-checkins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d11a4-18b3-4409-ac20-d2288b80bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Introduce expected/possible keywords per report's category:\n",
    "keywords_dictionary = {\n",
    "    'header' : ['weekly report', 'report', \"week's report\"],\n",
    "    'project_name': ['project name', 'project'],\n",
    "    'working_on' : ['working on', 'working'],\n",
    "    'progress_and_roadblocks' : ['progress and roadblocks', 'progress and roadblock'],#, 'progress', 'roadblocks'],\n",
    "    'progress' : ['progress'],\n",
    "    'roadblocks' : ['roadblocks', 'roadblock'],\n",
    "    'plans_for_following_week' : ['plans for the following week', 'plans for next week', 'plans', 'following week', 'next week'],\n",
    "    'meetings' : ['meetings', 'meet', 'met']\n",
    "}\n",
    "all_keywords = ['project_name', 'working_on', 'progress_and_roadblocks', 'progress', 'roadblocks','plans_for_following_week', 'meetings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b8e7c-2dcc-48cf-a927-052030882a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Extract messages from the Slack channel \"think-biver-sunday-checkins\":\n",
    "\n",
    "def check_format_of_json_names(list_names):\n",
    "    \"\"\" Iterates over all the json files in a channel's directory, and returns a list with the names of the json files \n",
    "    that have the correct format 'yyyy-mm-dd.json' \"\"\"\n",
    "    list_names_dates = []\n",
    "    for i in range(len(list_names)):\n",
    "        match = re.match(r'(\\d{4})(-)(\\d{2})(-)(\\d{2})(.)(json)',list_names[i])\n",
    "        if match!=None:\n",
    "            list_names_dates.append(list_names[i])\n",
    "    return list_names_dates\n",
    "\n",
    "##-- Initialize dataframe with first json file:\n",
    "json_names = check_format_of_json_names(listdir(source_path))\n",
    "checkins_df = pd.read_json(source_path+'/'+json_names[0])\n",
    "checkins_df['json_name'] = json_names[0]\n",
    "\n",
    "##-- Iterate over the remaining json files and concat info to checkins_df:\n",
    "for file in json_names[1:]:\n",
    "    file_df = pd.read_json(source_path+'/'+file)\n",
    "    file_df['json_name'] = file\n",
    "    checkins_df = pd.concat([checkins_df,file_df], axis=0, ignore_index=True)\n",
    "\n",
    "##-- Keep relevant columns:\n",
    "checkins_df = checkins_df[['user', 'client_msg_id', 'ts', 'json_name', 'text']]\n",
    "\n",
    "##-- Set dtypes:\n",
    "checkins_column_names = list(checkins_df.columns)\n",
    "checkins_column_dtypes = ['string','string','float64','string','string']\n",
    "for i in range(len(checkins_column_names)):\n",
    "    checkins_df[checkins_column_names[i]] = checkins_df[checkins_column_names[i]].astype(checkins_column_dtypes[i])\n",
    "\n",
    "##-- Fix the dtype of each column:\n",
    "checkins_column_types = [checkins_df[feature].dtypes for feature in list(checkins_df.columns)]\n",
    "\n",
    "checkins_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf36803-0f14-4fc0-89c1-df09461de0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, missing_value):\n",
    "    df = df.replace(pd.NaT, missing_value)\n",
    "    df = df.replace(np.nan, missing_value) \n",
    "    df = df.fillna(missing_value)\n",
    "    return df\n",
    "    \n",
    "def get_indices_with_repeated_text(df):\n",
    "    \"\"\" Function to get the dataframe's indices of the rows that have exactly the same text \"\"\"\n",
    "    indices_before_drop = list(df.index)\n",
    "    indices_after_drop = list(df[['text']].drop_duplicates(subset=['text'], keep='last').index )\n",
    "    indices_same_text = []\n",
    "    for i in indices_before_drop:\n",
    "        flag = False\n",
    "        for j in indices_after_drop:\n",
    "            if i == j and flag == False:\n",
    "                flag = True\n",
    "        if flag == False:\n",
    "            indices_same_text.append(i)\n",
    "    return np.array(indices_same_text)\n",
    "\n",
    "##-- Check for messages that have repeated text:\n",
    "indices_same_text = get_indices_with_repeated_text(checkins_df)\n",
    "print('indices_same_text: ', np.array(indices_same_text), '\\n')\n",
    "\n",
    "##-- Messages explaining how the format of the checkins should be:\n",
    "sample_format_msg_text = checkins_df.at[10,'text']\n",
    "sample_format_msg_indices = checkins_df[checkins_df['text']==sample_format_msg_text].index\n",
    "print('sample_format_msg_indices: ', np.array(sample_format_msg_indices), '\\n')\n",
    "\n",
    "##-- Messages from USLACKBOT:\n",
    "bot_indices = checkins_df[checkins_df['user']=='USLACKBOT'].index\n",
    "print('bot_indices: ', np.array(bot_indices), '\\n')\n",
    "\n",
    "##-- Joined-the-channel messages:\n",
    "joined_channel_indices = []\n",
    "for i in list(checkins_df.index):\n",
    "    if 'has joined the channel' in checkins_df.at[i,'text']:\n",
    "      joined_channel_indices.append(i)\n",
    "print('joined_channel_indices: ', joined_channel_indices, '\\n')\n",
    "\n",
    "##-- Drop from dataframe:\n",
    "for msg_type_indices in [sample_format_msg_indices, bot_indices, joined_channel_indices]:\n",
    "    checkins_df = checkins_df.drop(msg_type_indices,axis=0)\n",
    "\n",
    "##-- Remaining messages:\n",
    "#indices_same_text_remaining = get_indices_with_repeated_text(checkins_df)\n",
    "#print('indices_same_text_remaining: ', np.array(indices_same_text_remaining), '\\n')\n",
    "#checkins_df.loc[indices_same_text_remaining]\n",
    "\n",
    "##-- Handle missing values:\n",
    "checkins_df = handle_missing_values(checkins_df, missing_value)\n",
    "\n",
    "##-- Reset indices:\n",
    "checkins_df.index = np.arange(0,len(checkins_df),1)\n",
    "checkins_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548e496-3376-4ecd-8764-548e66a6ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_report_into_blocks(report_text):\n",
    "    \"\"\" Separates the original text into blocks (before identifying their categories)\n",
    "    Assumes that each keyword is followed by \":\".\n",
    "    Lines containing \":\" signal the beginning of a block. The text that follows the semicolon can have multiple lines.\n",
    "    \"\"\"\n",
    "    if report_text!='':\n",
    "        lines_list = report_text.splitlines()\n",
    "        report_by_blocks = [lines_list[0]]\n",
    "        for line in lines_list[1:]:\n",
    "            if \":\" not in line:\n",
    "                report_by_blocks[-1] = report_by_blocks[-1]+'\\n'+line\n",
    "            else:\n",
    "                report_by_blocks.append(line)\n",
    "        return report_by_blocks\n",
    "    else:\n",
    "        return missing_value\n",
    "        \n",
    "\n",
    "def identify_categories(report_by_blocks):\n",
    "    \"\"\" Reads the list generated by split_report_into_blocks and matches each block to a report's category.\n",
    "    Stores matching in python dictionary \n",
    "    (Needs lots of improvement)\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=all_keywords)\n",
    "    project = -1\n",
    "    for item in report_by_blocks:\n",
    "        item_key = re.sub(r'[0-9.*-/]', '', item.partition(\":\")[0]).lstrip()\n",
    "        item_text = item.partition(\":\")[2].replace('*', '').lstrip()\n",
    "        ##-- Autocorrect key if necessary: (PENDING)\n",
    "        ##-- Compares the block's keyword to expected keywords:\n",
    "        for type in all_keywords:\n",
    "            keys = [i.lower().replace(' ','') for i in keywords_dictionary[type]]\n",
    "            if item_key.lower().replace(\" \", \"\") in keys:\n",
    "                if type == 'project_name':\n",
    "                    project += 1\n",
    "                df.at[project,type] = item_text.rstrip()\n",
    "                break\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_test(df):\n",
    "    \"\"\" Function use for debugging to make sure that the text was correctly parsed and \n",
    "    that entries with multiple projects were correctly separated into individual rows\"\"\"\n",
    "    missmatch = []\n",
    "    for i in range(len(df)):\n",
    "        text = df.at[i,'text']\n",
    "        project = df.at[i,'project_name']\n",
    "        working = df.at[i,'working_on']\n",
    "        pr = df.at[i,'progress_and_roadblocks']\n",
    "        plans = df.at[i,'plans_for_following_week']\n",
    "        meeting = df.at[i,'meetings']\n",
    "        index = df.at[i,'index']\n",
    "        index_ = df.at[i,'index_']\n",
    "        print(i, index, index_,'\\n -------------------------')\n",
    "        print(text,'\\n -------------------------')\n",
    "        print(project,'\\n -------------------------')\n",
    "        print(working,'\\n -------------------------')\n",
    "        print(pr,'\\n -------------------------')\n",
    "        print(plans,'\\n -------------------------')\n",
    "        print(meeting,'\\n ======================================')\n",
    "        if index != index_:\n",
    "            missmatch.append(i)\n",
    "    return missmatch\n",
    "\n",
    "\n",
    "def get_indices_progress_roadblocks(df, missing_value):\n",
    "    \"\"\"\n",
    "    Function to collect the dataframe's indices that contain:\n",
    "        progress_roadblocks = entries that have both \"Progress\" and \"Roadblocks\"\n",
    "        progress = entries that have only \"Progress\"\n",
    "        roadblocks = entries that have only \"Roadblocks\"\n",
    "        progress_and_roadblocks_true = entries that have the desire label \"progress_and_roadblocks\"\n",
    "        progress_and_roadblocks_other = []    \n",
    "    \"\"\"\n",
    "    progress = []\n",
    "    roadblocks = []\n",
    "    progress_roadblocks = []\n",
    "    progress_and_roadblocks_true = []\n",
    "    progress_and_roadblocks_other = []\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            if df.at[i, 'progress'] != missing_value and df.at[i, 'roadblocks'] != missing_value:\n",
    "                progress_roadblocks.append(i)\n",
    "            else:\n",
    "                if df.at[i, 'progress'] != missing_value :\n",
    "                    progress.append(i)\n",
    "                if df.at[i, 'roadblocks'] != missing_value :\n",
    "                    roadblocks.append(i)\n",
    "            if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'progress'] != missing_value:\n",
    "                progress_and_roadblocks_true.append(i)\n",
    "            if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'roadblocks'] != missing_value:\n",
    "                progress_and_roadblocks_true.append(i)\n",
    "            if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'progress'] != missing_value and df.at[i, 'roadblocks'] != missing_value:\n",
    "                progress_and_roadblocks_other.append(i)\n",
    "        except:\n",
    "            continue\n",
    "    return [progress, roadblocks, progress_roadblocks, progress_and_roadblocks_true, progress_and_roadblocks_other]\n",
    "\n",
    "\n",
    "def combine_progress_and_roadblocks(df, missing_value):\n",
    "    \"\"\" Combines the information in 'progress' and 'roadblocks' into 'progress_and_roadblocks', such that\n",
    "    the text in progress_and_roadblocks becomes:\n",
    "        \"Progress: progress_text\n",
    "         new_line\n",
    "         Roadblocks: roadblocks_text\"\n",
    "    An alternative is to split 'progress_and_roadblocks' although it is much more complicated.\n",
    "    \"\"\"\n",
    "    for i in range(len(df)):\n",
    "        pr_text = ''\n",
    "        if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'progress'] != missing_value:\n",
    "            pr_text += 'Progress: ' + df.at[i, 'progress'] + '\\n'\n",
    "        if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'roadblocks'] != missing_value:\n",
    "            pr_text += 'Roadblocks: ' + df.at[i, 'roadblocks']\n",
    "        \n",
    "        if df.at[i, 'progress_and_roadblocks'] == missing_value and df.at[i, 'roadblocks'] == missing_value:\n",
    "            pr_text = missing_value\n",
    "\n",
    "        if df.at[i, 'progress_and_roadblocks'] != missing_value and df.at[i, 'progress'] == missing_value and df.at[i, 'roadblocks'] == missing_value:\n",
    "            pr_text = df.at[i, 'progress_and_roadblocks']\n",
    "        \n",
    "        df.at[i, 'progress_and_roadblocks_combined'] = pr_text\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c6959-c369-4256-ab5a-8a1fbd1a69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- MAIN ANALYSIS:\n",
    "\n",
    "##-- Initialize a dataframe to collect the original and parsed information:\n",
    "checkins_parsed_df = pd.DataFrame(columns=list(checkins_df)+list(all_keywords)+['n_projects','index_'])\n",
    "\n",
    "for i in range(len(checkins_df)):\n",
    "    ##-- Dataframe with the parsed checkin message, with as many rows as projects in the message: \n",
    "    text = checkins_df.at[i,'text']\n",
    "    report_by_blocks = split_report_into_blocks(text)\n",
    "    df_i_blocks = identify_categories(report_by_blocks)\n",
    "    df_i_blocks['n_projects'] = len(df_i_blocks)\n",
    "    df_i_blocks['index_'] = i\n",
    "    if len(df_i_blocks) == 0:\n",
    "        df_i_blocks.loc[0] = [missing_value]*len(df_i_blocks.columns)\n",
    "        df_i_blocks['index_'] = i\n",
    "    df_i_blocks = handle_missing_values(df_i_blocks, missing_value)\n",
    "    \n",
    "    ##-- Dataframe with the original text. Rows are dublicated as many times as projects in the checkin:\n",
    "    df_i_text = pd.DataFrame([list(checkins_df.loc[i].values)]*len(df_i_blocks))\n",
    "    df_i_text.columns = checkins_df.columns\n",
    "    df_i_text['index'] = i\n",
    "    df_i_text = handle_missing_values(df_i_text, missing_value)\n",
    "\n",
    "    ##-- Concatenate df_i_text and df_i_blocks for i-th message:\n",
    "    df_i_all = pd.concat([df_i_text, df_i_blocks], axis=1, ignore_index=True)\n",
    "    df_i_all.columns = list(df_i_text.columns) + list(df_i_blocks.columns)\n",
    "    df_i_all = handle_missing_values(df_i_all, missing_value)\n",
    "\n",
    "    ##-- Concatenate to checkins_parsed_df:\n",
    "    checkins_parsed_df = pd.concat([checkins_parsed_df, df_i_all], axis=0, ignore_index=True)\n",
    "\n",
    "##-- Combine \"Progress\" and \"Roadblocks\":\n",
    "checkins_parsed_df = combine_progress_and_roadblocks(checkins_parsed_df, missing_value)\n",
    "checkins_parsed_df = handle_missing_values(checkins_parsed_df, missing_value)\n",
    "\n",
    "checkins_parsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4930aeb-506e-41a7-b2ed-b5e0ce15ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "missmatch = print_test(checkins_parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b2645-28c1-4094-80f4-2815b2e859f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(missmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355aa591-11a3-425f-a67d-be0a84ec2a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
