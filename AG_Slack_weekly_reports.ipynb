{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b88cdb-fa2b-450d-a1db-428ff13d3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import getmtime, exists, isdir, isfile\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c496c3-fc07-4d03-8e99-c9b4dcb686aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Introduce expected/possible keywords per report's category:\n",
    "keywords_dictionary = {\n",
    "    'header' : ['weekly report', 'report', \"week's report\"],\n",
    "    'project_name': ['project name', 'project'],\n",
    "    'working_on' : ['working on', 'working'],\n",
    "    'progress_and_roadblocks' : ['progress and roadblocks', 'progress and roadblock'],#, 'progress', 'roadblocks'],\n",
    "    'progress' : ['progress'],\n",
    "    'roadblocks' : ['roadblocks', 'roadblock'],\n",
    "    'plans_for_following_week' : ['plans for the following week', 'plans for next week', 'plans', 'following week', 'next week'],\n",
    "    'meetings' : ['meetings', 'meet', 'met']\n",
    "}\n",
    "all_keywords = ['project_name', 'working_on', 'progress_and_roadblocks', 'progress', 'roadblocks','plans_for_following_week', 'meetings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16db221-c130-4dd0-a77a-14640da17abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_format_of_json_names(list_names):\n",
    "    \"\"\" Iterates over all the json files in a channel's directory, and returns a list with the names of the json files \n",
    "    that have the correct format 'yyyy-mm-dd.json' \"\"\"\n",
    "    list_names_dates = []\n",
    "    for i in range(len(list_names)):\n",
    "        match = re.match(r'(\\d{4})(-)(\\d{2})(-)(\\d{2})(.)(json)',list_names[i])\n",
    "        if match!=None:\n",
    "            list_names_dates.append(list_names[i])\n",
    "    return list_names_dates\n",
    "    \n",
    "\n",
    "source_path = \"/home/agds/Documents/RebeccaEverleneTrust/RebeccaEverlene_Slack_export/think-biver-sunday-checkins\"\n",
    "\n",
    "json_names = check_format_of_json_names(listdir(source_path))\n",
    "##-- Initialize dataframe with first json file:\n",
    "checkins_df = pd.read_json(source_path+'/'+json_names[0])\n",
    "checkins_df['json_name'] = json_names[0]\n",
    "\n",
    "##-- Iterate over the remaining json files and concat info to checkins_df:\n",
    "for file in json_names[1:]:\n",
    "    file_df = pd.read_json(source_path+'/'+file)\n",
    "    file_df['json_name'] = file\n",
    "    checkins_df = pd.concat([checkins_df,file_df], axis=0, ignore_index=True)\n",
    "\n",
    "checkins_df = checkins_df[['user', 'ts', 'json_name', 'text']]\n",
    "initial_length = len(checkins_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2bc6d-d891-4209-9a43-6821f7bd75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value = 'n/d'\n",
    "\n",
    "def split_report_into_blocks(report_text):\n",
    "    \"\"\" Separates the original text into blocks (before identifying their categories)\n",
    "    Assumes that each keyword is followed by \":\".\n",
    "    Lines containing \":\" signal the beginning of a block. The text that follows the semicolon can have multiple lines.\n",
    "    \"\"\"\n",
    "    if report_text!='':\n",
    "        lines_list = report_text.splitlines()\n",
    "        report_by_blocks = [lines_list[0]]\n",
    "        for line in lines_list[1:]:\n",
    "            if \":\" not in line:\n",
    "                report_by_blocks[-1] = report_by_blocks[-1]+'\\n'+line\n",
    "            else:\n",
    "                report_by_blocks.append(line)\n",
    "        return report_by_blocks\n",
    "    else:\n",
    "        return missing_value\n",
    "        \n",
    "def identify_categories(report_by_blocks):\n",
    "    \"\"\" Reads the list generated by split_report_into_blocks and matches each block to a report's category.\n",
    "    Stores matching in python dictionary \"\"\"\n",
    "    dict_out = {}\n",
    "    for item in report_by_blocks:\n",
    "        item_key = item.partition(\":\")[0].replace('*', '').lstrip()\n",
    "        item_text = item.partition(\":\")[2].replace('*', '').lstrip()\n",
    "        #print('----------------------------------------', '\\n', item, '\\n', item_key, '\\n', item_text)\n",
    "        ##-- Autocorrect key if necessary: (PENDING)\n",
    "        ##-- Compares the block's keyword to expected keywords:\n",
    "        for type in all_keywords:   \n",
    "            keys = [i.lower().replace(' ','') for i in keywords_dictionary[type]] \n",
    "            if item_key.lower().replace(\" \", \"\") in keys:\n",
    "                #print('--------------------------- \\n',dict_out, list(dict_out.keys()), type)\n",
    "                if type in list(dict_out.keys()):\n",
    "                    dict_out[type] += [item_text.rstrip()]\n",
    "                else:\n",
    "                    dict_out[type] = [item_text.rstrip()]\n",
    "    \n",
    "                break\n",
    "    #print('====================================================')\n",
    "    if dict_out == {}:\n",
    "        dict_out['review'] = 1\n",
    "        \n",
    "    return dict_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af3b77-7204-4626-a421-f131abe4d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_channel = []\n",
    "review_text = []\n",
    "\n",
    "for i in range(len(checkins_df)):\n",
    "    try:\n",
    "        text = checkins_df.at[i,'text']\n",
    "        ##-- For now let's drop the \"has joined the channel\" messages to debug the rest:\n",
    "        if 'has joined the channel' in text:\n",
    "            checkins_df.drop(i, inplace=True)\n",
    "            joined_channel.append(i)\n",
    "        elif text!='':\n",
    "            report_by_blocks = split_report_into_blocks(text)\n",
    "            report_dict = identify_categories(report_by_blocks)\n",
    "            for key in list(report_dict.keys()):\n",
    "                #print('-------------------------- \\n', i, '\\n', key)\n",
    "                if report_dict[key] != 1 and len(report_dict[key]) == 1:\n",
    "                    checkins_df.at[i, key] = report_dict[key][0]\n",
    "                elif report_dict[key]!= 1 and len(report_dict[key]) > 1:\n",
    "                    checkins_df.at[i, key] = report_dict[key]\n",
    "                    #print(i, report_dict, '---------------')\n",
    "                elif report_dict[key] == 1:\n",
    "                    review_text.append(i)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "## Fill missing values with 0:\n",
    "checkins_df.fillna(0, inplace=True)\n",
    "checkins_df = checkins_df.replace('nan', 0)\n",
    "\n",
    "checkins_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea815f0f-a233-409c-a4b1-fc6db16de4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Separate checkins into as many rows as projects are in a single text:\n",
    "def split_projects(df):\n",
    "    ##-- Initialize df_out with first element of df:\n",
    "    df_out = df[:1].copy()\n",
    "    counter = []\n",
    "    for index in list(df.index)[1:]:\n",
    "        split_row = False\n",
    "        ##-- Check if the row needs to be splitted:\n",
    "        for feature in all_keywords:\n",
    "            if type(df.at[index, feature]) == list:\n",
    "                split_row = True\n",
    "        ##-- If so, duplicate the row:\n",
    "        df_before = df_out[:index+1].copy()\n",
    "        df_i = pd.DataFrame(df.loc[index].copy()).T\n",
    "        if split_row == False:\n",
    "            df_out = pd.concat([df_before, df_i], axis=0, ignore_index=True) \n",
    "        else:\n",
    "            df_out = pd.concat([df_before, df_i, df_i], axis=0, ignore_index=True) \n",
    "            counter.append(index)\n",
    "            df_out.at[ int(df_out.index[-1]), 'multiple_projects' ] = 1\n",
    "            df_out.at[ int(df_out.index[-2]), 'multiple_projects' ] = 1\n",
    "\n",
    "            n_projects = 2\n",
    "            \n",
    "            project_new_indices = [ int(df_out.index[-i]) for i in np.arange(1,n_projects,1) ]\n",
    "            project_number = 0\n",
    "            for index in project_new_indices:\n",
    "                for feature in all_keywords:\n",
    "                    try:\n",
    "                        df_out.at[ index, f\"{feature}_1\"] = df_out.at[ index, feature][project_number]\n",
    "                    except:\n",
    "                        continue\n",
    "                    project_number += 1\n",
    "\n",
    "    \n",
    "        #print(index, split_row)\n",
    "        #display(df_before)\n",
    "        #display(df_i)#, \n",
    "        #display(df_out)\n",
    "        #print('------------------------------------------------------ \\n')\n",
    "                \n",
    "    return df_out, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799977e6-4335-4d76-bb52-b283df5e1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, counter = split_projects(checkins_df)\n",
    "print(counter)\n",
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf4cbd-f36c-44aa-9dde-c5d83699b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Inspecting scenarios for progress_and_roadblocks:\n",
    "progress = []\n",
    "roadblocks = []\n",
    "progress_roadblocks = []\n",
    "progress_and_roadblocks_true = []\n",
    "progress_and_roadblocks_other = []\n",
    "for i in range(initial_length):\n",
    "    try:\n",
    "        if checkins_df.at[i, 'progress'] != 0 and checkins_df.at[i, 'roadblocks'] != 0:\n",
    "            progress_roadblocks.append(i)\n",
    "        else:\n",
    "            if checkins_df.at[i, 'progress'] != 0 :\n",
    "                progress.append(i)\n",
    "            if checkins_df.at[i, 'roadblocks'] != 0 :\n",
    "                roadblocks.append(i)\n",
    "        if checkins_df.at[i, 'progress_and_roadblocks'] == 0 and checkins_df.at[i, 'progress'] != 0:\n",
    "            progress_and_roadblocks_true.append(i)\n",
    "        if checkins_df.at[i, 'progress_and_roadblocks'] == 0 and checkins_df.at[i, 'roadblocks'] != 0:\n",
    "            progress_and_roadblocks_true.append(i)\n",
    "        if checkins_df.at[i, 'progress_and_roadblocks'] == 0 and checkins_df.at[i, 'progress'] != 0 and checkins_df.at[i, 'roadblocks'] != 0:\n",
    "            progress_and_roadblocks_other.append(i)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(len(progress_roadblocks), progress_roadblocks)          ## both 'progress' and 'roadblocks' are filled\n",
    "print(len(progress), progress)                                ## additional rows where only 'progress' in filled\n",
    "print(len(roadblocks), roadblocks)                            ## additional rows where only 'roadblocks' in filled\n",
    "print(len(progress_and_roadblocks_true), progress_and_roadblocks_true) ## rows where 'progress_and_roadblocks' is filled\n",
    "#14+18+21\n",
    "\n",
    "#print('\\n', progress_and_roadblocks_other)\n",
    "\n",
    "##-- Notes:\n",
    "##-- When properly identified, the distinction between 'progress_and_roadbacks', 'progress', 'roadblocks' works.\n",
    "##-- The messages in 'progress_and_roadblocks_other' are empty because of some other reason that needs to be debuged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8daba-4a8f-429c-9eee-d4b5dff3dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Formating 'progress_and_roadblocks':\n",
    "def combine_progress_and_roadblocks(df):\n",
    "    \"\"\" Combines the information in 'progress' and 'roadblocks' into 'progress_and_roadblocks', such that\n",
    "    the text in progress_and_roadblocks becomes:\n",
    "        \"Progress: progress_text\n",
    "         new_line\n",
    "         Roadblocks: roadblocks_text\"\n",
    "    An alternative is to split 'progress_and_roadblocks' although it is much more complicated.\n",
    "    \"\"\"\n",
    "    for i in df.index:\n",
    "        pr_text = ''\n",
    "        try:\n",
    "            if df.at[i, 'progress_and_roadblocks'] == 0 and df.at[i, 'progress'] != 0:\n",
    "                pr_text += 'Progress: ' + df.at[i, 'progress'] + '\\n'\n",
    "            if df.at[i, 'progress_and_roadblocks'] == 0 and df.at[i, 'roadblocks'] != 0:\n",
    "                pr_text += 'Roadblocks: ' + df.at[i, 'roadblocks']\n",
    "            \n",
    "            df.at[i, 'progress_and_roadblocks_combined'] = pr_text\n",
    "        except:\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "df = checkins_df.copy()\n",
    "df = combine_progress_and_roadblocks(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b8f78-9e4e-4fe9-818e-c1d02beeed09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
